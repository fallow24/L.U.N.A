% --- In Press ---

@INPROCEEDINGS{soa1, author={ {Daliang Liu} and {Hanxv Sun} and {Qingxuan Jia} and {Liangqing Wang}}, booktitle={2008 7th World Congress on Intelligent Control and Automation}, title={Motion control of a spherical mobile robot by feedback linearization}, year={2008}, volume={}, number={}, pages={965-970},}

@INPROCEEDINGS{soa2, author={{S.Hanxu} and{ X.Aiping} and {J.Qingxuan} and{ W.Liangqing}}, title={Omnidirectional kinematics analysis on bi-driver spherical robot}, booktitle={Journal of Beijing University of Aeronautics and Astronautics 31}, pages ={ 735-739}, month={July}, year={2005} }

@INPROCEEDINGS{soa3, author={H. {Vahid Alizadeh} and M. J. {Mahjoob}}, booktitle={2011 IEEE International Symposium on Robotic and Sensors Environments (ROSE)}, title={Quadratic damping model for a spherical mobile robot moving on the free surface of the water}, year={2011}, volume={}, number={}, pages={125-130},}
@ARTICLE{soa4,  author={V. {Muralidharan} and A. D. {Mahindrakar}},  journal={IEEE Transactions on Automatic Control},  title={Geometric Controllability and Stabilization of Spherical Robot Dynamics},   year={2015},  volume={60},  number={10},  pages={2762-2767},}
@ARTICLE{soa5, author={S. {Bhattacharya} and S. K. {Agrawal}}, journal={IEEE Transactions on Robotics and Automation}, title={Spherical rolling robot: a design and motion planning studies}, year={2000}, volume={16}, number={6}, pages={835-839},}

@article{soa6,
author = {J Alves and J Dias},
title ={Design and control of a spherical mobile robot},
journal = {Proceedings of the Institution of Mechanical Engineers, Part I: Journal of Systems and Control Engineering},
volume = {217},
number = {6},
pages = {457-467},
year = {2003},
doi = {10.1177/095965180321700602},

URL = { 
        https://doi.org/10.1177/095965180321700602
    
},
eprint = { 
        https://doi.org/10.1177/095965180321700602
    
}
}
@article{soa7,
  title={A spherical mobile micro-robot for scientific applications},
  author={Halme, Aarne and Suomela, Jussi and Sch{\"o}nberg, Torsten and Wang, Yan},
  journal={ASTRA},
  volume={96},
  year={1996}
}



@ARTICLE{tgrs2019,
  author =        {D. {L{\"u}hr} and M. {Adams} and H. {Houshiar} and
                  D. {Borrmann} and A. {N{\"u}chter}},
  journal =       {IEEE Transactions on Geoscience and Remote Sensing},
  title =         {{Feature Detection With a Constant FAR in Sparse
                  3-D Point Cloud Data}},
  year =          {2019},
  volume =        {},
  number =        {},
  pages =         {1--15},
  abstract =      {The detection of markers or reflectors within point
                  cloud data (PCD) is often used for 3-D scan
                  registration, mapping, and 3-D environmental
                  modeling. However, the reliable detection of such
                  artifacts is diminished when PCD is sparse and
                  corrupted by detection and spatial errors, for
                  example, when the sensing environment is
                  contaminated by high dust levels, such as in
                  mines. In the radar literature, constant false alarm
                  rate (CFAR) processors provide solutions for
                  extracting features within noisy data; however,
                  their direct application to sparse, 3-D PCD is
                  limited due to the difficulty in defining a suitable
                  noise window. Therefore, in this article, CFAR
                  detectors are derived, which are capable of
                  processing a 2-D projected version of the 3-D PCD or
                  which can directly process the 3-D PCD
                  itself. Comparisons of their robustness, with
                  respect to data sparsity, are made with various
                  state-of-the-art feature detection methods, such as
                  the Canny edge detector and random sampling
                  consensus (RANSAC) shape detection methods.},
  doi =           {10.1109/TGRS.2019.2950292},
  month =         {},
}

% --- 2019 ---

@TechReport{ICIP2019,
  author = 	  {A. N{\"u}chter and J. Schauer and D. Borrmann},
  title = 	  {{Technical Report: Reduction and Compression using
                  Octrees --- {3DTK}'s entry to the {ICIP} 2019
                  Challenge on Point Cloud Coding}},
  institution =  {Robotics and Telematics, University of Würzburg},
  year = 		  {2019},
  address =      {Würzburg, Germany},
  month = 	  {September},
  abstract     = {Modern photogrammetric methods as well as laser
                  measurement systems make it easy to collect large 3D
                  point clouds that sample objects or
                  environments. Several mechanisms are available in
                  literature for storing and compressing point clouds,
                  e.g., applying conventional image based compression
                  methods to 3D point clouds.  In this challenge entry
                  however, we make use of octree subsampling and
                  compression, which is nicely suited for
                  unstructured, registered 3D point clouds of
                  arbitrarily shaped objects.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icip2019.pdf},
}

@InProceedings{O3DM2019,
  author       = {M. Bleier and J. v.d. Lucht and A. N{\"u}chter},
  title        = {SCOUT3D -- An underwater laser scanning system for mobile mapping},
  booktitle    = {Proceedings of Optical 3D Metrology 2019},
  year         = {2019},
  series       = {ISPRS Int. Archives Photogrammetry and Remote Sensing, Spatial Inf. Sci., XLII-2/W18},
  pages        = {13--18},
  month        = {November},
  address      = {Strasbourg, France},
  abstract     = {This paper presents an underwater laser scanning
                  system and GNSS based trajectory estimation system
                  for scanning from a surface vessle in shallow
                  water. The system has an above-the-water and an
                  underwater component. Above-the-water two low-cost
                  multi- band GNSS receivers with an antenna baseline
                  of one meter are used for RTK positioning with
                  heading. The full 6-DOF is estimated by fusing the
                  satellite navigation data with a MEMS-based INS. The
                  3D data is captured in water using a structured
                  light scanner consisting of a low-light underwater
                  camera and a green cross line laser projector. We
                  describe the development of the system and employed
                  hardware components. We show results of scanning a
                  large test object in a water tank acquired by from a
                  tripod with a motorized yaw axis. Additionally, we
                  demonstrate first results of mobile mapping from a
                  floating platform. We evaluate the performance of
                  the system by measuring the 6-DOF trajectory with an
                  external optical tracking system. Additionally, we
                  assess the quality of the created point cloud using
                  reference objects placed in the scene.},
  doi          = {10.5194/isprs-archives-XLII-2-W18-13-2019},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/o3dm_2019.pdf},
  }

@InProceedings{LC2019,
  author       = {J. v.d. Lucht and M. Bleier and A. N{\"u}chter},
  title        = {A low cost underwater test environment},
  booktitle    = {Proceedings of LowCost 3D 2019},
  year         = {2019},
  series       = {ISPRS Int. Archives Photogrammetry and Remote Sensing, Spatial Inf. Sci., XLII-2/W17},
  pages        = {399--404},
  month        = {November},
  address      = {Strasbourg, France},
  abstract     = {In this paper we present the setup of a low cost
                  underwater test environment. The employed materials
                  and structures are described as well as the lessons
                  learned during operations and experiments conducted
                  in the water tank. We provide the bill of materials
                  and a break-down of the costs involved in setting up
                  the test site. The goal was to build a low cost test
                  environment for underwater applications, because our
                  lab is around 40 minutes by car from the nearest
                  lake. Also a natural lake is not an optimal location
                  for first test and experiments, because the access
                  to the water is difficult and logistics of equipment
                  is time consuming. This work aims to describe what
                  experiences we have gained during the time of
                  construction.  Which materials we used and what we
                  would do differently next time. Furthermore, we
                  describe the idea and process to place calibration
                  markers inside the container and how the water
                  thwarted our plan. We show that it is possible to
                  realize a useful test environment for underwater
                  experiments for less than Euro 20.000.},
  doi          = {10.5194/isprs-archives-XLII-2-W17-399-2019},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/lc3d_2019.pdf},
  }

@INPROCEEDINGS{VSGAMES2019,
author = {K. A. M. {Heydn} and M. P. {Dietrich} and M. {Barkowsky} and
                  G. {Winterfeldt} and S. {von Mammen} and
                  A. {N{\"u}chter}},
booktitle = {11th International Conference on Virtual Worlds and
                  Games for Serious Applications (VS-Games '19)},
title = {The Golden Bullet: A Comparative Study for Target
                  Acquisition, Pointing and Shooting},
year = {2019},
pages = {1--8},
abstract = {In this study, we evaluate an interaction sequence
                  performed by six modalities consisting of
                  desktop-based (DB) and virtual reality (VR)
                  environments using different input devices. For the
                  given study, we implemented a vertical prototype of
                  a first person shooter (FPS) game scenario, focusing
                  on the genre-defining point-and-shoot mechanic. We
                  introduce measures to evaluate the success of the
                  according interaction sequence (times for target
                  acquisition, pointing, shooting, overall net time,
                  and number of shots) and conduct experiments to
                  record and compare the users' performances. We show
                  that interacting using head-tracking for
                  landscape-rotation is performing similarly to the
                  input of a screen-centered mouse and also yielded
                  shortest times in target acquisition and
                  pointing. Although using head-tracking for target
                  acquisition and pointing was most efficient,
                  subjects rated the modality using head-tracking for
                  target acquisition and a 3DOF Controller for
                  pointing best. Eye-tracking (ET) yields promising
                  results, but calibration issues need to be resolved
                  to enhance reliability and overall user experience.},
  doi = {10.1109/VS-Games.2019.8864589},
  ISSN = {},
  month = {September},
  url = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/vsgames2019.pdf},
  }

@INPROCEEDINGS{ISMAR2018,
  author={D. {Borrmann} and A. {N{\"u}chter} and T. {Wiemann}},
  booktitle={IEEE International Symposium on Mixed and Augmented
                  Reality Adjunct (ISMAR-Adjunct '18)},
  title={{Workshop: Large-Scale 3D Point Cloud Processing for Mixed and
                  Augmented Reality}},
  year = {2018},
  pages={xxxv},
  doi={10.1109/ISMAR-Adjunct.2018.00018},
  abstract={The rapid development of 3D scanning technology combined
                  with state-of-the-art mapping algorithms allows to
                  capture 3D point clouds with high resolution and
                  accuracy. The high amount of data collected with
                  LiDAR, RGB-D cameras or generated through SfM
                  approaches makes the direct use of the recorded data
                  for realistic rendering and simulation
                  problematic. Therefore, these point clouds have to
                  be transformed into representations that fulfill the
                  computational requirements for VR and AR setups. In
                  this tutorial participants will be introduced to
                  state-of-the-art methods in point cloud processing
                  and surface reconstruction with open source software
                  to learn the benefits for AR and VR applications by
                  interleaved presentations, software demonstrations
                  and software trials. The focus lies on 3D point
                  cloud data structures (range images, octrees, k-d
                  trees) and algorithms, and their implementation in
                  C/C++. Surface reconstruction using Marching Cubes
                  and other meshing methods will play another central
                  role. Reference material for subtopics like 3D point
                  cloud registration and SLAM, calibration, filtering,
                  segmentation, meshing, and large scale surface
                  reconstruction will be provided. Participants are
                  invited to bring their Linux, MacOS or Windows
                  laptops to gain hands-on experience on practical
                  problems occuring when working with large scale 3D
                  point clouds in VR and AR applications.},
  month={October},
}

@INPROCEEDINGS{SSRR2019_2,
  author={R. {Edlinger} and A. {N{\"u}chter}},
  booktitle={IEEE International Symposium on Safety, Security, and
                  Rescue Robotics (SSRR '19)},
  title={{MARC -- Modular Autonomous Adaptable Robot Concept}},
  year={2019},
  pages={1--7},
  doi={10.1109/SSRR.2019.8848934},
  url={https://robotik.informatik.uni-wuerzburg.de/telematics/download/ssrr2019_2.pdf},
  abstract={The paper introduces a novel modular and adaptable payload
                  concept for plugging in sensor and actuator
                  platforms such as 3D LIDAR and visual sensor systems
                  and robot manipulator and gripper
                  systems. Integration, programming and operation of
                  heterogeneous robot systems (such as mobile
                  manipulators or robots in a machine network) are
                  very complex tasks for plant
                  operators. Heterogeneous system components have to
                  be orchestrated (via proprietary interfaces) by
                  higher-level control systems. Robot programs are
                  created offline, in proprietary tools, and used
                  through macros. System components are generally not
                  compatible and interchangeable across
                  manufacturers. These have to be programmed
                  separately in manufacturer-specific
                  tools. Cross-component debugging is difficult. The
                  operation of complex systems is difficult, requires
                  intensive training, and is currently limited to
                  simple graphical user interfaces (GUI). As part of
                  process optimization, it is usually necessary to
                  optimize process points during the start-up
                  phase. This requires highly skilled personnel
                  capable of robot programming at the plant operators
                  site. The combination of heterogeneous robot modules
                  results in many new hazardous situations. It is
                  therefore necessary to include an appropriate safety
                  concept. The goal is to design a robot payload
                  concept with a plug-and-play approach to be used as
                  a modular and flexible unit. This shall reduce the
                  effort for system integration and sensor calibrating
                  significantly and provide a customized perception of
                  the environment during certain work processes. The
                  modular, autonomous and adaptable robot concept with
                  several sensors and hardware components was
                  implemented as a prototype on a rescue robot. The
                  modules have already been integrated on other
                  autonomous vehicles for exploration and dexterity
                  tasks.},
  month={September},
}

@INPROCEEDINGS{SSRR2019_1,
  author={H. A. {Lauterbach} and C. B. {Koch} and R. {Hess} and D. {Eck}
                  and K. {Schilling} and A. {N{\"u}chter}},
  booktitle={IEEE Internati\section{Technical Approach}
\label{sec:TechnicalApproach}

\todo[inline]{Small intro to technical approach}

\subsection{Hardware Setup}
\label{sec:TechnicalApproach:HardwareSetup}

\todo[inline]{Talk about hardware setup}

\subsection{Sensor Integration}
\label{sec:TechnicalApproach:SensorIntegration}

\todo[inline]{Talk about sensor integration}onal Symposium on Safety, Security, and
                  Rescue Robotics (SSRR '19)},
  title={{The Eins3D project -- Instantaneous UAV-Based 3D Mapping for
                  Search and Rescue Applications}},
  year={2019},
  pages={1--6},
  doi={10.1109/SSRR.2019.8848972},
  url={https://robotik.informatik.uni-wuerzburg.de/telematics/download/ssrr2019_1.pdf},
  abstract={The overview of a situation in a search and rescue
                  disaster is the key aspect of an effective
                  assistance. In the recent years the utilization of
                  multicopter with various photogrammetry systems is
                  an upcoming trend and an open field of
                  research. This paper discusses the technical aspects
                  of an automated integral system that will support
                  rescuers during the strategic mission planning and
                  will give situational awareness by instantaneous 3D
                  mapping. The approach combines sensors including a
                  3D Laserscanner, a thermal camera and an attitude
                  system as a payload unit on an Multicopter. The
                  continuous data fusion and the down link are
                  providing an instant 3D environment map that is
                  continuously revised and updated.},
  month={September},
}

@INPROCEEDINGS{SSRR2019_3,
  author={P. {Koch} and S. {May} and H. {Engelhardt} and J. {Ziegler}
                  and A. {N{\"u}chter}},
  booktitle={IEEE International Symposium on Safety, Security, and
                  Rescue Robotics (SSRR '19)},
  title={{Signed Distance Based Reconstruction for Exploration and Change Detection in Underground Mining Disaster Prevention}},
  year={2019},
  pages={1--2},
  doi={10.1109/SSRR.2019.8848931},
  url= {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ssrr2019_3.pdf},
  abstract={This publication describes an application of a Truncated
                  Signed Distance Mapping approach for disaster
                  intervention in underground mine shafts through
                  geometrical change detection of the shaft walls. The
                  paper describes two main problems of such an
                  approach (aligning two potentially huge point clouds
                  and automatic change detection by comparing the
                  reconstructed volumes) and explains in detail the
                  proposed solution.},
  month={September},
}


@InProceedings{LS2019,
  author       = {H. A. Lauterbach and D. Borrmann and A. N{\"u}chter and A. P. Rossi and V. Unnithan and P. Torrese and R. Pozzobon},
  title        = {Mobile mapping of the La Corona lavatube on Lanzarote},
  booktitle    = {Proceedings of the ISPRS Geospatial Week 2019, Laserscanning 2019},
  year         = {2019},
  series       = {ISPRS Annals Photogrammetry and Remote Sensing,
                  Spatial Inf. Sci., IV-2/W5},
  pages        = {381--387},
  month        = {June},
  address      = {Enschede, Netherlands},
  abstract     = {Planetary surfaces consist of rough terrain and
                  cave-like environments. Future planetary exploration
                  demands for accurate mapping. However, recent
                  backpack mobile mapping systems are mostly tested in
                  structured, indoor environments. This paper
                  evaluates the use of a backpack mobile mapping
                  system in a cave-like environment. The experiments
                  demonstrate the abilities of an continuous-time
                  optimization approach by mapping part of a lavatube
                  of the La Corona volcano system on Lanzarote. We
                  compare two strategies for trajectory estimation
                  relying either on 2D or 3D laser scanners and show
                  that a 3D laser scanner substantially improved the
                  final results.},
  doi          = {10.5194/isprs-annals-IV-2-W5-381-2019},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ls2019.pdf},
}  

@InProceedings{EGU2019,
  author = 	  {P. Torrese and A. Pio Rossi and V. Unnithan and
                  D. Borrmann and H. Lauterbach and E. Luzzi and
                  R. Pozzobon and F. Sauro and L. Bessone and
                  A. N{\"u}chter},
  title = 	  {{Imaging the subsurface of planetary volcanic
                  analogues using ambient seismic noise data at the
                  Tinguatón Volcano (Lanzarote, Canary Islands)}},
  booktitle = {Proceedings of the EGU General Assembly 2019, Poster:
                  New mission concepts, enabling technologies and
                  terrestrial analogue studies for planetary
                  exploration},
  year = 	  {2019},
  number = 	  {EGU2018-18492},
  month = 	  {April},
  address =   {Vienna, Austria},
  url       = {https://meetingorganizer.copernicus.org/EGU2019/EGU2019-18492.pdf},
}


@INPROCEEDINGS{SMGM_2019, 
  author =    {E. {Dumic} and A. {Bjelopera} and A. {N{\"u}chter}}, 
  booktitle = {Proceedings of the 2nd International Colloquium on Smart
               Grid Metrology (SMAGRIMET''19)}, 
  title =     {{Projection based dynamic point cloud compression using 3DTK
               toolkit and H.265/HEVC}}, 
  year =      {2019}, 
  pages =     {1--4},
  publisher = {IEEE Xplore},
  abstract =  {This paper presents novel compression method for dynamic
                  point clouds based on projections and the H.265/HEVC
                  video coder. We used 3DTK - The 3D Toolkit to create
                  equirect-angular projection images and x265 as
                  H.265/HEVC coder, to compress and extract created
                  projection images. Compression was introduced in
                  3DTK generated projection image size (differ-ent
                  pixel size, but compatible with later video
                  compression), as well as lossless/lossy video
                  compression. Visual inspection shows better results
                  for compression only using different projection
                  resolution, with lossless video compression. Lossy
                  video compression adds noise and creates additional
                  points, resulting in lower visual quality.},
  url =      {https://robotik.informatik.uni-wuerzburg.de/telematics/download/smagrimet2019.pdf},
  doi =      {https://doi.org/10.23919/SMAGRIMET.2019.8720392}, 
  month =    {April},
  address =  {Split, Croatia},
}

@InProceedings{ICRAURP2019,
  author = 	  {M. Bleier and J. van der Lucht and A. N{\"u}chter},
  title = 	  {Towards an Underwater 3D Laser Scanning System for
                  Mobile Mapping},
  booktitle = {Proceedings of the IEEE ICRA Workshop on Underwater Robotic Perception},
  year = 	  {2019},
  month = 	  {May},
  address =   {Montreal, Canada},
  abstract     = {Digitizing archaeological or industrial sites on
                  land using standard methods of photogrammetry like
                  3D modeling from photos or laser scanning is well
                  understood.  In contrast, precise underwater
                  surveying with high resolution is still a complex
                  and difficult task.  In this paper, we present the
                  development and construction of a structured light
                  underwater laser scanning system and show first
                  results on applying the system for mobile scanning
                  in the water.  The laser scanner employs two line
                  lasers to project a cross on the scene.  This
                  enables mobile scanning in multiple directions and
                  provides an overlapping scan pattern, which is
                  exploited for trajectory optimization.  We describe
                  the image processing, calibration and 3D
                  reconstruction methods used for creating point
                  clouds using the system.  In experiments conducted
                  in a towing tank we demonstrate 3D scans captured by
                  rotating the scanner on a robotic joint and first
                  results of mobile scans acquired by moving the
                  scanner through the water along a linear
                  trajectory.},
   url         = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icraurp2019.pdf},
}

@InProceedings{3DTAGE2019,
  author       = {D. Borrmann and S. J{\"o}rissen and A. N{\"u}chter},
  title        = {{RADLER -- Ein Einrad als RADialer LasER Scanner}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2019, Jade Hochschule},
  pages        = {12--21},
  year         = {2019},
  month        = {February},
  abstract     = {Die Weiterentwicklung in der 3D-Messtechnik hat in
                  den letzten Jahren eine Vielzahl an
                  unterschiedlichen Messgeräten zu
                  3D-Umgebungserfassung hervorgebracht, jedes davon
                  mit seinen eigenen Vorzügen und Schwächen. Diese
                  Arbeit stellt ein modifiziertes Einrad vor, bei dem
                  ein an der Radachse befestigter 2D Laserscanner ein
                  radiales 3D Scanpattern erzeugt.  Dieses neuartige,
                  kostengünstige Messgerät verbindet die Vorteile von
                  radgetriebenen Scangeräten mit denen von
                  Handscannern. Nach der Vorstellung des
                  Hardwareaufbaus und der Sensorintegration werden die
                  Ergebnisse anhand von drei Testszenarien ausgewertet
                  und mit den Daten eines terrestrischen
                  3D-Laserscanners verglichen.},
   url         = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/olb2019.pdf},
}


@InProceedings{ISPRS_3DUW,
  author       = {Bleier, M. and Almeida, C. and Ferreira, A. and Pereira, R. and Matias, B. and Almeida, J. and Pidgeon, J. and van der Lucht, J. and Schilling, K. and Martins, A. and Silva, E. and N{\"u}chter, A.},
  title        = {{3D UNDERWATER MINE MODELLING IN THE VAMOS PROJECT}},
  booktitle    = {Proceedings of the 2nd ISPRS International Workshop
                  Underwater 3D Recording \& Modelling: A tool for modern
			   applications and CH recording},
  year         = {2019},
  pages        = {105--112},
  series       = {ISPRS Archives Photogrammetry and Remote Senssing
                  Spatial Information Science, Volume XLII-2/W10},
  address      = { Limassol, Cyprus},
  month        = {May},
  abstract     = {The project Viable Alternative Mine Operating System
                  (VAMOS) develops a novel underwater mining technique
                  for extracting inland mineral deposits in flooded
                  open-cut mines. From a floating launch and recovery
                  vessel a remotely-operated underwater mining vehicle
                  with a roadheader cutting machine is deployed. The
                  cut material is transported to the surface via a
                  flexible riser hose. Since there is no direct
                  intervisibility between the operator and the mining
                  machine, the data of the sensor systems can only be
                  perceived via a computer interface. Therefore, part
                  of the efforts in the project focus on enhancing the
                  situational awareness of the operator by providing a
                  3D model of the mine combined with representations
                  of the mining equipment and sensor data. We present
                  a method how a positioning and navigation system,
                  perception system and mapping system can be used to
                  create a replica of the physical system and mine
                  environment in Virtual Reality (VR) in order to
                  assist remote control. This approach is beneficial
                  because it allows visualizing different sensor
                  information and data in a consistent interface, and
                  enables showing the complete context of the mining
                  site even if only part of the mine is currently
                  observed by surveying equipment. We demonstrate how
                  the system is used during tele-operation and show
                  results achieved during the field trials of the
                  complete system in Silvermines, Ireland.},
  doi          = {10.5194/isprs-archives-XLII-2-W10-39-2019},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/u3drm2019.pdf},
}

@Article{AVN2019,
  author       = {J. van der Lucht and M. Bleier and F. Leutert and K. Schilling and A. N{\"u}chter},
  title        = {{Korrektur der Brechung an der Wasseroberfl{\"a}che beim triangulationsbasierten 3D-Laserscannen}},
  journal      = {Allgemeine Vermessungs-Nachrichten (AVN)},
  year         = {2019},
  volume       = {126},
  number       = {3},
  pages        = {43--52},
  month        = {March},
  url          = {},
  abstract     = {Die vorliegende Arbeit besch{\"a}ftigt sich mit der
                  Korrektur der Brechung an der Wasseroberfl{\"a}che beim
                  triangulationsbasierten 3D Laserscannen. Hierzu
                  wurde eine Methode entwickelt, um mit einem
                  Structured Light (SL) System 3D-Daten von teilweise
                  mit Wasser bedeckten Strukturen anzufertigen und die
                  dabei entstehende Brechung an der Wasseroberfl{\"a}che
                  zu korrigieren. Diese wurde anschließend in einem
                  Versuchsaufbau evaluiert. Der Scanner wurde dabei an
                  einem KUKA KR-16 Manipulatorarm befestigt, um den
                  Scanner gleichm{\"a}ßig, definiert und wiederholbar zu
                  bewegen. Die Bewegungen des Scanners wurden dabei
                  durch ein externes Trackingsystem erfasst. Ebenfalls
                  wurde bei diesen Versuchen der Einfluss
                  verschiedener Einstrahlwinkel betrachtet. Zu diesem
                  Zweck wurde der Scanner in verschiedenen Winkeln
                  relativ zur Wasseroberfl{\"a}che positioniert. Durch die
                  entwickelte Methode konnten Fehler durch die
                  Brechung an der Wasseroberfl{\"a}che erfolgreich
                  korrigiert werden. Außerdem konnte die Lage der
                  Wasseroberfl{\"a}che ohne externe Markierungen aus den
                  3D-Daten bestimmt werden.
			   },
}

@InCollection{Geomatics2019,
  author = 	  {A. N{\"u}chter},
  title = 	  {Position and orientation of sensors for unmanned vehicle systems},
  booktitle = 	  {Unmanned Vehicle Systems for Geomatics -- Towards Robotic Mapping},
  publisher = {Whittles Publishing},
  year = 	  {2019},
  editor = 	  {P. Patias and C. Armenakis},
  OPTpages = 	  {},
}

@InProceedings{ISER2018,
  author       = {D. Borrmann and S. J{\"o}rissen and A. N{\"u}chter},
  title        = {{RADLER - A RADial LasER scanning device}},
  booktitle    = {Proceedings of the 16th International Symposium of
                  Experimental Robotics (ISER '18)},
  year         = {2018},
  series       = {Springer Tracts in Advanced Robotics},
  address      = {Buenos Aires, Argentina},
  month        = {November},
  abstract     = {Mobile scanning, i.e., the practice of mounting
                  laser scanners on moving platforms is an efficient
                  way to acquire accurate and dense 3D point clouds of
                  outdoor environments for urban and regional planning
                  and architecture. The mobile scenario puts high
                  requirements on the accuracy of the calibration of
                  the measurement system, as small calibration
                  inaccuracies lead to large errors in the resulting
                  point cloud. We propose a novel algorithm for the
                  calibration of a mobile scanning system that
                  estimates the calibration parameters for all sensor
                  components simultaneously without relying on
                  additional hardware. We evaluate the calibration
                  algorithm on several real world data sets where
                  ground truth is available via an accurate geodetic
                  model.},
pages          = {655--664},
url            = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iser2018.pdf},
doi            = {10.1007/978-3-030-33950-0_56},
}

% --- 2019 ---

@InProceedings{EI2019,
  author = 	  {S. J{\"o}rissen and M. Bleier and A. N{\"u}chter},
  title = 	  {{Self-calibrated Surface Acquisition for Integrated
                 Positioning Verification in Medical Applications}},
  booktitle =    {Proceedings of the IS\&T International Symposium on
                  Electronic Imaging Science and Technology},
  year = 	       {2019},
  series = 	  {Electronic Imaging},
  pages = 	  {353-1--353-8},
  month = 	  {January},
  address =      {San Francisco, CA, USA},
  publisher =    {Society for Imaging Science and Technology},
  doi          = {10.2352/ISSN.2470-1173.2019.4.PMII-353},
  abstract     = {This paper presents a novel approach for a position
                  verification system in medical applications. By
                  replacing the already existing cross line laser
                  projectors with galvo- or MEMS-based projectors and
                  utilizing the surveillance cameras, a
                  self-calibration of the system is performed and
                  surface acquisition for positioning verification is
                  demonstrated. The functionality is shown by
                  analyzing the radii of calibration spheres and
                  determining the quality of the captured surface with
                  respect to a reference model. The paper focuses on
                  the demonstration with one pair of camera and
                  projector but can also be extended to a
                  multi-camera-projector system, as present in
                  treatment rooms. Compared to other systems, this
                  approach does not need external hardware and is thus
                  space and cost efficient.},
url            = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ei2019.pdf},  
}

% --- 2018 ---

@InProceedings{IAA2018,
  author = 	  {K. Schilling and T. Tzschichholz and I. Motroniuk
                  and A. Aumann and I. Mammadov and O. Ruf and
                  C. Schmidt and N. Appel and A. Kleinschrodt and S.
                  Montenegro and A. N{\"u}chter},
  title = 	  {TOM: A formation for photogrammetric earth
                  observation by three cubesats},
  booktitle = {Proceedings IAA-ASS-18 : International Academy of
                  Astronautics},
  year = 	  {2018},
  volume = 	  {163},
  number = 	  {IAA-AAS-CU-17-08-02},
  series = 	  {Advances in the Astronautical Sciences 4th IAA Dynamics and Control of Space Systems Conference},
  pages = 	  {1--14},
  month = 	  {May},
  address =   {Changsha, China},
  OPTorganization = {},
  url = {http://www.univelt.com/book=6516},
  publisher = {Univelt, Inc.},
}


@INPROCEEDINGS{IROS2018, 
  author     = {J. Almeida and A. Martins and C. Almeida and A. Dias and
                B. Matias and A. Ferreira and P. Jorge and R. Martins and
			 M. Bleier and A. N{\"u}chter and J. Pidgeon and S. Kapusniak
			 and E. Silva}, 
booktitle    = {IEEE/RSJ International Conference on Intelligent Robots and
               Systems (IROS '18)}, 
title        = {{Positioning. Navigation and Awareness of the !VAMOS!
                Underwater Robotic Mining System}}, 
year         = {2018},
abstract     = {This paper presents the positioning, navigation and
                  awareness (PNA) system developed for the Underwater
                  Robotic Mining System of the !VAMOS! project [1]. It
                  describes the main components of the !VAMOS! system,
                  the PNA sensors in each of those components, the
                  global architecture of the PNA system, and its main
                  subsystems: Position and Navigation, Realtime Mine
                  Modeling, 3D Virtual reality HMI and Real-time grade
                  system. General results and lessons learn during the
                  first mining field trial in Lee Moor, Devon, UK
                  during the months of September and October 2017 are
                  presented.},
pages        = {1527--1533}, 
doi          = {10.1109/IROS.2018.8593869},
url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iros2018.pdf},
month        = {October},
address      = {Madrid, Spain},
}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


@INPROCEEDINGS{SSRR2018_RTM, 
  author     = {H. A. Lauterbach and A. N{\"u}chter}, 
  booktitle  = {Proceedings of the 16th IEEE International Symposium on
                  Safety, Security, and Rescue Robotics (SSRR '18)}, 
  title      = {{Preliminary Results on Instantaneous UAV-Based 3D
                  Mapping for Rescue Applications}}, 
  year       = {2018}, 
  pages      = {1--2}, 
  abstract   = {This report presents a novel approach to generate a 3D
                  map with an UAV while flying over a disaster scene
                  with the aim to present the map instantaneously to
                  the operator and the rescue workers. Our approach
                  extends the well-known ICP algorithm.}, 
  doi        = {10.1109/SSRR.2018.8468625}, 
  url        = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ssrr2018_rtm.pdf},
  month      = {August},
  address    = {Philadelphia, PA, USA},
}


@INPROCEEDINGS{SSRR2018_SFM, 
  author     = {A. Martell and H. A. Lauterbach and K. Schilling and
                  A. N{\"u}chter}, 
  booktitle  = {Proceedings of the 16th IEEE International Symposium on
                  Safety, Security, and Rescue Robotics (SSRR '18)}, 
  title      = {{Benchmarking Structure from Motion Algorithms of
                  Urban Environments with Applications to
                  Reconnaissance in Search and Rescue Scenarios}},
  abstract   = {Structure from motion is a common approach to generate
                  3D models of objects and structures. The ease of the
                  data acquisition and the wide selection of available
                  algorithms makes the technique easily
                  accessible. Previous benchmarks on the topic have
                  been focused on scanning small structures, specially
                  for archaeology, or have been limited to single or
                  very few algorithms. In this work different
                  algorithms are benchmarked regarding accuracy and
                  processing time for datasets acquired in urban
                  environments, with the goal of analyzing the
                  feasibility of utilizing this technique on search
                  and rescue operations. Real-world rescue scenarios
                  are demanding due to the presence of challenging
                  surfaces and smoke.},
  year       = {2018},  
  pages      = {1--7}, 
  doi        = {10.1109/SSRR.2018.8468612},
  url        = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ssrr2018_sfm.pdf},
  month      = {August},
  address    = {Philadelphia, PA, USA},
}


@article{JPRS_2018,
  title = "Removing non-static objects from 3D laser scan data",
  journal = "ISPRS Journal of Photogrammetry and Remote Sensing (JPRS)",
  volume = "143",
  pages = "15--38",
  year = "2018",
  issn = "0924-2716",
  doi = "10.1016/j.isprsjprs.2018.05.019",
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/jprs2018.pdf},
  author = "Johannes Schauer and Andreas N{\"u}chter",
  abstract = "For the purpose of visualization and further
                  post-processing of 3D point cloud data, it is often
                  desirable to remove moving objects from a given data
                  set. Common examples for these moving objects are
                  pedestrians, bicycles and motor vehicles in outdoor
                  scans or manufactured goods and employees in indoor
                  scans of factories. We present a new change
                  detection method which is able to partition the
                  points of multiple registered 3D scans into two
                  sets: points belonging to stationary (static)
                  objects and points belonging to moving (dynamic)
                  objects. Our approach does not require any object
                  detection or tracking the movement of objects over
                  time. Instead, we traverse a voxel grid to find
                  differences in volumetric occupancy for “explicit”
                  change detection. Our main contribution is the
                  introduction of the concept of “point shadows” and
                  how to efficiently compute them. Without them, using
                  voxel grids for explicit change detection is known
                  to suffer from a high number of false positives when
                  applied to terrestrial scan data. Our solution
                  achieves similar quantitative results in terms of
                  F1-score as competing methods while at the same time
                  being faster."
}

@InProceedings{3DTAGE2018,
  author       = {J. van der Lucht and M. Bleier and F. Leutert
                  and K. Schilling and A. N{\"u}chter},
  title        = {{Korrektur der Brechung an der Wasseroberfl{\"a}che beim triangulationsbasierten 3D-Laserscannen}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2018, Jade Hochschule},
  pages        = {87--102},
  year         = {2018},
  month        = {February},
  abstract     = {Die vorliegende Arbeit besch{\"a}ftigt sich mit der
                  Korrektur der Brechung an der Wasseroberfl{\"a}che beim
                  triangulationsbasierten 3D Laserscannen. Hierzu
                  wurde eine Methode entwickelt, die es erm{\"o}glicht,
                  mit einem Structured Light (SL) System 3D-Daten von
                  teilweise mit Wasser bedeckten Strukturen
                  anzufertigen und die dabei entstehende Brechung an
                  der Wasseroberfl{\"a}che zu korrigieren. Diese wurde
                  anschließend in einem Versuchsaufbau evaluiert.  Der
                  Scanner wurde dabei an einem KUKA KR-16
                  Manipulatorarm befestigt, was die M{\"o}glichkeit bietet
                  den Scanner gleichm{\"a}ßig, definiert und wiederholbar
                  zu bewegen. Die Bewegungen des Scanners wurden dabei
                  durch ein externes Trackingsystem erfasst. Ebenfalls
                  wurde bei diesen Versuchen der Einfluss
                  verschiedener Einstrahlwinkel betrachtet. Zu diesem
                  Zweck wurde der Scanner in verschiedenen Winkeln
                  relativ zur Wasseroberfl{\"a}che bewegt. Durch die
                  entwickelte Methode konnten Fehler durch die
                  Brechung an der Wasseroberfl{\"a}che erfolgreich
                  korrigiert werden. Außerdem konnte die Lage der
                  Wasseroberfl{\"a}che ohne externe Markierungen aus den
                  3D-Daten bestimmt werden.},
   url         = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/olb2018.pdf},
}


@InProceedings{COMMII2018,
  author       = {J. van der Lucht and M. Bleier and F. Leutert
                  and K. Schilling and A. N{\"u}chter},
  title        = {{Structured-light based 3D laser scanning of semi-submerged
                  structures}},
  booktitle    = {Proceedings of the Technical Commision II Mid-term Symposium 
                  ``Towards Photogrammetry 2020''},
  series       = {ISPRS Annals Photogrammetry and Remote Sensing,
                  Spatial Inf. Sci., IV-2},
  year         = {2018},
  month        = {June},
  pages        = {287--294},
  address      = {Riva del Garda, Italy},
  abstract     = {In this work we look at 3D acquisition of
                  semi-submerged structures with a triangulation based
                  underwater laser scanning system. The motivation is
                  that we want to simultaneously capture data above
                  and below water to create a consistent model without
                  any gaps. The employed structured light scanner
                  consist of a machine vision camera and a green line
                  laser. In order to reconstruct precise surface
                  models of the object it is necessary to model and
                  correct for the refraction of the laser line and
                  camera rays at the water-air boundary.  We derive a
                  geometric model for the refraction at the air-water
                  interface and propose a method for correcting the
                  scans. Furthermore, we show how the water surface is
                  directly estimated from sensor data. The approach is
                  verified using scans captured with an industrial
                  manipulator to achieve reproducable scanner
                  trajectories with different incident angles. We show
                  that the proposed method is effective for refractive
                  correction and that it can be applied directly to
                  the raw sensor data without requiring any external
                  markers or targets.},
  doi          = {10.5194/isprs-annals-IV-2-287-2018},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/isprs-commision2-symposium2018.pdf},
}

@Article{MDPI2018,
  author = 	  {C. Pfitzner and S. May and A. N{\"u}chter},
  title = 	  {{Body Weight Estimation for Dose-Finding and Health Monitoring of Lying, Standing and Walking Patients Based on RGB-D Data}},
  journal = 	  {Sensors},
  year = 		  {2018},
  volume = 	  {18},
  number = 	  {5},
  OPTpages = 	  {},
  month = 	  {April},
  doi =          {10.3390/s18051311},
  url =          {https://robotik.informatik.uni-wuerzburg.de/telematics/download/mpdi2018.pdf},
  abstract =    {This paper describes the estimation of the body
                  weight of a person in front of an RGB-D camera. A
                  survey of different methods for body weight
                  estimation based on depth sensors is given. First,
                  an estimation of people standing in front of a
                  camera is presented. Second, an approach based on a
                  stream of depth images is used to obtain the body
                  weight of a person walking towards a sensor. The
                  algorithm first extracts features from a point cloud
                  and forwards them to an artificial neural network
                  (ANN) to obtain an estimation of body
                  weight. Besides the algorithm for the estimation,
                  this paper further presents an open-access dataset
                  based on measurements from a trauma room in a
                  hospital as well as data from visitors of a public
                  event. In total, the dataset contains 439
                  measurements. The article illustrates the efficiency
                  of the approach with experiments with persons lying
                  down in a hospital, standing persons, and walking
                  persons. Applicable scenarios for the presented
                  algorithm are body weight-related dosing of
                  emergency patients.},
}

@Article{ICRA2018,
  author = 	  {J. Schauer and A. N{\"u}chter},
  title = 	  {{The Peopleremover --- Removing Dynamic Objects From
                  3-D Point Cloud Data by Traversing a Voxel Occupancy
                  Grid}},
  journal = 	  {IEEE Robotics and Automation Letters (RAL},
  year = 		  {2018},
  volume = 	  {3},
  number = 	  {3},
  pages = 	  {1679--1686},
  month = 	  {July},
  url   = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icra2018.pdf},
  doi   = {10.1109/LRA.2018.2801797},
  abstract = {Even though it would be desirable for most
                  postprocessing purposes to obtain a point cloud
                  without moving objects in it, it is often
                  impractical or downright impossible to free a scene
                  from all nonstatic clutter. Outdoor environments
                  contain pedestrians, bicycles, and motor vehicles
                  which cannot easily be stopped from entering the
                  sensor range and indoor environments like factory
                  production lines cannot be evacuated due to
                  production losses during the time of the scan. In
                  this letter, we present a solution to this problem
                  that we call the "peopleremover." Given a registered
                  set of 3-D point clouds, we build a regular voxel
                  occupancy grid and then traverse it along the lines
                  of sight between the sensor and the measured points
                  to find the differences in volumetric occupancy
                  between the scans. Our approach works for scan
                  slices from mobile mapping as well as for the more
                  general scenario of terrestrial scan data. The
                  result is a clean point cloud free of dynamic
                  objects.},
}

@InProceedings{EGU2018_1,
  author = 	  {A. Pio Rossi and V. Unnithan and P. Torrese and
                  D. Borrmann and A. N{\"u}chter and H. Lauterbach and
                  G. Ortenzi and T. J{\"a}hrig and F. Sohl},
  title = 	  {{Augmented field Geology and Geophysics for Planetary
                  Analogues}},
  booktitle = {Proceedings of the EGU General Assembly 2018, Pico
                  session: Planetary geobiological analogs for Mars
                  and beyond: Field, lab and simulations},
  year = 	  {2018},
  volume = 	  {20},
  number = 	  {EGU2018-6389},
  month = 	  {April},
  address =   {Vienna, Austria},
  url       = {https://meetingorganizer.copernicus.org/EGU2018/EGU2018-6389.pdf},
}

@InProceedings{EGU2018_2,
  author = 	  {P. Torrese and A. Pio Rossi and V. Unnithan and D. Borrmann and H. Lauterbach and G. Ortenzi and T. J{\"a}hrig and R. Pozzobon and F. Sauro and T. Santagata and A. N{\"u}chter and F. Sohl},
  title = 	  {{Reconstructing the subsurface of planetary volcanic
                  analogues: ERT imaging of Lanzarote lava tubes
                  complemented with drone stereogrammetry, surface and
                  in-cave LiDAR and seismic investigations (Poster)}},
  booktitle = {Proceedings of the EGU General Assembly 2018, Pico
                  session: Planetary geobiological analogs for Mars
                  and beyond: Field, lab and simulations},
  year = 	  {2018},
  volume = 	  {20},
  number = 	  {EGU2018-14285},
  month = 	  {April},
  address =   {Vienna, Austria},
  url       = {https://meetingorganizer.copernicus.org/EGU2018/EGU2018-14285.pdf},
}

@InCollection{MDPIBOOK2018,
  author = 	  {A. N{\"u}chter and M. Bleier and J. Schauer and P. Janotta},
  editor = 	  {F. Remondino and A. Georgopoulos and D. Gonzalez-Aguilera and P. Agrafiotis},
  booktitle = 	  {Latest Developments in Reality-Based 3D Surveying and Modelling},
  title = 	  {Continuous-Time SLAM—Improving Google’s Cartographer 3D Mapping},
  publisher = 	  {MDPI},
  year = 		  {2018},
  address =      {Basel, Switzerland},
  month = 	  {January},
  pages = 	  {53--73},
  abstract     = {This paper shows how to use the result of Google’s
                  simultaneous localization and mapping (SLAM)
                  solution, called Cartographer, to bootstrap a
                  continuous-time SLAM algorithm that was developed by
                  the authors and presented in previous
                  publications. The presented approach optimizes the
                  consistency of the global point cloud, and thus
                  improves on Google’s results.  Algorithms and data
                  from Google are used as input for the
                  continuous-time SLAM software. In preceding work,
                  the continuous-time SLAM was successfully applied to
                  a similar backpack system which delivers consistent
                  3D point clouds even in the absence of an
                  IMU. Continuous-time SLAM means that the trajectory
                  of a mobile mapping system is treated in a
                  semi-rigid fashion, i.e., the trajectory is deformed
                  to yield a consistent 3D point cloud of the measured
                  environment.},
  doi          = {10.3390/books978-3-03842-685-1/4},
  url          = {http://www.mdpi.com/books/pdfdownload/article/515/1},
}

% --- 2017 ---

@InProceedings{LC2017,
  author       = {M. Bleier and A. N{\"u}chter},
  title        = {Towards robust self-calibration for handheld 3D line laser scanning},
  booktitle    = {Proceedings of LowCost 3D 2017},
  year         = {2017},
  series       = {ISPRS Int. Archives Photogrammetry and Remote Sensing, Spatial Inf. Sci., XLII-2/W8},
  pages        = {31--36},
  month        = {November},
  address      = {Hamburg, Germany},
  abstract     = {This paper studies self-calibration of a structured
                  light system, which reconstructs 3D information
                  using video from a static consumer camera and a
                  handheld cross line laser projector. Intersections
                  between the individual laser curves and geometric
                  constraints on the relative position of the laser
                  planes are exploited to achieve dense 3D
                  reconstruction. This is possible without any prior
                  knowledge of the movement of the projector. However,
                  inaccurrately extracted laser lines introduce noise
                  in the detected intersection positions and therefore
                  distort the reconstruction result. Furthermore, when
                  scanning objects with specular reflections, such as
                  glossy painted or metalic surfaces, the reflections
                  are often extracted from the camera image as
                  erroneous laser curves. In this paper we investiagte
                  how robust estimates of the parameters of the laser
                  planes can be obtained despite of noisy detections.},
  doi          = {10.5194/isprs-archives-XLII-2-W8-31-2017},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/lc2017.pdf},
}

@InProceedings{LS2017,
  author       = {B. Koch and R. Leblebici and A. Martell and
                  S. J{\"o}rissen and K. Schilling and A. N{\"u}chter},
  title        = {Evaluating continuous-time SLAM using a predefined
                  trajectory provided by a robotic arm},
  booktitle    = {Proceedings of the ISPRS Geospatial Week 2017, Laserscanning 2017},
  year         = {2017},
  series       = {ISPRS Annals Photogrammetry and Remote Sensing,
                  Spatial Inf. Sci., IV-2/W4},
  pages        = {17--23},
  month        = {September},
  address      = {Wuhan, China},
  abstract     = {Recently published approaches to SLAM algorithms
                  process laser sensor measurements and output a map
                  as a point cloud of the environment. Often the
                  actual precision of the map remains unclear, since
                  SLAMalgorithms apply local improvements to the
                  resulting map. Unfortunately, it is not trivial to
                  compare the performance of SLAMalgorithms
                  objectively, especially without an accurate ground
                  truth. This paper presents a novel benchmarking
                  technique that allows to compare a precise map
                  generated with an accurate ground truth trajectory
                  to a map with a manipulated trajectory which was
                  distorted by different forms of noise. The accurate
                  ground truth is acquired by mounting a laser scanner
                  on an industrial robotic arm. The robotic arm is
                  moved on a predefined path while the position and
                  orientation of the end-effector tool are
                  monitored. During this process the 2D profile
                  measurements of the laser scanner are recorded in
                  six degrees of freedom and afterwards used to
                  generate a precise point cloud of the test
                  environment. For benchmarking, an offline
                  continuous-time SLAM algorithm is subsequently
                  applied to remove the inserted distortions. Finally,
                  it is shown that the manipulated point cloud is
                  reversible to its previous state and is slightly
                  improved compared to the original version, since
                  small errors that came into account by imprecise
                  assumptions, sensor noise and calibration errors are
                  removed as well.},
  doi          = {10.5194/isprs-annals-IV-2-W4-91-2017},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ls2017.pdf},
}  

@Article{GIM2017,
  author       = {V. Lehtola and H. Kaartinen and A. N{\"u}chter},
  title        = {Autonomous 3D Modelling of Indoor Spaces},
  journal      = {GIM International},
  year         = {2017},
  volume       = {31},
  number       = {10},
  pages        = {20--23},
  month        = {October},
  abstract     = {Mobile scanning can be an equally accurate yet more
                  cost-effective solution than traditional terrestrial
                  laser scanning done with tripods. To succeed,
                  however, mobile scanners not only require a suitable
                  combination of sensors, but also reliable and
                  continuous knowledge about where the scanners are
                  located and the direction in which they are pointing
                  during scanning. There are multiple ways to achieve
                  this, which has led to the development of various
                  scientific and commercial solutions. This article
                  compares several mobile scanning solutions for 3D
                  modelling of indoor spaces and highlights their
                  strengths and weaknesses.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/gim2017.pdf},
}

@InProceedings{RTM2017,
  author       = {M. Bleier and A. Dias and A. Ferreira and J. Pidgeon
                  and J. Almeida and E. Silva and K. Schilling and
                  A. N{\"u}chter},
  title        = {{Real-time 3D Mine Modelling in the \textexclamdown VAMOS! Project}},
  booktitle    = {Real Time Mining},
  year         = {2017},
  editor       = {M. Buxton and J. Benndorf},
  pages        = {91--102},
  month        = {October},
  address      = {Amsterdam, The Netherlands},
  publisher    = {Wagner Digitaldruck und Medien GmbH},
  abstract     = {The project Viable Alternative Mine Operating System
                  (\textexclamdown VAMOS!) develops a new safe, clean
                  and low visibility mining technique for excavating
                  raw materials from submerged inland mines. During
                  operations, the perception data of the mining
                  vehicle can only be communicated to the operator via
                  a computer interface. In order to assist remote
                  control and facilitate assessing risks a detailed
                  view of the mining process below the water surface
                  is necessary. This paper presents approaches to
                  real-time 3D reconstruction of the mining
                  environment for immersive data visualisation in a
                  virtual reality environment to provide advanced
                  spatial awareness. From the raw survey data a more
                  consistent 3D model is created using post-processing
                  techniques based on a continuous-time simultaneous
                  localization and mapping (SLAM) solution. Signed
                  distance function (SDF) based mapping is employed to
                  fuse the measurements from multiple views into a
                  single representation and reduce sensor noise.
                  Results of the proposed techniques are demonstrated
                  on a dataset captured in an sub- merged inland
                  mine.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/rtm2017.pdf},
}

@InProceedings{RTM2017slam,
  author       = {A. N{\"u}chter and J. Elseberg and P. Janotta},
  title        = {{Towards Mobile Mapping of Underground Mines}},
  booktitle    = {Real Time Mining},
  year         = {2017},
  editor       = {M. Buxton and J. Benndorf},
  month        = {October},
  address      = {Amsterdam, The Netherlands},
  publisher    = {Wagner Digitaldruck und Medien GmbH},
  pages        = {27--38},
  abstract     = {Mobile laser scanning systems automate the
                  acquisition of 3D point clouds of environments. The
                  mapping systems are commonly mounted on cars or
                  ships. This paper presents a flexible mapping
                  solution mounted on an underground vehicle, that is
                  able to map underground mines in 3D in walking
                  speeds. A clever choice of hard- and software
                  enables the system to generate 3D maps without using
                  GPS (global positioning system) information and
                  without relying on highly expensive IMU (inertial
                  measurement unit) systems.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/RTM2017slam.pdf},
}

@Article{REMSEN2017,
  author       = {V. Lehtola and H. Kaartinen and A. N{\"u}chter and
                  R. Kaijaluoto and A. Kukko and P. Litkey and
                  E. Honkavaara and T. Rosnell and M. Vaaja and
                  J.-P. Virtanen and et al.},
  title        = {{Comparison of the Selected State-Of-The-Art 3D
                  Indoor Scanning and Point Cloud Generation Methods}},
  journal      = {Remote Sensing},
  year         = {2017},
  pages        = {796},
  month        = {August},
  abstract     = {Accurate three-dimensional (3D) data from indoor
                  spaces are of high importance for various
                  applications in construction, indoor navigation and
                  real estate management. Mobile scanning techniques
                  are offering an efficient way to produce point
                  clouds, but with a lower accuracy than the
                  traditional terrestrial laser scanning (TLS). In
                  this paper, we first tackle the problem of how the
                  quality of a point cloud should be rigorously
                  evaluated. Previous evaluations typically operate on
                  some point cloud subset, using a manually-given
                  length scale, which would perhaps describe the
                  ranging precision or the properties of the
                  environment. Instead, the metrics that we propose
                  perform the quality evaluation to the full point
                  cloud and over all of the length scales, revealing
                  the method precision along with some possible
                  problems related to the point clouds, such as
                  outliers, over-completeness and misregistration. The
                  proposed methods are used to evaluate the end
                  product point clouds of some of the latest
                  methods. In detail, point clouds are obtained from
                  five commercial indoor mapping systems, Matterport,
                  NavVis, Zebedee, Stencil and Leica Pegasus:
                  Backpack, and three research prototypes, Aalto VILMA,
			   FGI Slammer and the W{\"u}rzburg backpack. These are
                  compared against survey-grade TLS point clouds
                  captured from three distinct test sites that each
                  have different properties. Based on the presented
                  experimental findings, we discuss the properties of
                  the proposed metrics and the strengths and
                  weaknesses of the above mapping systems and then
                  suggest directions for future research.},
  doi          = {10.3390/rs9080796},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/remotesensing2017.pdf},
}

@InProceedings{3DTAGE2017,
  author       = {O. Struckmeier and D. Borrmann and A. N{\"u}chter},
  title        = {{Teach-In f{\"u}r die 3D-Scan Akquise mit einem
                  Roboter}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2017, Jade Hochschule},
  pages        = {108--119},
  year         = {2017},
  month        = {February},
  abstract     = {Die 3D-Erfassung einer kompletten Umgebung mittels
                  3D-Laserscanner stellt abh{\"a}ngig von der zu
                  scannenden Umgebung und dem Scanner einen hohen
                  Zeitaufwand f{\"u}r einen menschlichen Operator dar.
                  Der Scanner muss an die einzelnen Scanpositionen
                  bewegt und dort verortet werden.  Mit steigender
                  Qualit{\"a}t der Messung nimmt zudem die Dauer der
                  einzelnen Scanvorg{\"a}nge zu. In diesem Beitrag wird
                  ein Teach-In Ansatz vorgestellt und evaluiert, der
                  den manuelle n Vorgang verk{\"u}rzt. Dabei f{\"u}hrt ein
                  Roboter die vom Vermesser geplanten und
                  eingespeicherten zeitintensiven Schritte automatisch
                  durch und entlastet somit den Bediener.},
   url         = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/olb2017.pdf},
}


@InProceedings{ICAR2017,
  author       = {R. Koch and S. May and A. N{\"u}chter},
  title        = {{Effective Distinction Of Transparent And Specular
                  Reflective Objects In Point Clouds Of A Multi-Echo
                  Laser Scanner}},
  booktitle    = {Proceedings of the 18th IEEE International
                  Conference on Advanced Robotics (ICAR '17)},
  pages        = {566--571},
  month        = {July},
  address      = {Hong Kong, China},
  year         = {2017},
  Abstract     = {A favoured sensor for mapping is a 3D laser scanner
                  since it allows a wide scanning range, precise
                  measurements, and is usable indoor and
                  outdoor. Hence, a mapping module delivers detailed
                  and high resolution maps which makes it possible to
                  navigate safely. Difficulties result from
                  transparent and specular reflective objects which
                  cause erroneous and dubious measurements. At such
                  objects, based on the incident angle, measurements
                  result from the object surface, an object behind the
                  transparent surface, or an object mirrored with
                  respect to the reflective surface. This paper
                  describes an enhanced Pre-Filter-Module to
                  distinguish between these cases. Two experiments
                  demonstrate the usability and show that for single
                  scans the identification of mentioned objects in 3D
                  is possible. The first experiment was made in an
                  empty room with a mirror. The second experiment was
                  made in a stairway which contains a glass
                  door. Further, results show that a discrimination
                  between a specular reflective and a transparent
                  object is possible. Especially for transparent
                  objects the detected size is restricted to the
                  incident angle. That is why future work concentrates
                  on implementing a post-filter module. Gained
                  experience shows that collecting the data of
                  multiple scans and postprocess them as soon as the
                  object was bypassed will improve the map.},
  doi          = {10.1109/ICAR.2017.8023667},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icar2017.pdf}
}


@inproceedings{SPIE2017,
  author       = { R. Koch and L.  B{\"o}ttcher and M. Jahrsd{\"o}rfer
                  and J. Maier and M. Trommer and S. May and
                  A. N{\"u}chter},
  title        = {{Out of lab calibration of a rotating 2D scanner for
                  3D mapping}},
  booktitle    = {Proceedings of the SPIE optical metrology,
                  Videometrics, Range Imaging, and Applications},
  volume       = {10332},
  pages        = {10332 - 10332 - 8},
  address      = {Munich, Germany},
  month        = {June},
  year         = {2017},
  abstract     = {Mapping is an essential task in mobile robotics. To
                  fulfil advanced navigation and manipulation tasks a
                  3D representation of the environment is
                  required. Applying stereo cameras or Time-of-flight
                  cameras (TOF cameras) are one way to archive this
                  requirement. Unfortunately, they suffer from
                  drawbacks which makes it difficult to map
                  properly. Therefore, costly 3D laser scanners are
                  applied. An inexpensive way to build a 3D
                  representation is to use a 2D laser scanner and
                  rotate the scan plane around an additional axis. A
                  3D point cloud acquired with such a custom device
                  consists of multiple 2D line scans. Therefore the
                  scanner pose of each line scan need to be determined
                  as well as parameters resulting from a calibration
                  to generate a 3D point cloud. Using external sensor
                  systems are a common method to determine these
                  calibration parameters. This is costly and difficult
                  when the robot needs to be calibrated outside the
                  lab. Thus, this work presents a calibration method
                  applied on a rotating 2D laser scanner. It uses a
                  hardware setup to identify the required parameters
                  for calibration. This hardware setup is light,
                  small, and easy to transport. Hence, an out of lab
                  calibration is possible. Additional a theoretical
                  model was created to test the algorithm and analyse
                  impact of the scanner accuracy. The hardware
                  components of the 3D scanner system are an HOKUYO
                  UTM-30LX-EW 2D laser scanner, a Dynamixel
                  servo-motor, and a control unit. The calibration
                  system consists of an hemisphere. In the inner of
                  the hemisphere a circular plate is mounted. The
                  algorithm needs to be provided with a dataset of a
                  single rotation from the laser scanner. To achieve a
                  proper calibration result the scanner needs to be
                  located in the middle of the hemisphere. By means of
                  geometric formulas the algorithms determine the
                  individual deviations of the placed laser
                  scanner. In order to minimize errors, the algorithm
                  solves the formulas in an iterative process. First,
                  the calibration algorithm was tested with an ideal
                  hemisphere model created in Matlab. Second, laser
                  scanner was mounted differently, the scanner
                  position and the rotation axis was modified. In
                  doing so, every deviation, was compared with the
                  algorithm results. Several measurement settings were
                  tested repeatedly with the 3D scanner system and the
                  calibration system. The results show that the length
                  accuracy of the laser scanner is most critical. It
                  influences the required size of the hemisphere and
                  the calibration accuracy.},
 doi           = {10.1117/12.2270298},
 URL           = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/spie2017.pdf},
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@InProceedings{ICCA2017,
  author       = {J. Schauer and A. N{\"u}chter},
  title        = {{Digitizing automotive production lines without
                  interrupting assembly operations through an
                  automatic voxel-based removal of moving objects}},
  booktitle    = {Proceedings of the 13th IEEE International
                  Conference on Control and Automation (ICCA '17)},
  year         = {2017},
  pages        = {701--706},
  month        = {July},
  address      = {Ohrid, Macedonia},
  abstract     = {We present an efficient method to partition a point
                  cloud gathered through kinematic laser scanning into
                  static and dynamic points. The presented algorithm
                  utilizes a voxel grid data structure and uses a ray
                  intersection test to mark voxels as dynamic. The
                  algorithm does not require any ego-motion
                  estimations, computationally expensive object
                  recognition or tracking of moving objects over
                  time. It is easy to implement and can be executed on
                  many cores in parallel. We show the viability of
                  this approach by applying our algorithm to a dataset
                  that we gathered by mounting a FARO Focus3D Laser
                  scanner onto a skid which was then sent along a
                  production line for consumer car chassis in a
                  factory of the Volkswagen corporation. Since factory
                  operators are interested in acquiring digital models
                  of their production lines without suspending factory
                  operations, the resulting point cloud will contain
                  many dynamic objects like humans or other car
                  bodies. We show how our algorithm is able to
                  successfully remove these dynamic objects from the
                  resulting point cloud with minimal errors. Our
                  implementation is published under a free license as
                  part of 3DTK. },
  doi          = {10.1109/ICCA.2017.8003145},
  URL          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icca2017.pdf},
}


@InProceedings{WC2017_1,
  author       = {M. Bleier and A. Dias and A. Ferreira and J. Pidgeon
                  and J. M. Almeida and E. Silva and K. Schilling and
                  A. N{\"u}chter},
  title        = {{Signed Distance Function Based Surface
                  Reconstruction of a Submerged Inland Mine Using
                  Continuous-Time SLAM}},
  booktitle    = {Proceedings of the 20th World Congress of the
                  International Federation of Automatic Control (IFAC
                  WC '17)},
  OPTpages     = {},		   
  year         = {2017},
  month        = {July},
  address      = {Toulouse, France},
  abstract     = {The planning of mining operations in water filled
                  open-pit mines requires detailed bathymetry to
                  create a mine plan and assess the involved
                  risks. This paper presents post- processing
                  techniques for creating an improved 3D model from a
                  survey carried out using an autonomous surface
                  vehicle with a multibeam sonar and a GPS/INS
                  navigation system. Inconsistencies of the created
                  point cloud as a result of calibration errors or GPS
                  signal loss are corrected using a continuous-time
                  simultaneous localization and mapping (SLAM)
                  solution. Signed distance function based mapping is
                  employed to fuse the measurements from multiple runs
                  into a consistent representation and reduce sensor
                  noise. From the signed distance function model we
                  reconstruct a 3D surface mesh. We use this terrain
                  model to establish a virtual reality scene for
                  immersive data visualization of the mining
                  operations for testing and planing during
                  development. Results of the proposed approach are
                  demonstrated on a dataset captured in an abandoned
                  submerged inland mine.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iwc2017.pdf},
}


@InProceedings{WC2017_2,
  author       = {C. Pfitzner and S. May and A. N{\"u}chter},
  title        = {{Evaluation of Features from RGB-D Data for Human
                  Body Weight Estimation}},
  booktitle    = {Proceedings of the 20th World Congress of the
                  International Federation of Automatic Control (IFAC
                  WC '17)},
  year         = {2017},
  OPTpages     = {},
  month        = {July},
  address      = {Toulouse, France},
  abstract     = {Body weight is a crucial parameter when it comes to
                  drug or radiation dosing. In case of emergency
                  treatment time is short so that physicians estimate
                  the body weight by the visual appearance of a
                  patient. Further, visual body weight estimation
                  might be a feature for person identification. This
                  paper presents the anthropometric feature extraction
                  from RGB-D sensor data, recorded from frontal
                  view. The features are forwarded to an artificial
                  neural network for weight estimation. Experiments
                  with 233 people demonstrate the capability of
                  different features for body weight estimation. To
                  prove robustness against sensor modalities, a
                  structured light sensor is used, as well as a
                  time-of-flight sensor. An additional experiment
                  including temperature features from a thermal camera
                  improves the body weight estimation beyond.}, 
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iwc2017_1.pdf}
}


@InProceedings{3DARCH2017_1,
  author       = {A. N{\"u}chter and M. Bleier and J. Schauer and P. Janotta},
  title        = {{Improving Google's Cartographer 3D Mapping by
                  Continuous-Time SLAM}},
  booktitle    = {Proceedings of the 7th ISPRS International Workshop
                  3D-ARCH 2017: "3D Virtual Reconstruction and
                  Visualization of Complex Architectures"},
  year         = {2017},
  pages        = {543--549},
  series       = {ISPRS Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XLII/W3},
  address      = {Nafplio, Greece},
  month        = {March},
  abstract     = {This paper shows how to use the result of Google's
                  SLAM solution, called Cartographer, to bootstrap our
                  continuous-time SLAM algorithm. The presented
                  approach optimizes the consistency of the global
                  point cloud, and thus improves on Google’s
                  results. We use the algorithms and data from Google
                  as input for our continuous-time SLAM software. We
                  also successfully applied our software to a similar
                  backpack system which delivers consistent 3D point
                  clouds even in absence of an IMU.},
  doi          = {10.5194/isprs-archives-XLII-2-W3-543-2017},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3darch2017slam.pdf},
  
}


@InProceedings{3DARCH2017_2,
  author       = {M. Bleier and A. N{\"u}chter},
  title        = {{Low-cost 3D Laser Scanning in Air or Water Using
                  Self-calibrating Structured Light}},
  booktitle    = {Proceedings of the 7th ISPRS International Workshop
                  3D-ARCH 2017: "3D Virtual Reconstruction and
                  Visualization of Complex Architectures"},
  year         = {2017},
  pages        = {105--112},
  series       = {ISPRS Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XLII/W3},
  address      = {Nafplio, Greece},
  month        = {March},
  abstract     = {In-situ calibration of structured light scanners in
                  underwater environments is time-consuming and
                  complicated. This paper presents a self-calibrating
                  line laser scanning system, which enables the
                  creation of dense 3D models with a single fixed
                  camera and a freely moving hand-held cross line
                  laser projector. The proposed approach exploits
                  geometric constraints, such as coplanarities, to
                  recover the depth information and is applicable
                  without any prior knowledge of the position and
                  orientation of the laser projector. By employing an
                  off-the-shelf underwater camera and a waterproof
                  housing with high power line lasers an affordable 3D
                  scanning solution can be built. In experiments the
                  performance of the proposed technique is studied and
                  compared with 3D reconstruction using explicit
                  calibration. We demonstrate that the scanning system
                  can be applied to above-the-water as well as
                  underwater scenes.},
  doi          = {10.5194/isprs-archives-XLII-2-W3-105-2017},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3darch2017sl.pdf},
}


@InProceedings{3DARCH2017_3,
  author       = {H. A. Lauterbach and D. Borrmann and A. N{\"u}chter},
  title        = {{Towards Radiometrical Alignment of 3D Point Clouds}},
  booktitle    = {Proceedings of the 7th ISPRS International Workshop
                  3D-ARCH 2017: "3D Virtual Reconstruction and
                  Visualization of Complex Architectures"},
  year         = {2017},
  pages        = {419--424},
  series       = {ISPRS Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XLII/W3},
  address      = {Nafplio, Greece},
  month        = {March},
  abstract     = {3D laser scanners are typically not able to collect
                  color information. Therefore coloring is often done
                  by projecting photos of an additional camera to the
                  3D scans. The capturing process is time consuming
                  and therefore prone to changes in the
                  environment. The appearance of the colored point
                  cloud is mainly effected by changes of lighting
                  conditions and corresponding camera settings. In
                  case of panorama images these exposure variations
                  are typically corrected by radiometrical aligning
                  the input images to each other. In this paper we
                  adopt existing methods for panorama optimization in
                  order to correct the coloring of point
                  clouds. Therefore corresponding pixels from
                  overlapping images are selected by using
                  geometrically closest points of the registered 3D
                  scans and their neighboring pixels in the
                  images. The dynamic range of images in raw format
                  allows for correction of large exposure
                  differences. Two experiments demonstrate the
                  abilities of the approach.},
  doi          = {10.5194/isprs-archives-XLII-2-W3-419-2017},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3darch2017cc.pdf},
}


@InProceedings{3DARCH2017_4,
  author       = {R. Koch and S. May and A. N{\"u}chter},
  title        = {{Detection and Purging of Specular Reflective and
                  Transparent Object Influences in 3D Range
                  Measurements}},
  booktitle    = {Proceedings of the 7th ISPRS International Workshop
                  3D-ARCH 2017: "3D Virtual Reconstruction and
                  Visualization of Complex Architectures"},
  year         = {2017},
  pages        = {377--384},
  series       = {ISPRS Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XLII/W3},
  address      = {Nafplio, Greece},
  month        = {March},
  abstract     = {3D laser scanners are favoured sensors for mapping
                  in mobile service robotics at indoor and outdoor
                  applications, since they deliver precise
                  measurements at a wide scanning range. The resulting
                  maps are detailed since they have a high
                  resolution. Based on these maps robots navigate
                  through rough terrain, fulfil advanced manipulation,
                  and inspection tasks. In case of specular reflective
                  and transparent objects, e.g., mirrors, windows,
                  shiny metals, the laser measurements get
                  corrupted. Based on the type of object and the
                  incident angle of the incoming laser beam there are
                  three results possible: a measurement point on the
                  object plane, a measurement behind the object plane,
                  and a measurement of a reflected object. It is
                  important to detect such situations to be able to
                  handle these corrupted points. This paper describes
                  why it is difficult to distinguish between specular
                  reflective and transparent surfaces. It presents a
                  3D- Reflection-Pre-Filter Approach to identify
                  specular reflective and transparent objects in point
                  clouds of a multi-echo laser scanner. Furthermore,
                  it filters point clouds from influences of such
                  objects and extract the object properties for
                  further investigations. Based on an
                  Iterative-Closest-Point-algorithm reflective objects
                  are identified. Object surfaces and points behind
                  surfaces are masked according to their
                  location. Finally, the processed point cloud is
                  forwarded to a mapping module. Furthermore, the
                  object surface corners and the type of the surface
                  is broadcasted. Four experiments demonstrate the
                  usability of the 3D-Reflection-Pre-Filter. The first
                  experiment was made in a empty room containing a
                  mirror, the second experiment was made in a stairway
                  containing a glass door, the third experiment was
                  made in a empty room containing two mirrors, the
                  fourth experiment was made in an office room
                  containing a mirror. This paper demonstrate that for
                  single scans the detection of specular reflective
                  and transparent objects in 3D is possible. It is
                  more reliable in 3D as in 2D. Nevertheless, collect
                  the data of multiple scans and post-filter them as
                  soon as the object was bypassed should pursued. This
                  is why future work concentrates on implementing a
                  post-filter module. Besides, it is the aim to
                  improve the discrimination between specular
                  reflective and transparent objects.},
  doi          = {10.5194/isprs-archives-XLII-2-W3-377-2017},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3darch2017mirror.pdf},
}


@Article{IJRR2017,
  author = 	  {K. Y. K. Leung and D. L{\"u}hr and H. Houshiar and
                  F. Inostroza and D. Borrmann and M. Adams and
                  A. N{\"u}chter and J. R. del Solar},
  title = 	  {{Chilean underground mine dataset}},
  journal = 	  {International Journal of Robotics Research (IJRR)},
  year = 		  {2017},
  volume = 	  {36},
  number = 	  {1},
  pages = 	  {16--23},
  month = 	  {January},
  abstract     = {This article presents a robotic dataset collected
                  from the largest underground copper mine in the
                  world. The sensor measurements from a 3D scanning
                  lidar, a 2D radar, and stereo cameras were recorded
                  from an approximately two kilometer traverse of a
                  production-active tunnel. The equipment used and the
                  data collection process is discussed in detail,
                  along with the format of the data. This dataset is
                  suitable for research in robotic navigation, as well
                  as simultaneous localization and mapping. The
                  download instructions are available at the following
                  website http://dataset.amtc.cl.},
  doi          = {10.1177/0278364916679497},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ijrr2017.pdf},
}


@Article{RAS2017,
  author       = {R. Koch and S. May and P. Murmann and A. N{\"u}chter},
  title        = {{Identification of Transparent and Specular
                  Reflective Material in Laser Scans to Discriminate
                  Affected Measurements for Faultless Robotic SLAM}},
  journal = 	  {Journal of Robotics and Autonomous Systems (JRAS)},
  year = 		  {2017},
  volume = 	  {87},
  month = 	  {January},
  pages = 	  {296--312},
  abstract     = {Mapping with laser scanners is the state-of-the-art
                  method applied in service, industrial, medical, and
                  rescue robotics. Although a lot of research has been
                  done, maps still suffer from interferences caused by
                  transparent and specular reflective objects. Glass,
                  mirrors, shiny or translucent surfaces cause
                  erroneous measurements depending on the incident
                  angle of the laser beam. In past experiments the
                  Mirror Detector Approach was implemented to
                  determine such measurements with a multi-echo laser
                  scanner. Recognition values are based on their
                  differences in recorded measurements in regard to
                  the distance of the echoes. This paper describes the
                  research to distinguish between reflective and
                  transparent objects. The implemented Mirror Detector
                  was specifically modified for recognition of said
                  objects for which four experiments were conducted;
                  one experiment to show the map of the original
                  Mirror Detector; two experiments to investigate
                  intensity characteristics based on angle, distance,
                  and material; and one experiment to show an applied
                  discrimination with the extended version of the
                  Mirror Detector, the Reflection Classifier
                  Approach. To verify the results, a comparison with
                  existing models was performed. This study showed
                  that shiny metals, like aluminium, etc., provide
                  significant characteristics, while mirrors are to be
                  characterized by a mixed model of glass and shiny
                  metal. Transparent objects turned out to be
                  challenging because their appearance in the sensor
                  data strongly depends on the
                  background. Nevertheless, these experiments show
                  that discrimination of transparent and reflective
                  materials based on the reflected intensity is
                  possible and feasible.},
  doi          = {10.1016/j.robot.2016.10.014},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ras2016.pdf},
}

@ARTICLE{ITS2017,
  author       = {L. Chen and L. Fan and G. Xie and K. Huang and
                  A. N{\"u}chter},
  journal      = {IEEE Transactions on Intelligent Transportation
                  Systems},
  title        = {Moving-Object Detection From Consecutive Stereo
                  Pairs Using Slanted Plane Smoothing},
  year         = {2017},
  volume       = {PP},
  number       = {99},
  pages        = {1--10},
  month        = {April},
  abstract     = {Detecting moving objects is of great importance for
                  autonomous unmanned vehicle systems, and a
                  challenging task especially in complex dynamic
                  environments. This paper proposes a novel approach
                  for the detection of moving objects and the
                  estimation of their motion states using consecutive
                  stereo image pairs on mobile platforms. First, we
                  use a variant of the semi-global matching algorithm
                  to compute initial disparity maps. Second, assisted
                  by the initial disparities, boundaries in the image
                  segmentation produced by simple linear iterative
                  clustering are classified into coplanar, hinge, and
                  occlusion. Moving points are obtained during
                  ego-motion estimation by a modified random sample
                  consensus) algorithm without resorting to
                  time-consuming dense optical flow. Finally, the
                  moving objects are extracted by merging superpixels
                  according to the boundary types and their
                  movements. The proposed method is accelerated on the
                  GPU at 20 frames per second. The data which we use
                  for testing and benchmarking is released, thus
                  completing similar data sets. It includes 812 image
                  pairs and 924 moving objects with ground truth for
                  better algorithms evaluation. Experimental results
                  demonstrate that the proposed method achieves
                  competitive results in terms of moving-object
                  detection and their motion state estimation in
                  challenging urban scenarios.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/its2017.pdf},
  doi          = {10.1109/TITS.2017.2680538},
}


% --- 2016 ---


@InProceedings{TLS2016,
  author       = {A. N{\"u}chter},
  title        = {{Effiziente Speicherung großer Punktwolken --
                  Datenstrukturen f{\"u}r Algorithmen f{\"u}r mobile und
                  terrestrische Laserscansysteme}},
  booktitle    = {Terrestrisches Laserscanning (TLS 2016) Beitr{\"a}ge
                  zum 154. DVW-Seminar am 28. und 29. November in
                  Fulda},
  pages        = {105--120},
  year         = {2016},
  address      = {Fulda, Germany},
  month        = {November},
  url          = {geodaesie.info/sites/default/files/privat/DVW_85_2016_TLS_2016_FINAL_161108.pdf},
}


@InProceedings{TA2016,
  author       = {J. Schauer and J. Bedkowski and K. Majek and A. N{\"u}chter},
  title        = {{Performance comparison between state-of-the-art
                  point-cloud based collision detection approaches on
                  the CPU and GPU}},
  booktitle    = {Proceedings of the 4th IFAC Symposium on Telematics
                  Applications (TA '13)},
  volume       = {49},
  number       = {30},
  pages        = {54--59},
  address      = {Porto Alegre, Brazil},
  year         = {2016},
  month        = {November},
  abstract     = {We present two fundamentally different approaches to
                  detect collisions between two point clouds and
                  compare their performance on multiple datasets. A
                  collision between points happens if they are closer
                  to each other than a given threshold radius. One
                  approach utilizes the main CPU with a k-d tree
                  datastructure to efficiently carry out fixed range
                  searches around points in 3D while the other mainly
                  executes on a GPU using a regular grid decomposition
                  technique implemented in the CUDA framework. We will
                  show how massively parallel 3D range searches on a
                  grid based datastructure on a GPU performs similarly
                  well as a tree based approach on the CPU with orders
                  of magnitude less parallelization. We also show how
                  each method scales with varying input sizes and how
                  they perform differently well depending on the
                  spatial structure of the input data.},
  doi          = {10.1016/j.ifacol.2016.11.125},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ta2016.pdf},
}

@InProceedings{ICARCV2016,
  author       = {F. Leutert and D. Borrmann and K. Schilling and A. N{\"u}chter},
  title        = {{Spatial Projection of Thermal Data for Visual Inspection}},
  booktitle    = {Proceedings of the 14th IEEE International
                  Conference on Control, Automation, Robotics and
                  Vision (ICARCV '16)},
  year         = {2016},
  pages        = {1--6},
  month        = {November},
  address      = {Phuket, Thailand},
  abstract     = {Since the advent of thermal imaging, devices with a
                  high optical resolution that use detector arrays to
                  capture the emitted radiance in the thermal infrared
                  range of an entire scene simultaneously have
                  developed as a standard in monitoring energy
                  related. They have had a huge impact on the building
                  industry and in manifacturing, where they are
                  commonly used to monitor proecces that require
                  stable temperature conditions. As beneficial as
                  contactless measurements are, the subsequent
                  localization of points of interest in the
                  environment is often difficult. To overcome this
                  problem we propose a portable system that combines
                  thermal imaging with Augmented Reality (AR). The
                  idea of the approach is to project the gathered
                  temperature information back into the scene to
                  facilitate visual inspection. },
  doi          = {10.1109/ICARCV.2016.7838617},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icarcv2016.pdf},
}


@Article{JPRS2016,
  author       = {V. V. Lehtola and J.-P. Virtanen and M. T. Vaaja and
                  H. Hyypp{\"a} and A. N{\"u}chter},
  title        = {{Localization of a Mobile Laser Scanner via
                  Dimensional Reduction}},
  journal      = {ISPRS Journal of Photogrammetry and Remote Sensing (JPRS)},
  year         = {2016},
  volume       = {121},
  pages        = {48--59},
  month        = {November},
  abstract     = {We extend the concept of intrinsic localization from
                  a theoretical one-dimensional (1D) solution onto a
                  2D manifold that is embedded in a 3D space, and then
                  recover the full six degrees of freedom for a mobile
                  laser scanner with a simultaneous localization and
                  mapping algorithm (SLAM). By intrinsic localization,
                  we mean that no reference coordinate system, such as
                  global navigation satellite system (GNSS), nor
                  inertial measurement unit (IMU) are
                  used. Experiments are conducted with a 2D laser
                  scanner mounted on a rolling prototype platform,
                  VILMA. The concept offers potential in being
                  extendable to other wheeled platforms.},
  doi          = {10.1016/j.isprsjprs.2016.09.004},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/jprs2016.pdf},
}


@Article{JINT2016,
  author       = {P. Koch and S. May and M. Schmidpeter and M. K{\"u}hn
                  and C. Pfitzner and C. Merkl and R. Koch and M. Fees
                  and J. Martin and A. N{\"u}chter},
  title        = {{Multi-Robot Localization and Mapping based on
                  Signed Distance Functions}},
  journal      = {Journal of Intelligent and Robotic Systems},
  year         = {2016},
  volume       = {83},
  number       = {3},
  pages        = {409--428},
  month        = {September},
  abstract     = {This publication describes a 2D Simultaneous
                  Localization and Mapping approach applicable to
                  multiple mobile robots. The presented strategy uses
                  data of 2D LIDAR sensors to build a dynamic
                  representation based on Signed Distance
                  Functions. Novelties of the approach are a joint map
                  built in parallel instead of occasional merging of
                  smaller maps and the limited drift localization
                  which requires no loop closure detection. A
                  multi-threaded software architecture performs
                  registration and data integration in parallel
                  allowing for drift-reduced pose estimation of
                  multiple robots. Experiments are provided
                  demonstrating the application with single and
                  multiple robot mapping using simulated data, public
                  accessible recorded data, two actual robots
                  operating in a comparably large area as well as a
                  deployment of these units at the Robocup rescue
                  league.},
  doi          = {10.1007/s10846-016-0375-7},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/jirs2016.pdf},
}


@InCollection{Handbook2016,
  author       = {K. Konolige and A. N{\"u}chter},
  booktitle    = {Handbook of Robotics},
  title        = {Range Sensors},
  publisher    = {Springer},
  year         = {2016},
  edition      = {second},
  pages        = {783--810},
  editor       = {B. Siciliano, O. Khatib},
  doi          = {10.1007/978-3-319-32552-1},
}


@InProceedings{ISPRSCongress2016,
  author       = {V. V. Lehtola and J-P. Virtanen and P. R{\"o}nnholm and A. N{\"u}chter},
  title        = {LOCALIZATION CORRECTIONS FOR MOBILE LASER SCANNER
                  USING LOCAL SUPPORT-BASED OUTLIER FILTERING},
  booktitle    = {Proceedings of the ISPRS Congress 2016},
  year         = {2016},
  number       = {III-4},
  series       = {ISPRS Annals Photogrammetry and Remote Sensing,
                  Spatial Inf. Sci.},
  pages        = {81--88},
  month        = {July},
  address      = {Prague, Czech Republic},
  abstract     = {Following the pioneering work introduced in [Lehtola
                  et al., ISPRS J. Photogramm. Remote Sens. 99, 2015,
                  pp. 25–29], we extend the state-of-the-art intrinsic
                  localization solution for a single two-dimensional
                  (2D) laser scanner from one into (quasi) three
                  dimensions (3D). By intrinsic localization, we mean
                  that no external sensors are used to localize the
                  scanner, such as inertial measurement devices (IMU)
                  or global navigation satellite systems
                  (GNSS). Specifically, the proposed method builds on
                  a novel concept of local support-based filtering of
                  outliers, which enables the use of six
                  degrees-of-freedom (DoF) simultaneous localization
                  and mapping (SLAM) for the purpose of enacting
                  appropriate trajectory corrections into the previous
                  one-dimensional solution. Moreover, the local
                  support-based filtering concept is platform
                  independent, and is therefore likely to be widely
                  generalizable. The here presented overall method is
                  yet limited into quasi-3D by its inability to
                  recover trajectories with steep curvature, but in
                  the future, it may be further extended into full
                  3D.},
  doi          = {10.5194/isprs-annals-III-4-81-2016},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/isprs2016.pdf},
}



@InProceedings{3DTAGE2016,
  author       = {D. Borrmann and F. Leutert and I. Maurovic and
                  M. Seder and A. N{\"u}chter},
  title        = {{Automatische Grundrisserstellung mittels
                  Laserscandaten}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2016, Jade Hochschule},
  pages        = {108--119},
  year         = {2016},
  month        = {February},
  abstract     = {In den letzten Jahren haben sich Laserscanner zum
                  Stand der Technik bei der Erstellung von
                  Geb{\"a}udemodellen entwickelt. Im Gegensatz zur
                  vergleichsweise kurzen Aufnahmezeit bei der
                  eigentlichen Erfassung der Umgebung mit dem Scanner
                  nimmt die Nachbearbeitung der Daten einen deutlich
                  h{\"o}heren Zeitanteil ein. Eine manuelle Datenanalyse
                  ist zeitaufw{\"a}ndig und fehleranf{\"a}llig. Dies erh{\"o}ht
                  den Bedarf an automatischen Verfahren zur
                  quantitativen Erfassung und Charakterisierung von
                  Umgebungen.  In diesem Beitrag pr{\"a}sentieren wir eine
                  automatische Grundrisserstellung basierend auf dem
                  3D Toolkit (3DTK - http://www.threedtk.de). Nach der
                  autonomen Akquise mit einem mobilen Roboter werden
                  die Daten mittels des iterativen Verfahrens der
                  n{\"a}chsten Punkte (engl. Iterative Closest Point
                  (ICP)) registriert. Anschließend erfolgt eine
                  automatische Vektorisierung eines 2D-Schnitts der
                  Umgebung basierend auf Verfahren aus der
                  Bildverarbeitung. Der so erzeugte Grundriss dient
                  als Grundlage f{\"u}r eine semantische Karte. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/olb2016.pdf},
  
}


@InProceedings{MedIm2016,
  author       = {C. Pfitzner, S. May and A. N{\"u}chter},
  title        = {Neural Network-based Visual Body Weight Estimation
                  for Drug Dosage Finding},
  booktitle    = {Proceedings of the SPIE 9784, Medical Imaging 2016:
                  Image Processing},
  year         = {2016},
  month        = {February},
  address      = {San Diego, CA, USA},
  abstract     = {Body weight adapted drug dosages are important for
                  emergency treatments. This paper describes an
                  improved body weight estimation approach for
                  emergency patients in a trauma room, based on images
                  from a RGBD sensor and a thermal camera. The
                  improvements are archived by several extensions: The
                  sensor fusion of RGBD and thermal camera eases
                  filtering and segmentation of the patient's body
                  from the background. Robustness and accuracy is
                  gained by an artificial neural network (ANN), which
                  considers features from the sensors as input to
                  calculate the patient's body weight, e.g. the
                  patient's volume, surface and shape parameters. The
                  ANN is trained offline with 30 percent of the
                  patients data. Preliminary experiments with 69 real
                  patients show an accuracy close to 90 percent for a
                  threshold of ten percent relative error in real body
                  estimation. Results are compared to the patient's
                  self estimation, a physician's guess and an
                  anthropometric method: If the patient is
                  knowledgeable it is the best possibility for body
                  weight adapted drug dosages with 97 percent
                  accuracy. The treating physicians and the
                  anthropometric estimation achieve an accuracy of
                  approximately 70 percent. The here presented
                  approach gets an accuracy of nearly 90 percent and
                  would be the best solution if a patient can not
                  provide his own body weight and can not be weighted
                  on a scale. These preliminary results demonstrate a
                  sufficient approach for an upcoming clinical trial
                  with 1,000 patients for body weight estimation. },
  doi          = {10.1117/12.2216042},
  url          = {},
}


% --- 2015 ---


@InProceedings{CIPA2015,
  author       = {H. Houshiar and D. Borrmann and J. Elseberg and
                  A. N{\"u}chter and S. Winkler and F. N{\"a}th},
  title        = {{CASTLE3D -- A Computer Aided System for Labelling
                  Archaeological Excavations in 3D}},
  series       = {ISPRS Annals Photogrammetry and Remote Sensing,
                  Spatial Inf. Sci., II-3/W1},
  booktitle    = {Proceedings of the XXV International CIPA Symposium},
  year         = {2015},
  pages        = {111--118},
  month        = {September},
  address      = {Taipei, Taiwan},
  abstract     = {Documentation of archaeological excavation sites
                  with conventional methods and tools such as hand
                  drawings, measuring tape and archaeological notes is
                  time consuming. This process is prone to human
                  errors and the quality of the documentation depends
                  on the qualification of the archaeologist on
                  site. Use of modern technology and methods in 3D
                  surveying and 3D robotics facilitate and improve
                  this process. Computer-aided systems and databases
                  improve the documentation quality and increase the
                  speed of data acquisition. 3D laser scanning is the
                  state of the art in modelling archaeological
                  excavation sites, historical sites and even entire
                  cities or landscapes. Modern laser scanners are
                  capable of data acquisition of up to 1 million
                  points per second. This provides a very detailed 3D
                  point cloud of the environment. 3D point clouds and
                  3D models of an excavation site provide a better
                  representation of the environment for the
                  archaeologist and for documentation. The point cloud
                  can be used both for further studies on the
                  excavation and for the presentation of results. This
                  paper introduces a Computer aided system for
                  labelling archaeological excavations in 3D
                  (CASTLE3D). Consisting of a set of tools for
                  recording and georeferencing the 3D data from an
                  excavation site, CASTLE3D is a novel documentation
                  approach in industrial archaeology. It provides a 2D
                  and 3D visualisation of the data and an easy-to-use
                  interface that enables the archaeologist to select
                  regions of interest and to interact with the data in
                  both representations. The 2D visualisation and a 3D
                  orthogonal view of the data provide cuts of the
                  environment that resemble the traditional hand
                  drawings. The 3D perspective view gives a realistic
                  view of the environment. CASTLE3D is designed as an
                  easy-to-use on-site semantic mapping tool for
                  archaeologists. Each project contains a predefined
                  set of semantic information that can be used to
                  label findings in the data. Multiple regions of
                  interest can be joined under one label. Further
                  information such as color, orientation and
                  archaeological notes are added to the label to
                  improve the documentation. The available 3D
                  information allows for easy measurements in the
                  data. The full 3D information of a region of
                  interest can be segmented from the entire data. By
                  joining this data from different georeferenced views
                  the full 3D shape of findings is stored. All the
                  generated documentation in CASTLE3D is exported to
                  an XML format and serves as input for other systems
                  and databases. Apart from presenting the
                  functionalities of CASTLE3D we evaluate its
                  documentation process in a sample project. For this
                  purpose we export the data to the Adiuvabit database
                  (http://adiuvabit.de) where more information is
                  added for further analysis. The documentation
                  process is compared to traditional documentation
                  methods and it is shown how the automated system
                  helps in accelerating the documentation process and
                  decreases errors to a minimum.},
  doi          = {10.5194/isprsannals-II-5-W3-111-2015},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/cipa2015.pdf},
}


@InProceedings{ROBOT2015,
  author       = {R. Koch and S. May and P. Koch and M. K{\"u}hn and
                  A. N{\"u}chter},
  title        = {Detection of Specular Reflections in Range
                  Measurements for Faultless Robotic SLAM},
  booktitle    = {Proceedings of ROBOT'2015: Second Iberian Robotics
                  Conference, Advances in Robotics, Volume 1},
  year         = {2015},
  volume       = {114},
  series       = {Advances in Intelligent Systems and Computing},
  pages        = {133--145},
  address      = {Lisbon, Portugal},
  publisher    = {Springer},
  abstract     = {Laser scanners are state-of-the-art devices used for
                  mapping in service, industry, medical and rescue
                  robotics. Although a lot of work has been done in
                  laser-based SLAM, maps still suffer from
                  interferences caused by objects like glass, mirrors
                  and shiny or translucent surfaces. Depending on the
                  surface's reflectivity, a laser beam is deflected
                  such that returned measurements provide wrong
                  distance data. At certain positions phantom-like
                  objects appear. This paper describes a specular
                  reflectance detection approach applicable to the
                  emerging technology of multi-echo laser scanners in
                  order to identify and filter reflective objects. Two
                  filter stages are implemented. The first filter
                  reduces errors in current scans on the fly. A second
                  filter evaluates a set of laser scans, triggered as
                  soon as a reflective surface has been passed. This
                  makes the reflective surface detection more robust
                  and is used to refine the registered
                  map. Experiments demonstrate the detection and
                  elimination of reflection errors. They show improved
                  localization and mapping in environments containing
                  mirrors and large glass fronts is improved.},
  doi          = {10.1007/978-3-319-27146-0_11},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/robot2015.pdf},
}


@Article{MNAA2015,
  author       = {J. Bedkowski and K. Majek and P. Majek and
                  P. Musialik and M. Pelka and A. N{\"u}chter},
  title        = {{Intelligent Mobile System for Improving Spatial Design Support and Security Inside Buildings}},
  journal      = {Mobile Networks and Applications},
  year         = {2015},
  volume       = {20},
  number       = {6},
  pages        = {1--14},
  abstract     = {This paper concerns an intelligent mobile
                  application for spatial design support and security
                  domain. Mobility has two aspects in our research:
                  The first one is the usage of mobile robots for 3D
                  mapping of urban areas and for performing some
                  specific tasks. The second mobility aspect is
                  related with a novel Software as a Ser- vice system
                  that allows access to robotic functionalities and
                  data over the Ethernet, thus we demonstrate the use
                  of the novel NVIDIA GRID technology allowing to
                  virtualize the graphic processing unit. We introduce
                  Complex Shape Histogram, a core component of our
                  artificial intelligence engine, used for classifying
                  3D point clouds with a Support Vector Machine. We
                  use Complex Shape Histograms also for loop closing
                  detection in the simultaneous localization and
                  mapping algorithm. Our intelligent mobile system is
                  built on top of the Qualitative Spatio-Temporal
                  Representa- tion and Reasoning framework. This
                  framework defines an ontology and a semantic model,
                  which are used for building the intelligent mobile
                  user interfaces. We show experiments demonstrating
                  advantages of our approach. In addition, we test our
                  prototypes in the field after the end-user case
                  studies demonstrating a relevant contribution for
                  future intelligent mobile systems that merge mobile
                  robots with novel data centers.},
  doi          = {10.1007/s11036-015-0654-8},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/mnaa2015.pdf}, 
}


@InProceedings{ICAT2015,
  author       = {H. Houshiar and A. N{\"u}chter},
  title        = {{3D Point Cloud Compression using Conventional Image
                  Compression for Efficient Data Transmission}},
  booktitle    = {Proceedings of the XXV International Symposium on
                  Information, Communication and Automation
                  Technologies (ICAT '15)},
  year         = {2015},
  pages        = {1--8},
  address      = {Sarajevo, Bosnia},
  month        = {October},
  publisher    = {IEEE Xplore},
  abstract     = {Modern 3D laser scanners make it easy to collect
                  large 3D point clouds. In this paper we present the
                  use of conventional image based compression methods
                  for 3D point clouds. We map the point cloud onto
                  panorama images to encode the range, reflectance and
                  color value for each point. An encoding method is
                  presented to map the floating point measured ranges
                  on to a three channel image. The image compression
                  methods are used to compress the generated panorama
                  images. We present the results of several lossless
                  compression methods and the lossy JPEG on point
                  cloud compression. Lossless compression methods are
                  designed to retain the original data. On the other
                  hand lossy compression methods sacrifice the details
                  for higher compression ratio. This produces
                  artefacts in the recovered point cloud data. We
                  study the effects of these artefacts on encoded
                  range data. A filtration process is presented for
                  determination of range outliers from uncompressed
                  point clouds.},
  doi          = {10.1109/ICAT.2015.7340499},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icat2015.pdf},
}


@Article{REMSEN2015,
  author       = {H. A. Lauterbach and D. Borrmann and R. Hess and
                  D. Eck and K. Schilling and A. N{\"u}chter},
  title        = {Evaluation of a Backpack-Mounted 3D Mobile Scanning
                  System},
  journal      = {Remote Sensing},
  year         = {2015},
  volume       = {7},
  number       = {10},
  pages        = {13753--13781},
  abstract     = {Recently, several backpack-mounted systems, also
                  known as personal laser scanning systems, have been
                  developed. They consist of laser scanners or cameras
                  that are carried by a human operator to acquire
                  measurements of the environment while walking. These
                  systems were first designed to overcome the
                  challenges of mapping indoor environments with doors
                  and stairs. While the human operator inherently has
                  the ability to open doors and to climb stairs, the
                  flexible movements introduce irregularities of the
                  trajectory to the system. To compete with other
                  mapping systems, the accuracy of these systems has
                  to be evaluated. In this paper, we present an
                  extensive evaluation of our backpack mobile mapping
                  system in indoor environments. It is shown that the
                  system can deal with the normal human walking
                  motion, but has problems with irregular
                  jittering. Moreover, we demonstrate the
                  applicability of the backpack in a suitable urban
                  scenario.},
  doi          = {10.3390/rs71013753},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/remotesensing2015.pdf},
}

@InProceedings{LS2015,
  author       = {A. N{\"u}chter and D. Borrmann and P. Koch and
                  M. K{\"u}hn and S. May},
  title        = {A Man-Portable, IMU-free Mobile Mapping},
  booktitle    = {Proceedings of the ISPRS Geospatial Week 2015, Laserscanning 2015},
  year         = {2015},
  series       = {ISPRS Annals Photogrammetry and Remote Sensing,
                  Spatial Inf. Sci., II-3/W5},
  pages        = {17--23},
  month        = {September},
  address      = {La Grande Motte, France},
  abstract     = {Mobile mapping systems are commonly mounted on cars,
                  ships and robots. The data is directly
                  geo-referenced using GPS data and expensive IMU
                  (inertial measurement systems). Driven by the need
                  for flexible, indoor mapping systems we present an
                  inexpensive mobile mapping solution that can be
                  mounted on a backpack. It combines a horizontally
                  mounted 2D profiler with a constantly spinning 3D
                  laser scanner. The initial system featuring a
                  low-cost MEMS IMU was revealed and demonstrated at
                  MoLaS: Technology Workshop Mobile Laser Scanning at
                  Fraunhofer IPM in Freiburg in November 2014. In this
                  paper, we present an IMU-free solution. },
  doi          = {10.5194/isprsannals-II-3-W5-17-2015},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ls2015.pdf},
}


@Article{ADVEI2015,
  author       = {J. Schauer and A. N{\"u}chter},
  title        = {Collision detection between point clouds using an
                  efficient $k$-d tree implementation},
  journal      = {Journal Advanced Engineering Informatics (JAdvEI)},
  year         = {2015},
  volume       = {29},
  number       = {3},
  pages        = {440--458},
  month        = {August},
  abstract     = {Context: An important task in civil engineering is
                  the detection of collisions of a 3D model with an
                  environment representation. Existing methods using
                  the structure gauge provide an insufficient measure
                  because the model either rotates or because the
                  trajectory makes tight turns through narrow
                  passages. This is the case in either automotive
                  assembly lines or in narrow train
                  tunnels. Objective: Given two point clouds, one of
                  the environment and one of a model and a trajectory
                  with six degrees of freedom along which the model
                  moves through the environment, find all colliding
                  points of the environment with the model within a
                  certain clearance radius. Method: This paper
                  presents two collision detection (CD) methods called
                  kd-CD and kd-CD-simple and two penetration depth
                  (PD) calculation methods called kd-PD and
                  kd-PD-fast. All four methods are based on searches
                  in a k-d tree representation of the environment. The
                  creation of the k-d tree, its search methods and
                  other features will be explained in the scope of
                  their use to detect collisions and calculate depths
                  of penetration. Results: The algorithms are
                  benchmarked by moving the point cloud of a train
                  wagon with 2.5 million points along the point cloud
                  of a 1144m long train track through a narrow tunnel
                  with overall 18.92 million points. Points where the
                  wagon collides with the tunnel wall are visually
                  highlighted with their penetration depth. With a
                  safety margin of 5cm kd-PD-simple finds all
                  colliding points on its trajectory which is sampled
                  into 19,392 positions in 77s on a standard desktop
                  machine of 1.6GHz. Conclusion: The presented methods
                  for collision detection and penetration depth
                  calculation are shown to solve problems for which
                  the structure gauge is an insufficient measure. The
                  underlying k-d tree is shown to be an effective data
                  structure for the required look-up operations.},
  doi          = {10.1016/j.aei.2015.03.007},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/aei2015.pdf},
}


@InProceedings{ICRA2015,
  author       = {C. Pfitzner and S. May and C. Merkl and L. Breuer
                  and M. K{\"o}hrmann and J. Braun and F. Dirauf and
                  A. N{\"u}chter},
  title        = {{Libra3D: Body Weight Estimation for Emergency
                  Patients in Clinical Environment with a 3D
                  Structured Light Sensor}},
  booktitle    = {Proceedings of the IEEE International Conference
                  Robotics and Automation (ICRA '15)},
  address      = {Seattle, WA, USA},
  year         = {2015},
  month        = {May},
  abstract     = {his paper describes the application of a weight
                  estimation method for emergency patients in clinical
                  environments. The approach applies established
                  algorithms for point cloud processing and filtering
                  to data from a low-cost, structured light sensor. A
                  patient's volume is estimated on the basis of their
                  visible front surface. The approach is currently
                  being tested in the workflow of the emergency room
                  at the Universitätsklinikum Erlangen,
                  Germany. Preliminary results show the accuracy of
                  the approach in relation to other conservative means
                  of weight measurements, for example, by physicians
                  and anthropometric measurements.},
  doi          = {10.1109/ICRA.2015.7139593},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icra2015.pdf},
  
}


@Article{AR2015,
  author       = {M. Al-khawaldah and A. N{\"u}chter},
  title        = {{Enhanced frontier-based exploration for indoor
                  environment with multiple robots}},
  journal      = {Advanced Robotics},
  year         = {2015},
  volume       = {28},
  number       = {10},
  pages        = {657--669},
  abstract     = {n this paper, the exploration and map-building of
                  unknown environment by a team of mobile robots is
                  intensively investigated. A new exploration
                  technique is proposed to increase the exploration
                  efficiency. In particular, the new technique has two
                  main objectives: firstly, it aims at reducing the
                  exploration time and the traveled distance by
                  reducing the overlap which takes place when a
                  certain area in the environment is explored by more
                  than one robot. To achieve this, a new procedure to
                  assign the next target location for each individual
                  robot is proposed. And secondly, it aims at reducing
                  computations complexity required by target selection
                  and path planning tasks. More importantly, the
                  proposed technique obviates the need for environment
                  segmentation complex procedures which is adopted in
                  some previous important research works. The new
                  technique is intensively tested with different
                  environments. The results showed the effectiveness
                  of the proposed technique.},
  doi          = {10.1080/01691864.2015.1015443},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/tadr2015.pdf},
  
}


@InProceedings{CESCIT2015,
  author       = {D. Borrmann and R. Hess and D. Eck and H. Houshiar
                  and A. N{\"u}chter and K. Schilling},
  title        = {{Evaluation of Methods for Robotic Mapping of
                  Cultural Heritage Sites}},
  booktitle    = {Proceedings of the 2th IFAC conference on Embedded
                  Systems, Computer Intelligence and Telematics
                  (CESCIT '15)},
  pages        = {105--110},
  address      = {Maribor, Slovenia},
  year         = {2015},
  month        = {June},
  abstract     = {In archaeological studies the use of new
                  technologies has moved into focus in the past years
                  creating new challenges such as the processing of
                  the massive amounts of data. In this paper we
                  present steps and processes for smart 3D modelling
                  of environments by use of the mobile robot Irma3D. A
                  robot that is equipped with multiple sensors, most
                  importantly a photo camera and a laser scanner,
                  enables the automation of most of the processes,
                  including data acquisition and registration. The
                  robot was tested in the W{\"u}rzburg Residence. Methods
                  for automatic 3D color reconstructions of cultural
                  heritage sites are evaluated in this paper.},
  doi          = {10.1016/j.ifacol.2015.08.116},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/cescit2015.pdf},
}


@Article{AVN2015_2,
  author       = {A. N{\"u}chter and D. Borrmann and J. Elseberg and
                  D. Redondo},
  title        = {{A Backpack-Mounted 3D Mobile Scanning System}},
  journal      = {Allgemeine Vermessungs-Nachrichten (AVN), Special
                  Issue MoLAS 2014},
  year         = {2015},
  volume       = {122},
  number       = {10},
  pages        = {301--307},
  month        = {October},
  abstract     = {Mobile laser scanning systems automate the
                  acquisition of 3D point clouds of environments. The
                  mapping systems are commonly mounted on cars or
                  ships. This paper presents a mapping solution
                  mounted on a backpack. A clever choice of hard- and
                  software enables the system to generate 3D maps
                  without using GPS (global positioning system)
                  information and without relying on expensive IMU
                  (inertial measurement unit) systems. Therefore, it
                  enables flexible indoor mapping.},
}


@Article{AVN2015_1,
  author       = {D. Borrmann and H. Houshiar and J. Elseberg and A
                  N{\"u}chter and F. N{\"a}th and S. Winkler},
  title        = {Das Castle3D Framework zur fortlaufenden
                  semantischen 3D-Kartierung von arch{\"a}ologischen
                  Ausgrabungsst{\"a}tten},
  journal      = {Allgemeine Vermessungs-Nachrichten (AVN)},
  year         = {2015},
  volume       = {122},
  number       = {6/7},
  pages        = {233--246},
  abstract     = {Das 3D Laserscanning ist Stand der Technik bei der
                  Modellierung arch{\"a}ologischer
                  Ausgrabungsst{\"a}tten, historischer Anlagen und
                  sogar ganzer St{\"a}dte oder Landschaften. Die
                  Dokumentation der Befunde auf einer
                  Ausgrabungsst{\"a}tte ist eine wesentliche
                  arch{\"a}ologische Aufgabe. Ein automatisiertes
                  System w{\"u}rde diesen Prozess beschleunigen und die
                  Anzahl der Fehler auf ein Minimum reduzieren.
                  Dieser Beitrag stellt einen neuen Ansatz in der
                  Dokumentation industrieller Arch{\"a}ologie vor durch
                  die Entwicklung einer standardisierten
                  Herangehensweise an die computerunterst{\"u}tzte
                  Dokumentation einer arch{\"a}ologischen
                  Ausgrabungsst{\"a}tten.  Ausserdem wird eine Reihe
                  von Tools zur Erfassung und Registrierung von
                  3D-Daten auf Ausgrabungsst{\"a}tten vorgestellt, die
                  den Hauptbestandteil der Arbeitskette abdecken.  Wir
                  stellen ein effizientes Werkzeug zur Verf{\"u}gung
                  f{\"u}r die Visualisierung der erworbenen
                  3D-Punktwolken im 3D- und 2D-Modus. Der Hauptzweck
                  dieser Software ist Arch{\"a}ologen ein einfach zu
                  bedienendes Tool f{\"u}r die semantische Kartierung
                  vor Ort zu bieten. Es enth{\"a}lt Funktionen f{\"u}r
                  die Auswahl und Kennzeichnung von Funden. Jedes
                  Label kann mit weiteren Informationen versehen
                  werden. Diese Daten werden im XML-Format exportiert
                  und dienen als Eingabe f{\"u}r andere Systeme und
                  Datenbanken.},
}


@InProceedings{ICARSC2015,
  author       = {P. Koch and S. May and M. Schmidpeter and
                  M. K{\"u}hn and C. Pfitzner and C. Merkl and R. Koch
                  and M. Fees and J. Martin and A. N{\"u}chter},
  title        = {{Multi-Robot Localization and Mapping based on
                  Signed Distance Functions}},
  booktitle    = {Proceedings of the IEEE International Conference on
                  Autonomous Robot Systems and Competitions (ICARSC
                  '15)},
  pages        = {77--82},  
  address      = {Vila Real, Portugal},
  year         = {2015},
  month        = {April},
  abstract     = {This publication describes a 2D Simultaneous
                  Localization and Mapping approach applicable to
                  multiple mobile robots. The presented strategy uses
                  data of 2D LIDAR sensors to build a dynamic
                  representation based on Signed Distance Functions. A
                  multi-threaded software architecture performs
                  registration and data integration in parallel
                  allowing for drift-reduced pose estimation of
                  multiple robots. Experiments are provided
                  demonstrating the application with single and
                  multiple robot mapping using simulated data, public
                  accessible recorded data as well as two actual
                  robots operating in a comparably large area.},
  doi          = {10.1109/ICARSC.2015.18},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icarsc2015.pdf},
}


@InProceedings{PIA2015,
  author       = {J. Gailis and A. N{\"u}chter},
  title        = {{Towards Globally Consistent Scan Matching With
                  Ground Truth Integration}},
  booktitle    = {Proceedings of the ISPRS International Conference on
                  Photogrammetric Image Analysis (PIA '15)},
  year         = {2015},
  pages        = {59--64},
  series       = {ISPRS Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XL-3/W2},
  address      = {Munich, Germany},
  month        = {February},
  abstract     = { The scan matching based simultaneous localization
                  and mapping method with six dimensional poses is
                  capable of creating a three dimensional point cloud
                  map of the environment, as well as estimating the
                  six dimensional path that the vehicle has
                  travelled. The essence of it is the registering and
                  matching of sequentially acquired 3D laser scans,
                  while moving along a path, in a common coordinate
                  frame in order to provide 6D pose estimations at the
                  respective positions, as well as create a three
                  dimensional map of the environment. An approach that
                  could drastically improve the reliability of
                  acquired data is to integrate available ground truth
                  information. This paper is about implementing such
                  functionality as a contribution to 6D SLAM
                  (simultaneous localization and mapping with 6 DoF)
                  in the 3DTK – The 3D Toolkit software (N{\"u}chter and
                  Lingemann, 2011), as well as test the functionality
                  of the implementation using real world datasets.},
  doi          = {10.5194/isprsarchives-XL-3-W2-59-2015},
  url          = {https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XL-3-W2/59/2015/isprsarchives-XL-3-W2-59-2015.pdf},
}


@InProceedings{3DARCH2015_2,
  author       = {D. Borrmann and R. Hess and D. Eck and
                  A. N{\"u}chter and K. Schilling},
  title        = {{Robotic Mapping of Cultural Heritage Sites}},
  booktitle    = {Proceedings of the 6th ISPRS International Workshop
                  3D-ARCH 2015: "3D Virtual Reconstruction and
                  Visualization of Complex Architectures"},
  year         = {2015},
  pages        = {9--16},
  series       = {ISPRS Archives Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XL-5/W4},
  address      = {Avila, Spain},
  month        = {February},
  abstract     = {In archaeological studies the use of new
                  technologies has moved into focus in the past years
                  creating new challenges such as the processing of
                  the massive amounts of data. In this paper we
                  present steps and processes for smart 3D modelling
                  of environments by use of the mobile robot Irma3D. A
                  robot that is equipped with multiple sensors, most
                  importantly a photo camera and a laser scanner,
                  enables the automation of most of the processes,
                  including data acquisition and registration. The
                  robot was tested in two scenarios, Ostia Antica and
                  the W{\"u}rzburg Residence. The paper describes the
                  steps for creating 3D color reconstructions of these
                  renown cultural heritage sites.},
  doi          = {10.5194/isprsarchives-XL-5-W4-9-2015},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3darch2015_2.pdf},
  
}

@InProceedings{3DARCH2015_1,
  author       = {P. K{\"a}shammer and A. N{\"u}chter},
  title        = {{Mirror Identification and Correction of 3D Point Clouds}},
  booktitle    = {Proceedings of the 6th ISPRS International Workshop
                  3D-ARCH 2015: "3D Virtual Reconstruction and
                  Visualization of Complex Architectures"},
  year         = {2015},
  pages        = {109--114},
  series       = {IISPRS Archives Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XL-5/W4},
  address      = {Avila, Spain},
  month        = {February},
  abstract     = {In terrestrial laser scanning (TLS), the surface
                  geometry of objects is scanned by laser beams and
                  recorded digitally. This produces a discrete set of
                  scan points, commonly referred to as a point
                  cloud. The coordinates of the scan points are
                  determined by measuring the angles and the
                  time-of-flight relative to the origin (scanner
                  position). However, if it comes to mirror surfaces
                  laser beams are fully reflected, due to the high
                  reflectivity. Mirrors do not appear in the point
                  cloud at all. Instead, for every reflected beam, a
                  incorrect scan point is created behind the actual
                  mirror plane. Consequently, problems arise in
                  multiple derived application fields such as 3D
                  virtual reconstruction of complex architectures. The
                  paper presents a new approach to automatically
                  detect framed rectangular mirrors with known
                  dimensions and to correct the 3D point cloud, using
                  the calculated mirror plane. },
  doi          = {10.5194/isprsarchives-XL-5-W4-109-2015},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3darch2015_1.pdf},
}


@Article{GSIS2015,
  author       = {H. Houshiar and J. Elseberg and D. Borrmann and A. N{\"u}chter},
  title        = {{A Study of Projections for Key Point Based
                  Registration of Panoramic Terrestrial 3D Laser
                  Scans}},
  journal      = {Journal of Geo-spatial Information Science},
  year         = {2015},
  volume       = {18},
  number       = {1},
  pages        = {11--31},
  month        = {January},
  abstract     = {This paper surveys state-of-the-art image features
                  and descriptors for the task of 3D scan registration
                  based on panoramic reflectance images. As modern
                  terrestrial laser scanners digitize their
                  environment in a spherical way, the sphere has to be
                  projected to a two-dimensional image. To this end,
                  we evaluate the equirectangular, the cylindrical,
                  the Mercator, the rectilinear, the Pannini, the
                  stereographic, and the z-axis projection. We show
                  that the Mercator and the Pannini projection
                  outperform the other projection methods. }
},
  doi          = {10.1080/10095020.2015.1017913},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/gsis2013.pdf},
}


@Article{JINT2015,
  author       = {G. Demisse and D. Borrmann and A. N{\"u}chter},
  title        = {{Interpreting Thermal 3D Models of Indoor
                  Environments for Energy Efficiency}},
  journal      = {Journal of Intelligent and Robotic Systems},
  year         = {2015},
  volume       = {77},
  number       = {1},
  pages        = {55--72},
  month        = {January},
  abstract     = {In recent years 3D models of buildings are used in
                  maintenance and inspection, preservation, and other
                  building related applications. However, the usage of
                  these models is limited because most models are pure
                  representations with no or little associated
                  semantics. In this paper we present a pipeline of
                  techniques used for interior interpretation, object
                  detection, and adding energy related semantics to
                  windows of a 3D thermal model. A sequence of
                  algorithms is presented for building the fundamental
                  semantics of a 3D model. Among other things, these
                  algorithms enable the system to differentiate
                  between objects in a room and objects that are part
                  of the room, e.g. floor, windows. Subsequently, the
                  thermal information is used to construct a
                  stochastic mathematical model– namely Markov Random
                  Field– of the temperature distribution of the
                  detected windows. As a result, the MAP(Maximum a
                  posteriori) framework is used to further label the
                  windows as either open, closed or damaged based upon
                  their temperature distribution. The experimental
                  results showed the robustness of the
                  techniques. Furthermore, a strategy to optimize the
                  free parameters is described, in cases where there
                  is a sample training dataset.},
  doi          = {10.1007/s10846-014-0099-5},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/jint2015.pdf},  
}


% --- 2014 ---


@InProceedings{VMV2014,
  author       = {S. May and P. Koch and R. Koch and C. Merkl and
                  C. Pfitzer and A.N{\"u}chter},
  title        = {A Gereralized 2D and 3D Multi-Sensor Data
                  Integration Approach based on Signed Distance
                  Functions for Multi-Modal Robotic Mapping},
  booktitle    = {Proceedings of th 19th International Workshop on
                  Vision, Modeling and Visualization (VMV '14)},
  year         = {2014},
  address      = {Darmstadt, Germany},
  month        = {October},
  abstract     = {This paper describes a data integration approach for
                  arbitrary 2D/3D depth sensing units exploiting
                  assets of the signed distance function. The
                  underlying framework generalizes the KinectFusion
                  approach with an objectoriented model respecting
                  different sensor modalities. For instance,
                  measurements of 2D/3D laser range finders and RGB-D
                  cameras can be integrated into the same
                  representation. Exemplary, an environment is
                  reconstructed with a 3D laser range finder, while
                  adding fine details from objects of interest by
                  closer inspection with an RGB-D sensor. A typical
                  application of this approach is the exploration in
                  rescue environments, where large-scale mapping is
                  performed on the basis of long-range laser range
                  finders while hollows are inspected with lightweight
                  sensors attached to a manipulator arm.},
  doi          = {10.2312/vmv.20141281},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/vmv2014.pdf},
}


@Article{AUTOMATIKA2014,
  author       = {M. Al-khawaldah and A. N{\"u}chter},
  title        = {{Multi-Robot Cooperation for Efficient Exploration}},
  journal      = {AUTOMATIKA -- Journal for Control, Measurement,
                  Electronics, Computing and Communications},
  year         = {2014},
  volume       = {55},
  number       = {3},
  pages        = {276--286},
  abstract     = {This paper addresses the problem of exploration of
                  an unknown environment by developing effective
                  exploration strategies for a team of mobile robots
                  equipped with continuously rotating 3D scanners. The
                  main aim of the new strategies is to reduce the
                  exploration time of unknown environment. Unlike most
                  of other published works, to save time, the laser
                  scanners rotate and scan the environment while
                  robots are in motion. Furthermore, the new
                  strategies are able to explore large outdoor
                  environments as a considerable reduction of the
                  required computations, especially those required for
                  path planning, have been achieved. Moreover, another
                  new exploration strategy has been developed so that
                  robots continuously replan the order to visit the
                  remaining unexplored areas according to the new data
                  (i.e. updated map) collected by the robot in
                  question or by the other team members. This new
                  extension led to further enhancements over the above
                  mentioned ones, but with slightly higher
                  computational costs. Finally, to assess our new
                  exploration strategies with different levels of
                  environment complexity, new set of experiments were
                  conducted in environments where obstacles are
                  distributed according to the Hilbert curve. The
                  results of these experiments show the effectiveness
                  of the proposed technique to effectively distribute
                  the robots over the environment. More importantly,
                  we show how the optimal number of robots is related
                  to the environment complexity.},
  doi          = {10.7305/automatika.2014.12.648},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/automatika2014.pdf},
}


@Article{ADVEI2014,
  author       = {D. Borrmann and A. N{\"u}chter and
                  M. \DJ{}akulovi\'{c} and I. Maurovi\'{c} and
                  I. Petrovi\'{c} and D. Osmankovi\'{c} and
                  J. Velagi\'{c}},
  title        = {A mobile robot based system for fully automated
                  thermal 3D mapping},
  journal      = {Journal Advanced Engineering Informatics (JAdvEI)},
  year         = {2014},
  volume       = {28},
  number       = {4},
  pages        = {425--440},
  month        = {October},
  abstract     = {It is hard to imagine living in a building without
                  electricity and a heating or cooling system these
                  days. Factories and data centers are equally
                  dependent on a continuous functioning of these
                  systems. As beneficial as this development is for
                  our daily life, the consequences of a failure are
                  critical. Malfunctioning power supplies or
                  temperature regulation systems can cause the
                  close-down of an entire factory or data center. Heat
                  and air conditioning losses in buildings lead to a
                  large waste of the limited energy resources and
                  pollute the environment unnecessarily. To detect
                  these flaws as quickly as possible and to prevent
                  the negative consequences constant monitoring of
                  power lines and heat sources is necessary. To this
                  end, we propose a fully automatic system that
                  creates 3D thermal models of indoor
                  environments. The proposed system consists of a
                  mobile platform that is equipped with a 3D laser
                  scanner, an RGB camera and a thermal camera. A novel
                  3D exploration algorithm ensures efficient data
                  collection that covers the entire scene. The data
                  from all sensors collected at different positions is
                  joined into one common reference frame using
                  calibration and scan matching. In the
                  post-processing step a model is built and points of
                  interest are automatically detected. A viewer is
                  presented that aids experts in analyzing the heat
                  flow and localizing and identifying heat
                  leaks. Results are shown that demonstrate the
                  functionality of the system.},
  doi          = {10.1016/j.aei.2014.06.002},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/advei2014.pdf},  
}


@InProceedings{PCV2014,
  author       = {J. Schauer and A. N{\"u}chter},
  title        = {{Efficient Point Cloud Collision Detection and
                  Analysis in a Tunnel Environment using Kinematic
                  Laser Scanning and k-d Tree Search}},
  booktitle    = {Proceedings of the Photogrammetric
                  Computer Vision (PCV '14)},
  series       = {ISPRS Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XL-3},
  pages        = {289--295},
  year         = {2014},
  address      = {Z{\"u}rich, Switzerland},
  month        = {September},
  abstract     = {Measuring the structure gauge of tunnels and other
                  narrow passages has so far been the only way to
                  evaluate whether large vehicles can pass through
                  them. But especially for very long vehicles like
                  train wagons and their cargo, the structure gauge is
                  an insufficient measure because the center part of
                  the vehicle between two bogies will inevitably leave
                  the swept volume of its cross section when moving
                  along any other trajectory than a straight line
                  perpendicular to its cross section. In addition, the
                  vehicle as well as the cargo must keep a minimum
                  safety margin from the environment at all points of
                  its trajectory. This paper explores an automated
                  method to check for possible collisions of a model
                  represented by a 3D point cloud moving through the
                  3D point cloud of an environment. We were given
                  environment data of a train track through a narrow
                  tunnel where simply relying on the structure gauge
                  would indicate that a given wagon would pass through
                  without any collision even though in reality, the
                  train wagon would collide with the inner tunnel wall
                  inside a sharp turn of the tracks. The k-d tree
                  based collision detection method presented in this
                  paper is able to correctly highlight these
                  collisions and indicate the penetration depth of
                  each colliding point of the environment into the
                  model of the train wagon. It can be generalized for
                  any setup where two static point clouds have to be
                  tested for intersection along a trajectory.},
  doi          = {10.5194/isprsarchives-XL-3-289-2014},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/pcv2014.pdf},
  
}


@InProceedings{ROBOTYKI2014,
  author       = {J. Bedkowski and K. Majek and A. N{\"u}chter},
  title        = {Nowy algorytm 6DSLAM wykorzystujacy semantyczne
                  rozpoznanie otoczenia},
  booktitle    = {13 Krajowka Konferencja Robotyki Kudowa Zdroj Prace
                  Naukowe, Elektronika z. 194 Post. Robotyki Tom II},
  pages        = {513--520},
  year         = {2014},
  month        = {June},
  abstract     = {W artykule przedstawiono modyfikację algorytmu
                  6DSLAM wykorzystującą semantyczne rozpoznawanie
                  otoczenia. Zastosowanie semantycznego podejścia nie
                  tylko poprawia w porównaniu do klasycznej metody
                  dokładność tworzonej mapy metrycznej przez robota
                  mobilnego, ale także umożliwia tworzenie takiej mapy
                  w trudnych warunkach terenowych. Przedstawiono
                  eksperymenty tworzenia mapy metrycznej/semantycznej
                  budynków uwzględniając jazdę poziomą oraz kierunku
                  pionowym po schodach. Porównano wynik z poprzednią
                  implementacją algorytmu 6DSLAM. Nowe podejście
                  poprawia spójność oraz dokładność mapy
                  metrycznej. Zastosowanie semantycznego rozpoznawania
                  otoczenia pozwala na rozszerzenie mapy metrycznej o
                  nowe informacje o charakterze jakościowym, w tym
                  przypadku rozróżniane są ściany, podłoga, sufit oraz
                  punkty charakteryzujące się otoczeniem
                  nieuporządkowanym.},
}


@InProceedings{COMMV2014,
  author       = {J. Elseberg and D. Borrmann and J. Schauer and
                  A. N{\"u}chter and D. Koriath and U. Rautenberg},
  title        = {{A sensor skid for precise 3D modeling of production
                  lines}},
  booktitle    = {Proceedings of the Commision V Symposium Close-range
                  imaging, ranging and applications},
  series       = {ISPRS Annals Photogrammetry and Remote Sensing,
                  Spatial Inf. Sci., II-5.},
  year         = {2014},
  month        = {June},
  pages        = {117--122},
  address      = {Riva del Garda, Italy},
  abstract     = {Motivated by the increasing need of rapid
                  characterization of environments in 3D, we designed
                  and built a sensor skid that automates the work of
                  an operator of terrestrial laser scanners. The
                  system combines terrestrial laser scanning with
                  kinematic laser scanning and uses a novel semi-rigid
                  SLAMmethod. It enables us to digitize factory
                  environments without the need to stop
                  production. The acquired 3D point clouds are precise
                  and suitable to detect objects that collide with
                  items moved along the production line.},
  doi          = {10.5194/isprsannals-II-5-117-2014},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/isprs-commision5-symposium2014.pdf},
}


@InProceedings{3DTAGE2014,
  author       = {H. Houshiar and D. Borrmann and A. N{\"u}chter},
  title        = {{Fortlaufende semantische 3D-Kartierung von
                  arch{\"a}ologischen Ausgrabungsst{\"a}tten}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2014, Jade Hochschule},
  pages        = {268--277},
  year         = {2014},
  month        = {February},
  abstract     = {Das 3D Laserscanning ist Stand der Technik bei der
                  Modellierung arch{\"a}ologischer Ausgrabungsst{\"a}tten,
                  historischer Anlagen und sogar ganzer St{\"a}dte oder
                  Landschaften. Die Dokumentation der Befunde auf
                  einer Ausgrabungsst{\"a}tte ist eine wesentliche
                  arch{\"a}ologische Aufgabe. Ein automatisiertes System
                  w{\"u}rde diesen Prozess beschleunigen und die Anzahl
                  der Fehler auf ein Minimum reduzieren. Dieser
                  Beitrag stellt einen neuen Ansatz in der
                  Dokumentation industrieller Arch{\"a}ologie vor. Er
                  besteht aus einer Reihe von Tools zur Erfassung und
                  Registrierung von 3D-Daten auf
                  Ausgrabungsst{\"a}tten. Wir stellen ein effizientes
                  Werkzeug zur Verf{\"u}gung f{\"u}r die Visualisierung der
                  erworbenen 3D-Punktwolken im 3D- und 2D-Modus. Der
                  Hauptzweck dieser Software ist Arch{\"a}ologen ein
                  einfach zu bedienendes Tool f{\"u}r die semantische
                  Kartierung vor Ort zu bieten. Es enth{\"a}lt Funktionen
                  f{\"u}r die Auswahl und Kennzeichnung von Funden. Jedes
                  Label kann mit weiteren Informationen versehen
                  werden. Diese Daten werden im XML-Format exportiert
                  und dienen als Eingabe f{\"u}r andere Systeme und
                  Datenbanken.},
}


@periodical{JRAD2014Ed,
  editor       = {A. N{\"u}chter and R. B. Rusu and D. Holz and D. Munoz},
  title        = {Journal of Robotics and Autonomous Systems (JRAS)},
  issuetitle   = {Special Issue on Semantic Perception, Mapping and
                  Exploration},
  volume       = {62},
  number       = {5},
  pages        = {617--618},
  month        = {May},
  year         = {2014},
} 



@Article{JRAS2014,
  author       = {A. N{\"u}chter and R. B. Rusu and D. Holz and D. Munoz},
  title        = {{Editorial: Semantic Perception, Mapping and Exploration}},
  journal      = {Journal of Robotics and Autonomous Systems (JRAS),
                  Special Issue on Semantic Perception, Mapping and
                  Exploration},
  year         = {2014},
  volume       = {62},
  number       = {5},
  pages        = {1--2},
  month        = {May},
  doi          = {10.1016/j.robot.2013.10.002},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/editorial2013.pdf},
}


@InProceedings{3DUI2014,
  author       = {G. Bruder and F. Steinicke and A. N{\"u}chter},
  title        = {Immersive Point Cloud Virtual Environments},
  booktitle    = {Proceedings of IEEE Symposium on 3D User Interfaces
                  3DUI Proceedings of IEEE Symposium on 3D User
                  Interfaces (3DUI '14) Poster},
  pages        = {161--162},
  year         = {2014},
  month        = {March},
  abstract     = {Today's three-dimensional (3D) virtual environments
                  (VEs) are usually based on textured polygonal 3D
                  models, which represent the appearance and geometry
                  of the virtual world. However, some application
                  domains require other graphical paradigms, which are
                  currently not adequately addressed by 3D user
                  interfaces. We introduce a novel approach for a
                  technical human-robot telepresence setup that allows
                  a human observer to explore a VE, which is a 3D
                  reconstruction of the real world based on point
                  clouds. Such point cloud virtual environments
                  (PCVEs) represent the external environment, and are
                  usually acquired by 3D scanners. We present an
                  application scenario, in which a mobile robot
                  captures 3D scans of a terrestrial environment,
                  which are automatically registered to a coherent
                  PCVE. This virtual 3D reconstruction is displayed in
                  an immersive virtual environment (IVE) in which a
                  user can explore the PCVE. We explain and describe
                  the technical setup, which opens up new vistas of
                  presenting a VE as points rather than a polygonal
                  representation.},
  doi          = {10.1109/3DUI.2014.6798870},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3dui2014.pdf},
}

@Article{TVT2014,
  author       = {Qingquan Li and Long Chen and Ming Li and Shih-Lung
                  Shaw and A. N{\"u}chter},
  title        = {{A Sensor-Fusion Drivable-Region and Lane-Detection
                  System for Autonomous Vehicle Navigation in
                  Challenging Road Scenarios}},
  journal      = {IEEE Transactions on Vehicular Technology},
  year         = {2014},
  volume       = {63},
  number       = {2},
  pages        = {540--555},
  month        = {February},
  abstract     = {Autonomous vehicle navigation is challenging since
                  various types of road scenarios in real urban
                  environments have to be considered, particularly
                  when only perception sensors are used, without
                  position information. This paper presents a novel
                  real-time optimal-drivable-region and lane detection
                  system for autonomous driving based on the fusion of
                  light detection and ranging (LIDAR) and vision
                  data. Our system uses a multisensory scheme to cover
                  the most drivable areas in front of a vehicle. We
                  propose a feature-level fusion method for the LIDAR
                  and vision data and an optimal selection strategy
                  for detecting the best drivable region. Then, a
                  conditional lane detection algorithm is selectively
                  executed depending on the automatic classification
                  of the optimal drivable region. Our system
                  successfully handles both structured and
                  unstructured roads. The results of several
                  experiments are provided to demonstrate the
                  reliability, effectiveness, and robustness of the
                  system.},
  doi          = {10.1109/TVT.2013.2281199},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/tvt2013.pdf},
}


% --- 2013 ---


@InProceedings{ICAR2013_1,
  author       = {G. Demisse and D. Borrmann and A. N{\"u}chter},
  title        = {{Interpreting Thermal 3D Models of Indoor
                  Environments for Energy Efficiency}},
  booktitle    = {Proceedings of the 16th IEEE International
                  Conference on Advanced Robotics (ICAR '13)},
  pages        = {1--8},
  year         = {2013},
  address      = {Montevideo, Uruguay},
  month        = {November},
  abstract     = {In recent years, 3D models of buildings are used in
                  maintenance and inspection, preservation, and other
                  building related applications. However, the usage of
                  these models is limited, because most models are
                  pure representations with no or little associated
                  semantics. In this paper, we present a pipeline of
                  techniques used for interior interpretation, object
                  detection, and adding energy related semantics to
                  windows of a 3D thermal model. A sequence of
                  algorithms is presented for building the fundamental
                  semantics of a 3D model. Furthermore, a Markov
                  Random Field is used to model the temperature
                  distribution of detected windows to further label
                  the windows as either open, closed or damaged.},
  doi          = {10.1109/ICAR.2013.6766550},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icar2013_1.pdf},  
}


@InProceedings{ICAR2013_2,
  author       = {B. Okal and A. N{\"u}chter},
  title        = {{Sliced Curvature Scale Space for Representing and
                  Recognizing 3D Object}},
  booktitle    = {Proceedings of the 16th IEEE International
                  Conference on Advanced Robotics (ICAR '13)},
  pages        = {1--7},
  year         = {2013},
  address      = {Montevideo, Uruguay},
  month        = {November},
  abstract     = {Perception plays a key role in the development of
                  intelligent autonomous systems. In particular object
                  recognition and registration tasks are crucial to
                  any intelligent autonomous system such as autonomous
                  cars or personal robots. The representation of 3D
                  object sensor measurements largely affects the
                  choice of higher level processing possible on the
                  sensor data. We explore the use of scale space
                  theory via the curvature scale space and extend it
                  to represent 3D objects in our new SCSS (Sliced
                  Curvature Scale Space) framework. We further develop
                  techniques of further processing the SCSS
                  representation including feature extraction and
                  dimensionality reduction for use in learning
                  frameworks. We perform an array of experiments to
                  validate the effectiveness of our method and
                  demonstrate recognition performance using support
                  vector machines. The results indicate that our new
                  representation retains the nice qualities of the
                  original curvature scale space method while being
                  robust and compact for 3D object representation and
                  recognition.},
  doi          = {10.1109/ICAR.2013.6766545},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icar2013_2.pdf},
}


@InProceedings{ICAR2013_3,
  author       = {H. Houshiar and J. Elseberg and D. Borrmann and
                  A. N{\"u}chter},
  title        = {{Panorama Based Point Cloud Reduction and Registration}},
  booktitle    = {Proceedings of the 16th IEEE International
                  Conference on Advanced Robotics (ICAR '13)},
  pages        = {1--8},
  year         = {2013},
  address      = {Montevideo, Uruguay},
  month        = {November},
  abstract     = {To reconstruct environments 3D point clouds acquired
                  by laser scanners are registered. This is an
                  important but also time consuming part of any
                  mapping system for mobile robots. The time needed
                  for mapping is drastically reduced when the size of
                  the input data is reduced. This paper examines
                  different ways of reducing the size of point clouds
                  without losing vital information for the matching
                  process. We present novel point cloud reduction
                  methods on the basis of panorama images. It is shown
                  that the reduced point clouds are ideally suited for
                  feature based registration on panorama images. We
                  evaluate the presented reduction methods based on
                  their effect on the performance of the registration
                  algorithm.},
  doi          = {10.1109/ICAR.2013.6766587},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icar2013_3.pdf},
}


@InProceedings{TA2013,
  author       = {A. N{\"u}chter and J. Elseberg and D. Borrmann},
  title        = {{Irma3D -- An Intelligent Robot for Mapping Applications}},
  booktitle    = {Proceedings of the 3rd IFAC Symposium on Telematics
                  Applications (TA '13)},
  pages        = {119--124},
  address      = {Seoul, Korea},
  year         = {2013},
  month        = {November},
  abstract     = {Motivated by the increasing need of rapid
                  characterization of environments in 3D, we designed
                  a robot system that automates the work of an
                  operator of terrestrial laser scanners. The built
                  system enables to work without using special targets
                  or markers and thus enables the surveyors to save
                  more than 75\% of the time spent in the
                  field. Another impulse for developing the platform
                  is the demand for a remote multi-sensor inspection
                  tool. The robot is capable of surveying remote sites
                  or danger areas, such as plants, underground mines,
                  tunnels, caves, or channels. The results are
                  precise, multi-modal digital 3D maps. This paper
                  presents the recently developed robot Irma3D, its
                  hardware, the developed interconnected software
                  modules, the associated sensor calibration methods
                  and a few applications.},
  doi          = {10.3182/20131111-3-KR-2043.00011},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ta2013.pdf},
}


@InProceedings{SSG2013,
  author       = {J. Elseberg and D. Borrmann and A. N{\"u}chter.},
  title        = {A Study of Scan Patterns for Mobile Mapping},
  booktitle    = {Proceedings of the ISPRS Conference on "Serving
                  Society with Geoinformatics" (ISPRS-SSG '13)},
  series       = {ISPRS Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XL-7/W2},
  pages        = {75--80},
  year         = {2013},
  address      = {Antalya, Turkey},
  month        = {November},
  abstract     = {Mobile terrestrial scanning systems automate
                  terrestrial laser scanning. Continous scanning
                  mobile terrestrial systems constantly spin the
                  terrestrial laser scanner and thus combine
                  terrestrial scanning with kinematic laser
                  scanning. This paper presents a scan pattern
                  analysis for these systems. We aim at finding the
                  most advantageous combination of terrestrial and
                  kinematic systems. The resulting 3D point cloud
                  depends on the scan pattern and the trajectory and
                  velocity of the mobile system.},
  doi          = {10.5194/isprsarchives-XL-7-W2-75-2013},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ssg2013.pdf},
}


@InProceedings{CIPA2013,
  author       = {H. Houshiar and D. Borrmann and J. Elseberg and
                  A. N{\"u}chter and S. Winkler and F. N{\"a}th},
  title        = {{On-Site Semantic mapping of Archeological Excavation Areas}},
  booktitle    = {Proceedings of the XXIV International CIPA
                  Symposium},
  series       = {ISPRS Annals Photogrammetry and Remote
                  Sensing. Spatial Inf. Sci., II-5/W1},
  year         = {2013},
  pages        = {163--168},
  month        = {September},
  address      = {Strasbourg, France},
  abstract     = {3D laser scanning is the state of the art in
                  modeling archaeological excavation sites, historical
                  sites and even entire cities or landscapes. The
                  documentation of findings on an excavation site is
                  an essential archaeological task. Automated systems
                  accelerate this process and decrease the amount of
                  error to a minimum. This paper presents a new
                  documentation approach in industrial archaeology. It
                  consists of a set of tools for recording and
                  registering 3D data from excavation sites. We
                  provide an efficient tool for visualization of
                  acquired 3D point clouds in 3D and 2D modes. The
                  main purpose of this software is to provide an easy
                  to use, on-site semantic mapping tool for
                  archaeologists. It includes functions for selecting
                  and labeling findings. Additional information can be
                  provided for each label. This data is exported to an
                  XML format and serves as input for other systems and
                  databases.},
  doi          = {10.5194/isprsannals-II-5-W1-163-2013},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/cipa2013.pdf},
}


@Article{REMSEN2013,
  author       = {J. Elseberg and D. Borrmann and A. N{\"u}chter},
  title        = {{Algorithmic solutions for computing accurate
                  maximum likelihood 3D point clouds from mobile laser
                  scanning platforms}},
  journal      = {Remote Sensing},
  year         = {2013},
  volume       = {5},
  number       = {11},
  pages        = {5871--5906},
  month        = {November},
  abstract     = {Mobile laser scanning puts high requirements on the
                  accuracy of the positioning systems and the
                  calibration of the measurement system. We present a
                  novel algorithmic approach for calibration with the
                  goal of improving the measurement accuracy of mobile
                  laser scanners. We describe a general framework for
                  calibrating mobile sensor platforms that estimates
                  all configuration parameters for any arrangement of
                  positioning sensors, including odometry. In
                  addition, we present a novel semi-rigid Simultaneous
                  Localization and Mapping (SLAM) algorithm that
                  corrects the vehicle position at every point in time
                  along its trajectory, while simultaneously improving
                  the quality and precision of the entire acquired
                  point cloud. Using this algorithm, the temporary
                  failure of accurate external positioning systems or
                  the lack thereof can be compensated for. We
                  demonstrate the capabilities of the two newly
                  proposed algorithms on a wide variety of datasets.},
  doi          = {10.3390/rs5115871},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/remotesensing2013.pdf},
}


@Article{GIM2013,
  author       = {A. N{\"u}chter and J. Elseberg and D. Borrmann},
  title        = {{Automation in 3D Laser Scanning -- From an
                  Automated Tripod towards Optimal 3D Point Clouds
                  from Mobile Laser Scanning}},
  journal      = {GIM International},
  year         = {2013},
  volume       = {27},
  number       = {9},
  month        = {September},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/GIM2013.pdf},
}


@InProceedings{KI2013,
  author       = {C. Gurau and A. N{\"u}chter},
  title        = {{Challenges in Using Semantic Knowledge for 3D
                  Object Classification}},
  booktitle    = {Proceedings of the KI 2013 Workshop on Visual and
                  Spatial Cognition, KIK - KI \& Kognition Workshop
                  Series},
  year         = {2013},
  address      = {Koblenz, Germany},
  month        = {September},
  abstract     = {To cope with a wide variety of tasks, robotic
                  systems need to perceive and understand their
                  environments. In particular, they need a
                  representation of individual objects, as well as
                  contextual relations between them. Visual
                  information is the primary data source used to make
                  predictions and inferences about the world. There
                  exists, however, a growing tendency to introduce
                  high-level semantic knowledge to enable robots to
                  reason about objects. We use the Semantic Web
                  framework to represent knowledge and make inferences
                  about sensor data, in order to detect and classify
                  objects in the environment. The contribution of this
                  work is the identification of several challenges
                  that co-occur when combining sensor data processing
                  with such a reasoning method.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ki2013.pdf},
}


@InProceedings{IAV2013,
  author       = {Liang Zhang and Qingquan Li and Ming Li and Q.Zh Mao
                  and A. N{\"u}chter},
  title        = {{Multiple Vehicle-like Target Tracking Based on
                  Velodyne Lidar}},
  booktitle    = {Proceedings of the 6th IFAC Symposium on Intelligent
                  Autonomous Vehicles (IAV '13)},
  year         = {2013},
  volume       = {8},
  number       = {1},
  address      = {Gold Coast, Australia},
  month        = {June},
  abstract     = {This paper proposes a novel multiple vehicle-like
                  target tracking method based on a Velodyne HDL64E
                  light detection and ranging (LiDAR) system. The
                  proposed method combines multiple hypothesis
                  tracking (MHT) algorithm with dynamic point cloud
                  registration (DPCR), which is able to solve the
                  multiple vehicle-like target tracking in highly
                  dynamic urban environments without any auxiliary
                  information from GPS or IMU. Specifically, to track
                  targets consistently, the DPCR is developed to
                  calculate accurately the pose of the ego-vehicle for
                  the transformation of raw measurements taken in the
                  moving coordinate systems into a static absolute
                  coordinate system; while in turn, MHT helps to
                  improve the performance of DPCR by discriminating
                  and removing the dynamic points from the
                  scene. Furthermore, the proposed MHT method is also
                  able to solve the occlusion problem existing in the
                  point cloud. Experiments on sets of urban
                  environments prove that the presented method is
                  effective and robust, even in highly dynamic
                  environments.},
  doi          = {10.3182/20130626-3-AU-2035.00058},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iav2013.pdf},
}


@InProceedings{SOCG2013,
  author       = {D. Borrmann and P.~J. de Rezende and C.~C. de Souza
                  and S.~P. Fekete and S. Friedrich and A. Kr{\"o}ller
                  and A. N{\"u}chter and C. Schmidt and D.~C. Tozoni},
  title        = {{Point Guards and Point Clouds: Solving general Art
                  Gallery Problems}},
  booktitle    = {Proccedings of the 20th ACM Annual Symposium on
                  Computational Geometry (SoCG '13)},
  pages        = {347--348},
  year         = {2013},
  address      = {Rio de Janeiro, Brazil},
  month        = {June},
  abstract     = {In this video, we illustrate how one of the
                  classical areas of computational geometry has gained
                  in practical relevance, which in turn gives rise to
                  new, fascinating geometric problems. In particular,
                  we demonstrate how the robot platform IRMA3D can
                  produce high-resolution, virtual 3D environments,
                  based on a limited number of laser scans. Computing
                  an optimal set of scans amounts to solving an
                  instance of the Art Gallery Problem (AGP): Place a
                  minimum number of stationary guards in a polygonal
                  region P, such that all points in P are guarded.},
  doi          = {10.1145/2462356.2462361},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/socg2013.pdf},
}


@Article{JOSER2013,
  author       = {J. B\k{e}dkowski and K. Majek and A. N{\"u}chter},
  title        = {{General Purpose Computing on Graphics Processing
                  Units for Robotic Applications}},
  journal      = {Journal of Software Engineering for Robotics
                  (JOSER)},
  year         = {2013},
  volume       = {4},
  number       = {1},
  pages        = {23--33},
  abstract     = {This paper deals with research related with the
                  improvements of state of the art algorithms used in
                  robotic applications based on parallel
                  computation. The main goal is to decrease the
                  computational complexity of 3D cloud of points
                  processing in such applications as: data filtering,
                  normal vector estimation, data registration and
                  calculation of point feature histogram. The
                  presented results efficiently improve the existing
                  implementations with minimal lost of accuracy. The
                  main contribution is a regular grid decomposition
                  originally implemented for nearest neighborhood
                  search. This data structure is used almost for all
                  presented methods, it provides an efficient method
                  for decreasing the time of computation. The results
                  are compared with well-known robotic frameworks such
                  as PCL and 3DTK.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/joser2013.pdf},
}

@InProceedings{3DTAGE2013_1,
  author       = {D. Borrmann and H. Houshiar and J. Elseberg and
                  A. N{\"u}chter},
  title        = {{Vom Kombinieren von 3D-Modellen mit Farb- und
                  Temperaturinformationen}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2013, Jade Hochschule},
  pages        = {246--253},
  year         = {2013},
  month        = {February},
  abstract     = {In den letzten Jahren wurden grosse Fortschritte bei
                  der automatischen Registrierung unterschiedlicher
                  Daten gemacht, zum Beispiel bei Laserscandaten,
                  Fotos und Thermalbilder. So wurden zuverl{\"a}ssige
                  Methoden entwickelt, um Daten aus einem einzelnen
                  Aufnahmeprozess zu registrieren. Probleme bereiten
                  jedoch Daten, die zu unterschiedlichen Zeiten
                  aufgenommen wurden. Dies ist aber essentiell um
                  wertvolle Informationen verschiedener Sensoren zu
                  kombinieren und den Anforderungen an die einzelnen
                  Sensoren gerecht zu werden. Verwertbare
                  Informationen von Thermalbildern erh{\"a}lt man
                  ausschliesslich ohne st{\"o}rende Einfl{\"u}sse des
                  Sonnenlichts. Farbfotos hingegen werden optimal bei
                  guten Farbverh{\"a}ltnissen aufgenommen. Laserscanner
                  sind relativ robust gegen{\"u}ber wechselnden
                  Lichtverh{\"a}ltnissen. F{\"u}r alle Sensoren ist ein
                  Aufnahmezeitpunkt w{\"u}nschenswert, zu dem m{\"o}glichst
                  wenige dynamische Objekte die Szene
                  beeinflussen. {\"U}blicherweise ist eine genaue
                  Georeferenzierung der Daten notwendig um Konsistenz
                  zwischen den einzelnen Modellen zu erreichen. Dies
                  erh{\"o}ht den Aufwand f{\"u}r die Datenakquise
                  erheblich. In diesem Beitrag pr{\"a}sentieren wir
                  robuste Verfahren zur vereinfachten Kombination
                  unterschiedlicher Datens{\"a}tze. },
}

@InProceedings{3DTAGE2013_2,
  author       = {A. N{\"u}chter and J. Elseberg and D. Borrmann},
  title        = {{Optimale 3D-Punktwolken aus mobilen
                  Laserscandaten}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2013, Jade Hochschule},
  month        = {February},
  pages        = {186--193},
  year         = {2013},
  abstract     = {Mobiles Laserscanning stellt hohe Anforderungen an
                  die Exaktheit der Positionierung und Kalibrierung
                  des Messsystems, da sich bereits kleinste
                  Ungenauigkeiten in den akquirierten 3D-Daten
                  drastisch niederschlagen k{\"o}nnen. Dieser Beitrag
                  pr{\"a}sentiert eine neuen Ansatz zur Kalibrierung und
                  zur L{\"o}sung des SLAM-Problems mit dem Ziel, die
                  Messgenauigkeit des mobilen Scansystems zu
                  optimieren. Bei dem Kalibrierungsverfahren handelt
                  es sich um eine allgemeing{\"u}ltige Methode, die die
                  Positionierung und Orientierung s{\"a}mtlicher Sensoren
                  berechnet, einschliesslich der Odometrie. Der
                  vorgestellte SLAM-Ansatz (Simultaneous Localization
                  and Mapping) ist semi-rigide. Dabei wird die
                  Trajektorie so deformiert und jede Pose dahingehend
                  optimiert, dass die Gesamtqualit{\"a}t der 3D-Punktwolke
                  optimal wird. Das SLAM-Verfahren kann kurzfristige
                  Sensorausf{\"a}lle oder Ungenauigkeiten ausgleichen und
                  erm{\"o}glicht vielf{\"a}ltige neue Anwendungen. },
}


@InProceedings{3DARCH2013,
  author       = {R.-C. Dumitru and D. Borrmann and A. N{\"u}chter},
  title        = {{Interior Reconstruction using the 3D Hough
                  Transform}},
  booktitle    = {Proceedings of the 5th ISPRS International Workshop
                  3D-ARCH 2013: "3D Virtual Reconstruction and
                  Visualization of Complex Architectures"},
  year         = {2013},
  series       = {ISPRS Archives Photogrammetry and Remote Senssing
                  Spatial Inf. Sci., Volume XL-5/W1},
  address      = {Trento, Italy},
  month        = {February},
  abstract     = {Laser scanners are often used to create accurate 3D
                  models of buildings for civil engineering purposes,
                  but the process of manually vectorizing a 3D point
                  cloud is time consuming and error-prone (Adan and
                  Huber, 2011). Therefore, the need to characterize
                  and quantify complex environments in an automatic
                  fashion arises, posing challenges for data
                  analysis. This paper presents a system for 3D
                  modeling by detecting planes in 3D point clouds,
                  based on which the scene is reconstructed at a high
                  architectural level through removing automatically
                  clutter and foreground data. The implemented
                  software detects openings, such as windows and doors
                  and completes the 3D model by inpainting.},
  doi          = {10.5194/isprsarchives-XL-5-W1-65-2013},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3darch2013.pdf},
  
}


@Article{ISPRS2013,
  author       = {J. Elseberg and D. Borrmann and A. N{\"u}chter},
  title        = {{One Billion Points in the Cloud --- An Octree for
                  Efficient Processing of 3D Laser Scans}},
  journal      = {ISPRS Journal of Photogrammetry \& Remote Sensing
                  (JPRS), Special issue on terrestrial 3D modelling},
  year         = {2013},
  volume       = {76},
  pages        = {76--88},
  month        = {February},
  abstract     = {Automated 3-dimensional modeling pipelines include
                  3D scanning, registration, data abstraction, and
                  visualization. All steps in such a pipeline require
                  the processing of a massive amount of 3D data, due
                  to the ability of current 3D scanners to sample
                  environments with a high density. The increasing
                  sampling rates make it easy to acquire Billions of
                  spatial data points. This paper presents algorithms
                  and data structures for handling these data. We
                  propose an efficient octree to store and compress 3D
                  data without loss of precision. We demonstrate its
                  usage for an exchange file format, fast point cloud
                  visualization, sped-up 3D scan matching, and shape
                  detection algorithms. We evaluate our approach using
                  typical terrestrial laser scans.},
  doi          = {10.1016/j.isprsjprs.2012.10.004},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/isprs2012.pdf},
}


% --- 2012 ---


@InProceedings{ICMV2012,
  author       = {M.-C. Sima and A. N{\"u}chter},
  title        = {{An extension of the Felzenszwalb-Huttenlocher
                  segmentation to 3D point clouds}},
  booktitle    = {Proceedings of the 5th International Conference on
                  Machine Vision (ICMV '12)},
  year         = {2012},
  series       = {SPIE 8783},
  address      = {Wuhan, China},
  month        = {October},
  abstract     = {This paper investigates the segmentation algorithm
                  proposed by Felzenszwalb and Huttenlocher1 and its
                  compatibility to 3D point clouds acquired with
                  state-of-the-art 3D laser scanners. To use the
                  algorithm, we adapt the range and intensity data to
                  the smoothed graph structure used by the
                  algorithm. We investigate the influence of the
                  algorithm’s parameters to its performance and result
                  that are meaningful to both the machines and the
                  humans.},
  doi          = {10.1117/12.2010527},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icmv2012.pdf},
}


@InProceedings{IROS2012Video,
  author       = {D. Borrmann and H. Afzal and J. Elseberg and A. N{\"u}chter},
  title        = {{Thermal 3D Modeling of Indoor Environments for Saving Energy}},
  booktitle    = {Proceedings of the IEEE/RSJ International Conference
                  on Intelligent Robots and Systems (IROS '12)},
  pages        = {4538--4539},
  year         = {2012},
  address      = {Vilamoura, Algarve, Portugal},
  month        = {October},
  abstract     = {Heat and air conditioning losses in buildings and
                  factories lead to a large amount of wasted
                  energy. The Action Plan for Energy Efficiency [4] of
                  the European Commission estimates that the largest
                  cost-effective energy savings potential lies in
                  residential ($\sim$27\%) and commercial ($\sim$30\%)
                  buildings. Imagine a technology that creates a
                  precise digital 3D model of heat distribution and
                  heat flow enabling one to detect all sources of
                  wasted energy and to modify buildings to reach these
                  savings. This video presents our approach to this
                  task. Methods for creating a consistent laser scan
                  model enhanced with information from thermal and
                  optical cameras are presented.},
  doi          = {10.1109/IROS.2012.6386265},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iros2012_2.pdf},
}


@InProceedings{IROS2012,
  author       = {J. Elseberg and D. Borrmann and A. N{\"u}chter},
  title        = {{6DOF Semi-Rigid SLAM for Mobile Scanning}},
  booktitle    = {Proceedings of the IEEE/RSJ International Conference
                  on Intelligent Robots and Systems (IROS '12)},
  pages        = {1865--1870},
  year         = {2012},
  address      = {Vilamoura, Algarve, Portugal},
  month        = {October},
  abstract     = {The terrestrial acquisition of 3D point clouds by
                  laser range finders has recently moved to mobile
                  platforms. Measuring the environment while
                  simultaneously moving the vehicle demands a high
                  level of accuracy from positioning systems such as
                  the IMU, GPS and odometry. We present a novel
                  semi-rigid SLAM algorithm that corrects the global
                  position of the vehicle at every point in time,
                  while simultaneously improving the quality and
                  accuracy of the entire acquired map. Using the
                  algorithm the temporary failure of positioning
                  systems or the lack thereof can be compensated
                  for. We demonstrate the capabilities of our approach
                  on a wide variety of systems and data sets.},
  doi          = {10.1109/IROS.2012.6385509},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iros2012_1.pdf},
}



@InProceedings{SYROCO2012_4,
  author       = {D. Borrmann and A. N{\"u}chter and M. Dakulovic and
                  I. Maurovic and I. Petrovic and D. Osmankovic and
                  J. Velagic},
  title        = {{The Project ThermalMapper -- Thermal 3D Mapping of
                  Indoor Environments for Saving Energy}},
  booktitle    = {Proceedings of the 10th International IFAC Symposium
                  on Robot Control (SYROCO '12)},
  year         = {2012},
  volume       = {10},
  address      = {Dubrovnik, Croatia},
  month        = {September},
  abstract     = {Heat and air conditioning losses in buildings and
                  factories lead to a large amount of wasted
                  energy. The Action Plan for Energy Efficiency of the
                  Commission of the European Communities (2008)
                  estimates that the largest cost-effective energy
                  savings potential lies in residential ($\sim$27\%)
                  and commercial ($\sim$30\%) buildings. Imagine a
                  technology that creates a precise digital 3D model
                  of heat distribution and heat flow enabling one to
                  detect all sources of wasted energy and to modify
                  buildings to reach these savings. This paper
                  presents our overall approach to map indoor
                  environments with thermal data in 3D.},
  doi          = {10.3182/20120905-3-HR-2030.00045},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/syroco2012_1.pdf},
}



@InProceedings{SYROCO2012_3,
  author       = {D. Borrmann and H. Afzal and J. Elseberg and A. N{\"u}chter},
  title        = {{Mutual Calibration for 3D Thermal Mapping}},
  booktitle    = {Proceedings of the 10th International IFAC Symposium
                  on Robot Control (SYROCO '12)},
  year         = {2012},
  volume       = {10},
  address      = {Dubrovnik, Croatia},
  month        = {September},
  abstract     = {Three-dimensional digital heat distribution maps are
                  needed to assess the energy efficiency of real
                  estates. The availability of such maps are of great
                  importance for reducing the ecological footprint of
                  houses, buildings, and factories. Designing estates
                  has reached the point, where so-called Passivhaus
                  buildings make extensive use of the intrinsic heat
                  from internal sources such as waste heat from
                  lighting, white goods, and other electrical devices,
                  but without using dedicated heaters. In our approach
                  for creating high-precise heat distribution maps a
                  robot is equipped with a 3D laser scanner, a thermal
                  camera, and a color camera. Data from all the
                  sensors are combined to model the environment
                  precisely. This paper describes the setup of the
                  sensors and the processing of the acquired data,
                  including the automatic co-calibration needed to
                  fulfill this task.},
  doi          = {10.3182/20120905-3-HR-2030.00073},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/syroco2012_2.pdf},
}



@InProceedings{SYROCO2012_2,
  author       = {S. May and R. Koch and R. Scherlipp and A. N{\"u}chter},
  title        = {{Robust Registration of Narrow-Field-of-View Range
                  Images}},
  booktitle    = {Proceedings of the 10th International IFAC Symposium
                  on Robot Control (SYROCO '12)},
  year         = {2012},
  volume       = {10},
  address      = {Dubrovnik, Croatia},
  month        = {September},
  abstract     = {This paper focuses on range image registration for
                  robot localization and environment mapping. It
                  extends the well-known Iterative Closest Point (ICP)
                  algorithm in order to deal with erroneous
                  measurements. The dealing with measurement errors
                  originating from external lighting, occlusions or
                  limitations in the measurement range is only
                  rudimentary in literature. In this context we
                  present a non-parametric extension to the ICP
                  algorithm that is derived directly from measurement
                  modalities of sensors in projective space. We show
                  how aspects from reverse calibration can be embedded
                  in search-tree-based approaches. Experiments
                  demonstrate the applicability to range sensors like
                  the Kinect device, Time-of-Flight cameras and 3D
                  laser range finders. As a result the image
                  registration becomes faster and more robust.},
  doi          = {10.3182/20120905-3-HR-2030.00057},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/syroco2012_3.pdf},
}

@InProceedings{SYROCO2012_1,
  author       = {M. Al-khawaldah and A. N{\"u}chter},
  title        = {{Multi-Robot Exploration and Mapping with a rotating
                  3D Scanner}},
  booktitle    = {Proceedings of the 10th International IFAC Symposium
                  on Robot Control (SYROCO '12)},
  year         = {2012},
  volume       = {10},
  address      = {Dubrovnik, Croatia},
  month        = {September},
  abstract     = {This paper investigates the field of exploration and
                  map-building with multiple cooperating mobile
                  robots. New and efficient exploration and mapping
                  technique is proposed by employing laser
                  scanners. The paper also aims to extend existing
                  exploration and mapping techniques of single robot
                  to multi-robot to increase the exploration
                  efficiency (i.e. to reduce the environment
                  exploration time required). The goal of the proposed
                  method is to have multiple mobile robots exploring a
                  given unknown environment as fast as possible, while
                  coordinating their actions and sharing their local
                  maps in certain time instances. In the suggested
                  technique, each robot is equipped with a laser
                  scanner that is continuously rotating to scan the
                  environment, and is employing a frontier-based
                  exploration algorithm which is important to guide
                  the robots during the exploration. A new factor is
                  introduced to enhance the performance of the
                  frontier-based exploration. This factor aims at
                  spreading robots in the environment to reduce
                  overlap.},
  doi          = {10.3182/20120905-3-HR-2030.00025},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/syroco2012_4.pdf},
}



@InProceedings{ISER2012,
  author       = {J. Elseberg, D. Borrmann and A. N{\"u}chter},
  title        = {{Automatic and Full Calibration of Mobile Laser Scanning Systems}},
  booktitle    = {Proceedings of the 13th International Symposium of
                  Experimental Robotics (ISER '12)},
  pages        = {907--917},
  year         = {2012},
  number       = {88},
  series       = {Springer Tracts in Advanced Robotics},
  address      = {Quebec City, Canada},
  month        = {June},
  abstract     = {Mobile scanning, i.e., the practice of mounting
                  laser scanners on moving platforms is an efficient
                  way to acquire accurate and dense 3D point clouds of
                  outdoor environments for urban and regional planning
                  and architecture. The mobile scenario puts high
                  requirements on the accuracy of the calibration of
                  the measurement system, as small calibration
                  inaccuracies lead to large errors in the resulting
                  point cloud. We propose a novel algorithm for the
                  calibration of a mobile scanning system that
                  estimates the calibration parameters for all sensor
                  components simultaneously without relying on
                  additional hardware. We evaluate the calibration
                  algorithm on several real world data sets where
                  ground truth is available via an accurate geodetic
                  model.},
  doi          = {0.1007/978-3-319-00065-7_60},
}



@InProceedings{IAS2012,
  author       = {D. Borrmann and J. Elseberg and A, N{\"u}chter},
  title        = {{Thermal 3D Mapping of Building Facades}},
  booktitle    = {Proceedings of the 8th Conference on Intelligent
                  Autonomous Systems (IAS '12)},
  pages        = {173--182},
  year         = {2012},
  volume       = {2},
  number       = {192},
  series       = {Advances in Intelligent Systems and Computing},
  address      = {Jeju Island, Korea},
  publisher    = {Springer},
  month        = {June},
  abstract     = {Never before in history were humans as dependant on
                  energy as we are today. But the natural ressources
                  are limited and a waste of energy has drastic
                  influences on the environment. In their Action Plan
                  for Energy Efficiency [6] the European Commission
                  estimates that the largest and cost-effictive energy
                  savings potential lies in residential ($\sim$27\%)
                  and commercial ($\sim$30\%) buildings. To eliminate
                  heat and air conditioning losses in buildings and
                  factories heat and air leaks need to be localized
                  and identified. Imagine the availability of a
                  complete 3D model of every building that architects
                  can use to analyze the heat insulation of buildings
                  and to identify necessary modifications. In these 3D
                  models temperature peaks are not only detectable but
                  also their extent is visible. A robot equiped with a
                  3D laser scanner, a thermal camera, and a color
                  camera constitutes the basis for our approach. The
                  data from all three sensors and from different
                  locations are joined into one high-precise 3D model
                  that shows the heat distribution. This paper
                  describes the setup of the hardware and the methods
                  applied to create the 3D model, including the
                  automatic co-calibration of the sensors. Challenges
                  unique to the task of thermal mapping of outdoor
                  environments are discussed.},
  doi          = {10.1007/978-3-642-33926-4_16},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ias2012.pdf},
}


@InProceedings{IV2012,
  author       = {Long Chen and Qingquan Li and Quanwen Zhu and Ming
                  Li and A. N{\"u}chter},
  title        = {{3D LIDAR Point Cloud based Intersection Recognition
                  for Autonomous Driving}},
  booktitle    = {Proceedings of the 2012 IEEE Intelligent Vehicles
                  Symposium (IV '12)},
  pages        = {456--461},
  year         = {2012},
  address      = {Alcala de Henares, Madrid, Spain},
  month        = {June},
  abstract     = {Finding road intersections in advance is crucial for
                  navigation and path planning of moving autonomous
                  vehicles, especially when there is no position or
                  geographic auxiliary information available. In this
                  paper, we investigate the use of a 3D point cloud
                  based solution for intersection and road segment
                  classification in front of an autonomous vehicle. It
                  is based on the analysis of the features from the
                  designed beam model. First, we build a grid map of
                  the point cloud and clear the cells which belong to
                  other vehicles. Then, the proposed beam model is
                  applied with a specified distance in front of
                  autonomous vehicle. A feature set based on the
                  length distribution of the beam is extracted from
                  the current frame and combined with a trained
                  classifier to solve the road-type classification
                  problem, i.e., segment and intersection. In
                  addition, we also make the distinction between
                  +-shaped and T-shaped intersections. The results are
                  reported over a series of real-world data. A
                  performance of above 80\% correct classification is
                  reported at a real-time classification rate of 5
                  Hz.},
  doi          = {10.1109/IVS.2012.6232219},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iv2012.pdf},
}


@InProceedings{IV2012_WS,
  author       = {Ming Li and Wei Li and Jian Wang and Qingquan Li and A. N{\"u}chter},
  title        = {Dynamic VeloSLAM -- Preliminary Report on 3D Mapping
                  of Dynamic Environments},
  booktitle    = {Proceedings of the 2012 IEEE Intelligent Vehicles
                  Symposium (IV '12), Workshop on Navigation,
                  Perception, Accurate Positioning and Mapping for
                  Intelligent Vehicles},
  year         = {2012},
  address      = {Alcala de Henares, Madrid, Spain},
  month        = {June},
  abstract     = {3D mapping using point cloud registration is a basic
                  inevitable problem for many applications, especially
                  for modeling of large scale complicated
                  environments. This paper presents a novel approach
                  for mapping highly dynamic environments, i.e., we
                  present a system capable for mapping road traffic
                  scenarios. Given 3D laser scans acquired at a high
                  frame rate and no other sensor input, a 3D map is
                  built by removing dynamic parts of the scene and
                  estimating the ego-motion of the vehicle precisely
                  at the same time. We extend the well-known ICP
                  algorithm for HDL-64 laser scan data and build a
                  system for solving the simultaneous localization and
                  mapping problem in urban road scenarios. This paper
                  presents initial results on two data sets.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iv2012_ws.pdf},
}


@InProceedings{VMAC2012,
  author       = {G. Demisse and R. Mihalyi and B. Okal and D. Poudel
                  and J. Schauer and A. N{\"u}chter},
  title        = {Mixed Palletizing and Task Completion for Virtual Warehouses},
  booktitle    = {Virtual Manufacturing Automation (VMAC '12) Workshop
                  at IEEE International Conference Robotics and
                  Automation, ICRA},
  year         = {2012},
  address      = {St. Paul, MN, USA},
  month        = {May},
  abstract     = {Palletizing, or packing rectangular boxes of various
                  sizes onto pallets, is a frequently encountered task
                  in many commercial scenarios, e.g., shipment of
                  goods. An extension of this problem is the automated
                  placement of boxes on pallets, henceforth task
                  completion, by means of industrial robot arms. The
                  palletizing and task completion problems are treated
                  in the context of the IEEE ICRA 2012 Virtual
                  Manufacturing Automation Competition. We approach
                  the palletizing challenge by a winner-takes-all
                  strategy, where multiple heuristics are evaluated
                  against the given datasets. Our results show a
                  performance comparable to that of the commercial
                  software benchmark from the previous
                  competitions. We solve task completion in USARSim by
                  picking boxes and placing them on a pallet. Our
                  inverse kinematics algorithm consists of a geometric
                  and numeric component. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/vmac2012.pdf},
}


@InProceedings{SPMK2012_WS,
  author       = {Ming Li and Wei Li and Jian Wang and Qingquan Li and
                  A. N{\"u}chter},
  title        = {Towards Reliable Object Anchoring in Highly Dynamic
                  Traffic Scenes},
  booktitle    = {Proceedings of the ICRA 2012 WORKSHOP Semantic
                  Perception and Mapping for Knowledge-enabled Service
                  Robotics (with interactive session and
                  demonstrations)},
  year         = {2012},
  address      = {St. Paul, MN, USA},
  month        = {May},
}


@InProceedings{ROBOTIK2012,
  author       = {T. Wiemann and K. Lingemann and A. N{\"u}chter and
                  J. Hertzberg},
  title        = {A Toolkit for Automatic Generation of Polygonal Maps
                  -- Las Vegas Reconstruction},
  booktitle    = {Proceedings of the 7th German Conference Robotik
                  2012},
  pages        = {446--451},
  year         = {2012},
  address      = {Munich, Germany},
  month        = {May},
  abstract     = {In this paper we present a new open source software
                  package for automatic generation of polygonal 3D
                  maps from point cloud data for robotic purposes
                  called "Las Vegas Reconstruction Toolkit" [11]. The
                  implemented algorithms focus on minimizing the
                  computational costs and optimization of the number
                  of polygons in the generated maps. Furthermore, we
                  present two application examples: 6D self
                  localization and scene interpretation. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/robotik2012.pdf},
}


@InProceedings{3DTAGE2012_1,
  author       = {D. Borrmann and J. Elseberg and P. N. K.C. and A. N{\"u}chter},
  title        = {{Ein Punkt pro Kubikmeter -- pr{\"a}zise
                  Registrierung von terrestrischen Laserscans mit
                  Scanmatching}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2012, Jade Hochschule},
  pages        = {4--11},
  year         = {2012},
  month        = {February},
  abstract     = { Die pr{\"a}zise Registrierung von terrestrischen
                  Laserscans erfordert geschultes Personal,
                  professionelle Scanner Hardware, meist propriet{\"a}re
                  Software sowie gen{\"u}gend Zeit f{\"u}r die Anbringung von
                  Zielmarken, Durchf{\"u}hrung der Messungen und die
                  anschlie&szilg;ende Verarbeitung der akquirierten
                  Daten. Wir zeigen, wie man auf einige dieser Punkte
                  verzichten und dennoch zu hochqualitativen
                  Ergebnissen kommen kann.  Im Zuge einer
                  Bachelorarbeit wurde ein der Vermessungstechnik
                  fremder Informatikstudent damit beauftragt, den
                  Campus der Jacobs University auf einer Teilfl{\"a}che
                  von ca. 9 ha zu vermessen. Zur Verf{\"u}gung standen ein
                  professioneller Scanner in Form des Riegl
                  VZ-400. Insgesamt wurden 131 Aufnahmen mit insgesamt
                  {\"u}ber 2 Milliarden Punkten gemacht. Nach manueller
                  Vorregistrierung der Punktwolken erfolgte die
                  pr{\"a}zise Anordnung dann vollautomatisch mit der frei
                  erh{\"a}ltlichen Software 3DTK, die dazu in der Lage war
                  die gesamte Datenmenge in k{\"u}rzester Zeit mit
                  h{\"o}chster Genauigkeit zu registrieren.},
}

@InProceedings{3DTAGE2012_2,
  author        = {A. N{\"u}chter and H. Houshair and D. Borrmann and
                  J. Elseberg},
  title         = {{Projektionen f{\"u}r die Scanregistrierung mit
                  Hilfe von Bildmerkmalen}},
  booktitle     = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2012, Jade Hochschule},
  month         = {February},
  pages         = {12--21},
  year          = {2012},
  abstract      = {Die Aufnahme und das Registrieren von
                  terrestrischen 3D-Laserscans ist eine grundlegende
                  Fragestellung in vielen Anwendungsbereichen. Um den
                  Prozess des Registrierens von zwei 3D-Scans zu
                  automatisieren, werden Merkmale aus den Scandaten
                  extrahiert, diese einander zugeordnet (assoziiert)
                  und die Registrierung berechnet. Als Merkmale kommen
                  neben Strukturmerkmalen wie 3D-Fl{\"a}chen oft
                  Bildmerkmale zum Einsatz. Dazu wird ein fl{\"a}chiges
                  Bild der Reflektionswerte eines 3D-Scans erzeugt. In
                  der Regel wird hierbei auf der x-Achse der
                  Rotationswinkel um die Stehachse des Scanners und
                  auf der y-Achse der Rotationswinkel des Spiegels
                  abgetragen. In diesem Beitrag untersuchen wir wie
                  sich die Registrierungsergebnisse {\"a}ndern, wenn
                  andere Projektionen verwendet werden. Dazu
                  analysieren wir mit Hilfe von SIFT-Merkmalen die
                  gleichm{\"a}ßige Rektangularprojektion, die zylindrische
                  Projektion, die Hochachsenrojektion, die
                  Mercatorprojektion, die Rektangularprojektion, die
                  Pannini-Projektion, sowie die stereographische
                  Projektion.},
}


@Book{Lehrbuch_2012,
  author       = {J. Hertzberg and K. Lingemann and A. N{\"u}chter},
  title        = {{Mobile Roboter: Eine Einf{\"u}hrung aus Sicht der Informatik}},
  publisher    = {Springer},
  year         = {2012},
  series       = {eXamen.press},
  address      = {Heidelberg, Germany},
  pages        = {390},
  doi          = {10.1007/978-3-642-01726-1},
}


@Article{JOSER2012,
  author       = {J. Elseberg and S. Magnenat and R. Siegwart and A. N{\"u}chter},
  title        = {Comparison on nearest-neigbour-search strategies and
                  implementations for efficient shape registration},
  journal      = {Journal of Software Engineering for Robotics (JOSER)},
  year         = {2012},
  volume       = {3},
  number       = {1},
  pages        = {2--12},
  abstract     = {The iterative closest point (icp) algorithm is one
                  of the most popular approaches to shape registration
                  currently in use. At the core of icp is the
                  computationally-intensive determination of nearest
                  neighbors (NN). As of now there has been no
                  comprehensive analysis of competing search
                  strategies for NN. This paper compares several
                  libraries for nearest-neighbor search (NNS) on both
                  simulated and real data with a focus on shape
                  registration. In addition, we present a novel
                  efficient implementation of NNS via k-d trees as
                  well as a novel algorithm for NNS in octrees.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/joser2012.pdf},
}


@Article{AVN2012,
  author       = {J. Elseberg and D. Borrmann and A. N{\"u}chter},
  title        = {{Eine Milliarde 3D-Punkte mit Standardhardware
                  verarbeiten -- Processing One Billion 3D Points on a
                  Standard Computer}},
  journal      = {Allgemeine Vermessungs-Nachrichten (AVN)},
  year         = {2012},
  volume       = {119},
  number       = {1},
  pages        = {11--23},
  month        = {January},
  abstract     = {Dieser Beitrag stellt eine neue Implementation der
                  Octree-Datenstruktur vor. Sie erm{\"o}glicht es, eine
                  Milliarde 3D-Punkte in 8 GB Hauptspeicher exakt zu
                  repr{\"a}sentieren und effiziente Algorithmen zu
                  implementieren. Der Octree gibt eine Hierarchie vor,
                  die dazu verwendet werden kann, grosse Punktwolken
                  zu inspizieren und fl{\"u}ssig in ihnen zu
                  navigieren. Des Weiteren schlagen wir in diesem
                  Artikel ein effizentes bin{\"a}res Dateiformat f{\"u}r den
                  Austausch von 3D-Scans vor.}, 
}


% --- 2011 ---


@Article{AUTOMATIKA2011,
  author       = {J. Sprickerhof and A. N{\"u}chter and K. Lingemann
                  and J. Hertzberg},
  title        = {{A Heuristic Loop Closing Technique for Large-Scale
                  6D SLAM}},
  journal      = {AUTOMATIKA -- Journal for Control, Measurement,
                  Electronics, Computing and Communications, Special
                  Issue with selected papers from the 4th European
                  Conference on Mobile Robots},
  year         = {2011},
  volume       = {52},
  number       = {3},
  month        = {December},
  abstract     = {This paper presents a novel heuristic for correcting
                  scan pose estimations after loop closing in SLAM
                  using 3D laser scans. Contrary to state of the art
                  approaches, the built SLAM graph is sparse, and
                  optimization is done without any iteration between
                  the SLAM front and back end, yielding a highly
                  efficient loop closing method.  Several experiments
                  were carried out in an urban environment and
                  evaluated against ground truth. The results are
                  compared to other state of the art algorithms,
                  proving the high quality, yet achieved faster by an
                  order of magnitude. },
  doi          = {10.1080/00051144.2011.11828420},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/automatika2011.pdf},
}


@InProceedings{ICAT2011_3,
  author       = {F. Grosan and A. Tandrau and and A. N{\"u}chter},
  title        = {{Localizing Google SketchUp Models in Outdoor 3D
                  Scans}},
  booktitle    = {Proceedings of the XXIII International Symposium on
                  Information, Communication and Automation
                  Technologies (ICAT '11)},
  year         = {2011},
  address      = {Sarajevo, Bosnia},
  month        = {October},
  publisher    = {IEEE Xplore},
  abstract     = {This work introduces a novel solution for localizing
                  objects based on search strings and freely available
                  Google SketchUp models. To this end we automatically
                  download and preprocess a collection of 3D models to
                  obtain equivalent point clouds. The outdoor scan is
                  segmented into individual objects, which are
                  sequentially matched with the models by a variant of
                  iterative closest points algorithm using seven
                  degrees of freedom and resulting in a highly precise
                  pose estimation of the object. An error function
                  evaluates the similarity level. The approach is
                  verified using various segmented cars and their
                  corresponding 3D models.},
  doi          = {10.1109/ICAT.2011.6102106},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icat2011_3.pdf},
}


@InProceedings{ICAT2011_2,
  author       = {J. Elseberg and D. Borrmann and A. N{\"u}chter},
  title        = {{Full Wave Analysis in 3D Laser Scans for Vegetation
                  Detection in Urban Environments}},
  booktitle    = {Proceedings of the XXIII International Symposium on
                  Information, Communication and Automation
                  Technologies (ICAT '11)},
  year         = {2011},
  address      = {Sarajevo, Bosnia},
  month        = {October},
  publisher    = {IEEE Xplore},
  abstract     = {This paper presents a novel technique for detecting
                  vegetation of virtually all forms in terrestrial
                  laser scanning data of urban environments. We make
                  use of a modern laser range finder capability to
                  measure multiple echoes per laser pulse via Full
                  Wave Analysis. The algorithm is able to efficiently,
                  i.e., less than acquisition time, identify
                  vegetation to a high degree of accuracy (more than
                  99 percent). We present and evaluate three
                  alternatives to classify candidate regions as either
                  vegetation or non-vegetation. },
  doi          = {10.1109/ICAT.2011.6102101},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icat2011_2.pdf},
}


@InProceedings{ICAT2011_1,
  author       = {J. Elseberg and D. Borrmann and A. N{\"u}chter},
  title        = {{Efficient Processing of Large 3D Point Clouds}},
  booktitle    = {Proceedings of the XXIII International Symposium on
                  Information, Communication and Automation
                  Technologies (ICAT '11)},
  year         = {2011},
  address      = {Sarajevo, Bosnia},
  month        = {October},
  publisher    = {IEEE Xplore},
  abstract     = {Autonomous robots equipped with laser scanners
                  acquire data at an increasingly high
                  rate. Registration, data abstraction and
                  visualization of this data requires the processing
                  of a massive amount of 3D data. The increasing
                  sampling rates make it easy to acquire Billions of
                  spatial data points. This paper presents algorithms
                  and data structures for handling this data. We
                  propose an efficient octree to store and compress 3D
                  data without loss of precision. We demonstrate its
                  usage for fast 3D scan matching and shape detection
                  algorithms. We evaluate our approach using typical
                  data acquired by mobile scanning platforms.},
  doi          = {10.1109/ICAT.2011.6102102},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icat2011_1.pdf},
}


@InProceedings{ECMR2011,
  author       = {A. N{\"u}chter and S. Feyzabadi and D. Qiu and
                  S. May},
  title        = {{SLAM à la carte - GPGPU for Globally Consistent
                  Scan Matching}},
  booktitle    = {Proceedings of the 4th European Conference on Mobile
                  Robots (ECMR '11)},
  year         = {2011},
  address      = {{\"O}rebro, Sweden},
  month        = {September},
  url          = {The computational complexity of SLAM is large and
                  constitutes a challenge for real-time processing of
                  a huge amount of sensor data with the limited
                  resources of a mobile robot. Often, notebooks are
                  used to control a mobile system and even these
                  computing devices have nowadays graphics cards which
                  allow general purpose computation using many
                  cores. SLAM à la carte (graphique) exploits these
                  capabilities and carries out 3D scan registrations
                  on the GPU. A speed-up of more than one order of
                  magnitude for precise 3D mapping is reported. },
}


@InProceedings{3DCMA2011,
  author       = {A. N{\"u}chter and S. Gutev and D. Borrmann and J. Elseberg},
  title        = {{Skyline-Based Registration of 3D Laser Scans}},
  booktitle    = {Proceedings of the Joint ISPRS workshop on 3D city
                  modelling \& applications and the 6th 3D GeoInfo
                  (3DCMA '11), The Chinese Academic Journal (CD ROM
                  version) CN 11-9251/G},
  year         = {2011},
  address      = {Wuhan, China},
  month        = {June},
  abstract     = {Acquisition and registration of terrestrial 3D laser
                  scans is a fundamental task in mapping and modeling
                  of cities in three dimensions. To automate this task
                  marker-free registration methods are required. Based
                  on the existence of skyline features this paper
                  proposes a novel method. The skyline features are
                  extracted from panoramic 3D scans and encoded as
                  strings enabling the use of string matching for
                  merging the scans. Initial results of the proposed
                  method in the old city center of Bremen are
                  presented.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3dcma2011.pdf},
}


@Article{GSIS2011,
  author       = {A. N{\"u}chter and S. Gutev and D. Borrmann and J. Elseberg},
  title        = {{Skyline-Based Registration of 3D Laser Scans}},
  journal      = {Journal Geo-spatial Information Science (GSIS),
                  Special Issue with selected papers from the 3D City
                  Modeling and Applications Workshop},
  year         = {2011},
  volume       = {14},
  number       = {2},
  pages        = {85--90},
  month        = {May},
  abstract     = {Acquisition and registration of terrestrial 3D
                  laser scans is a fundamental task in mapping and
                  modeling of cities in three dimensions. To automate
                  this task marker-free registration methods are
                  required. Based on the existence of skyline features
                  this paper proposes a novel method. The skyline
                  features are extracted from panoramic 3D scans and
                  encoded as strings enabling the use of string
                  matching for merging the scans. Initial results of
                  the proposed method in the old city center of Bremen
                  are presented. },
  doi          = {10.1007/s11806-011-0449-4},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3dcma2011.pdf},
}


@InProceedings{3DTage2011,
  author       = {J. Elseberg and D. Borrmann and A. N{\"u}chter},
  title        = {{Eine effiziente Octree-Datenstruktur f{\"u}r das
                  Verarbeiten von grossen 3D-Punktwolken}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2011, Fachhochschule Oldenburg/Ostfr./Whv.},
  month        = {February},
  pages        = {72--79},
  year         = {2011},
  abstract     = {Dieser Beitrag stellt eine neue Implementation der
                  Octree-Datenstruktur vor, die es erm{\"o}glicht, eine
                  Milliarde 3D-Punkte in 8 GB Hauptspeicher exakt zu
                  repr{\"a}sentieren und effiziente Algorithmen zu
                  implementieren. Der Octree gibt eine Hierarchie vor,
                  die dazu verwendet werden kann, große Punktewolken
                  zu inspizieren und fl{\"u}ssig in ihnen zu navigieren.},
}


@Article{3DRESEARCH2011,
  author       = {D. Borrmann and J. Elseberg and A. N{\"u}chter and
                  K. Lingemann},
  title        = {{The 3D Hough Transform for Plane Detection in Point
                  Clouds -- A Review and A new Accumulator Design}},
  journal      = {Journal of 3D Research},
  year         = {2011},
  volume       = {2},
  number       = {2},
  pages        = {1--13},
  month        = {March},
  abstract     = {The Hough Transform is a well-known method for
                  detecting parameterized objects. It is the de facto
                  standard for detecting lines and circles in
                  2-dimensional data sets. For 3D it has attained
                  little attention so far. Even for the 2D case high
                  computational costs have lead to the development of
                  numerous variations for the Hough Transform. In this
                  article we evaluate different variants of the Hough
                  Transform with respect to their applicability to
                  detect planes in 3D point clouds reliably. Apart
                  from computational costs, the main problem is the
                  representation of the accumulator. Usual
                  implementations favor geometrical objects with
                  certain parameters due to uneven sampling of the
                  parameter space. We present a novel approach to
                  design the accumulator focusing on achieving the
                  same size for each cell and compare it to existing
                  designs. },
  doi          = {10.1007/3DRes.02(2011)3},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3dresearch2011.pdf},  
}


% --- 2010 ---


@InProceedings{SIMPAR2010,
  author       = {E. Digor and A. Birk and A. N{\"u}chter},
  title        = {Exploration Strategies for a Robot with a Continously Rotating 3D Scanner},
  booktitle    = {Proceedings of the Second International Conference
                  on Simulation, Modeling and Programming for
                  Autonomous Robots (SIMPAR '10)},
  pages        = {374--386},
  year         = {2010},
  volume       = {6472},
  series       = {Lecture Notes in Computer Science},
  address      = {Darmstadt, Germany},
  month        = {November},
  abstract     = {To benchmark the efficiency of exploration
                  strategies one has to use robot simulators. In an
                  exploration task, the robot faces an unknown
                  environment. Of course one could test the algorithm
                  in different real-world scenarios, but a competitive
                  strategy must have good performance in any
                  environment that can be systematically constructed
                  inside a simulator. This paper presents an
                  evaluation of exploration strategies we developed
                  for a specific sensor. A continously rotating 3D
                  laser scanner that scans only into one direction at
                  a time moves through the environment sampling the
                  surrounding. Our evaluation framework features an
                  efficient scanning and robot simulator for kinematic
                  feasible trajectories. We will show that shorter
                  trajectories do not necessarily imply quicker
                  exploration. A simple simulator framework is
                  sufficient for evaluating these properties of path
                  planning algorithms. },
  doi          = {10.1007/978-3-642-17319-6},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/simpar2010.pdf},
}


@InProceedings{WREM2010,
  author       = {D. Borrmann and J. Elseberg and S. S. Raunyar and
                  A. N{\"u}chter},
  title        = {Lifelong 3D Mapping -- Monitoring with a 3D Scanner},
  booktitle    = {Proceedings of the IROS Workshop on Robotics for
                  Environmental Monitoring (WREM '10)},
  year         = {2010},
  address      = {Taipei, Taiwan},
  month        = {October},
  abstract     = {Geodesy and surveying are the sciences for
                  monitoring the earth. In recent years traditional
                  surveying equipment has been pushed aside by the
                  emerging technology of laser scanners, that automate
                  the precise measurement of points in the
                  environment. A further step of automation is
                  achieved by operating the surveying equipment
                  automatically and the usage of robotic
                  mapping. Thus, robotic mapping will become a key
                  component in monitoring and surveillance tasks. This
                  paper evaluates a 3D laser scanner from surveying
                  for its usage in robotic monitoring tasks. We
                  examine how seasonal changes and weather conditions
                  impact the data of the 3D scanner and how to deal
                  with these changes. For this analysis 3D scans of
                  various predetermined locations on the campus of the
                  Jacobs University Bremen were taken on a weekly
                  basis over a period of 13 weeks using the RIEGL
                  VZ-400 3D laser range finder. The scans have been
                  registered by means of conventional surveying
                  markers, SIFT features and using our point cloud
                  based 6D SLAM framework. An analysis of the changes
                  in the environment over the course of the scanning
                  period and an evaluation of the matching results
                  complete the analysis.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/lifelong.pdf},
}


@InProceedings{IROS2010_1,
  author       = {J. Elseberg and D. Borrmann and A. N{\"u}chter and
                  K. Lingemann},
  title        = {{Non-Rigid Registration and Rectification of 3D
                  Laser Scans}},
  booktitle    = {Proceedings of the IEEE/RSJ International Conference
                  on Intelligent Robots and Systems (IROS '10)},
  pages        = {1546--1552},
  year         = {2010},
  address      = {Taipei, Taiwan},
  month        = {October},
  abstract     = {Three dimensional point clouds acquired by range
                  scanners often do not represent the environment
                  precisely due to noise and errors in the acquisition
                  process. These latter systematical errors manifest
                  as deformations of different kinds in the 3D range
                  image. This paper presents a novel approach to
                  correct deformations by an analysis of the
                  structures present in the environment and correcting
                  them by non-rigid transformations. The resulting
                  algorithms are used for creating high-accuracy 3D
                  indoor maps.},
  doi          = {10.1109/IROS.2010.5652278},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iros2010_1.pdf},
}


@InProceedings{IROS2010_2,
  author       = {K. Pathak and D. Borrmann and J. Elseberg and
                  N. Vaskevicius and A. Birk and A. N{\"u}chter},
  title        = {{Evaluation of the Robustness of Planar-Patches
                  based 3D-Registration using Marker-based
                  Ground-Truth in an Outdoor Urban Scenario}},
  booktitle    = {Proceedings of the IEEE/RSJ International Conference
                  on Intelligent Robots and Systems (IROS '10)},
  pages        = {5725--5730},
  year         = {2010},
  address      = {Taipei, Taiwan},
  month        = {October},
  abstract     = {The recently introduced Minimum Uncertainty Maximum
                  Consensus (MUMC) algorithm for 3D scene registration
                  using planar-patches is tested in a large outdoor
                  urban setting without any prior motion estimate
                  whatsoever. With the aid of a new overlap metric
                  based on unmatched patches, the algorithm is shown
                  to work successfully in most cases. The absolute
                  accuracy of its computed result is corroborated for
                  the first time by ground-truth obtained using
                  reflective markers. There were a couple of
                  unsuccessful scan-pairs. These are analyzed for the
                  reason of failure by formulating two kinds of
                  overlap metrics: one based on the actual overlapping
                  surface-area and another based on the extent of
                  agreement of range-image pixels. We conclude that
                  neither metric in isolation is able to predict all
                  failures, but that both taken together are able to
                  predict the difficulty level of a scan-pair
                  vis-à-vis registration by MUMC.},
  doi          = {10.1109/IROS.2010.5649648},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iros2010_2.pdf},
}


@Article{KI2009,
  author       = {J. Hertzberg and K. Lingemann and C. L{\"o}rken and
                  A. N{\"u}chter and S. Stiene and T. Wiemann},
  title        = {{3D-Roboterkartenbau in Osnabr{\"u}ck}},
  journal      = {KI -- K{\"u}nstliche Intelligenz: Themenschwerpunk
                  Simultaneous Localization and Mapping (SLAM)},
  year         = {2010},
  volume       = {24},
  number       = {3},
  pages        = {245--248},
  month        = {September},
  abstract     = {Seit Herbst 2004 existiert die Arbeitsgruppe
                  „Wissensbasierte Systeme“ am Institut f{\"u}r Informatik
                  der Universit{\"a}t Osnabr{\"u}ck. Ein Langfristziel der
                  Arbeitsgruppe besteht darin, Schlussfolgerungs- und
                  Planungsverfahren der KI f{\"u}r den Einsatz online und
                  onboard auf mobilen Robotern einsetzbar zu
                  machen. Ein daraus abgeleitetes Arbeitsthema ist der
                  Bau von semantischen Roboterkarten basierend auf
                  3D-Laserscans bei 6-dimensionalen Scanposen. Wir
                  geben einen {\"U}berblick {\"u}ber die wichtigsten
                  Ergebnisse dazu und {\"u}ber unsere Perspektive dieses
                  Themas f{\"u}r die Zukunft.},
  doi          = {10.1007/s13218-010-0032-4},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/kiart2010.pdf},
}


@InProceedings{IAV2010_2,
  author       = {J. W{\"u}lfing and J. Hertzberg and K. Lingemann and
                  A. N{\"u}chter and T. Wiemann and S. Stiene},
  title        = {{Towards Real Time Robot 6D Localization in a
                  Polygonal Indoor Map Based on 3D ToF Camera Data}},
  booktitle    = {Proceedings of the 5th IFAC Symposium on Intelligent
                  Autonomous Vehicles (IAV '10)},
  year         = {2010},
  address      = {Lecce, Italy},
  month        = {September},
  abstract     = {This paper reports a method and results for solving
                  the following problem: Given a 3D polygonal indoor
                  map and a mobile robot equipped with a 3D time of
                  flight (ToF) camera, localize at frame rate the 6D
                  robot pose with respect to the map. To solve the
                  problem, the polygonal map is represented for
                  efficient usage as a solid-leaf BSP tree; at each
                  control cycle, the 6D pose change is estimated a
                  priori from odometry or IMU, the expected ToF camera
                  view at the prior pose sampled from the BSP tree,
                  and the pose change estimation corrected a
                  posteriori by fast ICP matching of the expected and
                  the measured ToF image. Our experiments indicate
                  that, first, the method is in fact real-time
                  capable; second, the 6D pose is tracked reliably in
                  a correct map under regular sensor conditions; and
                  third, the tracking can recover from some faults
                  induced by local map inaccuracies and transient or
                  local sensing errors. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iav2010_1.pdf},
}


@InProceedings{IAV2010_1,
  author       = {D. Borrmann and J. Elseberg and K. Lingemann and
                  A. N{\"u}chter},
  title        = {{A Data Structure for the 3D Hough Transform for
                  Plane Detection}},
  booktitle    = {Proceedings of the 5th IFAC Symposium on Intelligent
                  Autonomous Vehicles (IAV '10)},
  year         = {2010},
  address      = {Lecce, Italy},
  month        = {September},
  abstract     = {The Hough Transform is a well-known method for
                  detecting parametrized objects. It is the de facto
                  standard for the detection of lines and circles in
                  2-dimensional data sets. For 3D it has attained
                  little attention so far. Apart from computational
                  costs, the main problem is the representation of the
                  accumulator: Usual implementations favor geometrical
                  objects with certain parameters due to uneven
                  sampling of the parameter space. In this paper we
                  present a novel approach to design the accumulator
                  focusing on achieving the same size for each
                  cell. The proposed accumulator is compared to
                  previously known designs. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iav2010.pdf},
}


@InProceedings{SSRR2010,
  author       = {T. Wiemann and A. N{\"u}chter and K. Lingemann and
                  S. Stiene and J. Hertzberg},
  title        = {{Automatic Construction of Polygonal Maps From Point
                  Cloud Data}},
  booktitle    = {Proceedings of the IEEE International Workshop on
                  Safety, Security and Rescue Robotics (SSRR '10)},
  year         = {2010},
  address      = {Bremen, Germany},
  month        = {July},
  abstract     = {This paper presents a novel approach to create
                  polygonal maps from 3D point cloud data. The gained
                  map is augmented with an interpretation of the
                  scene. Our procedure produces accurate maps of
                  indoor environments fast and reliably. These maps
                  are successfully used by different robots with
                  varying sensor configurations for reliable self
                  localization.},
  doi          = {10.1109/SSRR.2010.5981571},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ssrr2010.pdf},
}

@Article{CVIU2010,
  author       = {A. N{\"u}chter and J. Elseberg and P. Schneider and D. Paulus},
  title        = {{Study of Parameterizations for the Rigid Body Transformations of The Scan Registration Problem}},
  journal      = {Journal Computer Vision and Image Understanding (CVIU)},
  year         = {2010},
  volume       = {114},
  number       = {8},
  pages        = {963--980},
  month        = {August},
  abstract     = {The iterative closest point (ICP) algorithm is the
                  de facto standard for geometric alignment of
                  three-dimensional models when an initial relative
                  pose estimate is available. The basis of the
                  algorithm is the minimization of an error function
                  that takes point correspondences into account. Four
                  closed-form solution methods are known for
                  minimizing this function. This paper presents novel
                  linear solutions to the scan registration problem,
                  i.e., to the problem of putting and aligning 3D
                  scans in a common coordinate system. We extend the
                  methods for registering n-scans in a global and
                  simultaneous fashion, such that the registration of
                  the nth scan influences all previous registrations
                  in one step.},
  doi          = {10.1016/j.cviu.2010.03.007},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/cviu2010.pdf},
}

@InProceedings{3DTage2010,
  author       = {J. Elseberg and A. N{\"u}chter and D. Borrmann and
                  K. Lingemann},
  title        = {{Verbesserte Kartenqualit{\"a}t durch Thin Plate
                  Splines und Hough-Transformation}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2010, Fachhochschule Oldenburg/Ostfr./Whv.},
  month        = {January},
  pages        = {134--141},
  year         = {2010},
  abstract     = {Laserscanner sind pr{\"a}zise Messger{\"a}te zur Ermittlung
                  von Distanzwerten. Dennoch weist eine jede mit einem
                  Laserscanner akquirierte Punktwolke Fehler auf, die
                  auch durch Kalibrierung nicht vollst{\"a}ndig verhindert
                  werden k{\"o}nnen. Neben Sensorrauschen kommt es auch zu
                  systematischen Fehlern. Die meisten k{\"u}nstlich
                  geschaffenen Umgebungen bestehen aus einer großen
                  Anzahl ebener Fl{\"a}chen, die helfen k{\"o}nnen, die
                  Qualit{\"a}t von Laserscan-Karten zu verbessern. Dieser
                  Aufsatz stellt Methoden vor, die unter Zuhilfenahme
                  von ebenen Umgebungsstrukturen die Fehler in den
                  Laserscans durch nicht-rigide Verformungen
                  verringern},
}

@InProceedings{ICRA2010,
  author       = {A. N{\"u}chter and J. Elseberg and P. Schneider and D. Paulus},
  title        = {{Linearization of Rotations for Globally Consistent $n$-Scan Matching}},
  booktitle    = {Proceedings of the IEEE International Conference Robotics and Automation (ICRA '10)},
  address      = {Anchorage, Alaska, USA},
  pages        = {1373--1379},
  year         = {2010},
  month        = {May},
  abstract     = {The ICP (Iterative Closest Point) algorithm is the
                  de facto standard for geometric alignment of
                  three-dimensional models when an initial relative
                  pose estimate is available. The basis of the
                  algorithm is the minimization of an error function
                  that takes point correspondences into account. While
                  four closed-form solution methods are known for
                  minimizing this function, linearization seems
                  necessary for solving the global scan registration
                  problem. This paper presents such linear solutions
                  for registering n-scans in a global and simultaneous
                  fashion. It studies parameterizations for the rigid
                  body transformations of the n-scan registration
                  problem. },
  doi          = {10.1109/ROBOT.2010.5509306},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icra2010.pdf},
}


% --- 2009 ---


@Article{JFR2009_2,
  author       = {M. Magnusson and H. Andreasson and A. N{\"u}chter
                  and A. J. Lilienthal},
  title        = {{Automatic Appearance-Based Loop Detection from 3D
                  Laser Data Using the Normal Distributions
                  Transform}},
  journal      = {Journal of Field Robotics (JFR), Special Issue on
                  Three-Dimensional Mapping},
  year         = {2009},
  volume       = {26},
  number       = {11--12},
  pages        = {934--965},
  abstract     = {We propose a new approach to appearance-based loop
                  detection for mobile robots, using three-dimensional
                  (3D) laser scans. Loop detection is an important
                  problem in the simultaneous localization and mapping
                  (SLAM) domain, and, because it can be seen as the
                  problem of recognizing previously visited places, it
                  is an example of the data association
                  problem. Without a flat-floor assumption,
                  two-dimensional laser-based approaches are bound to
                  fail in many cases. Two of the problems with 3D
                  approaches that we address in this paper are how to
                  handle the greatly increased amount of data and how
                  to efficiently obtain invariance to 3D rotations. We
                  present a compact representation of 3D point clouds
                  that is still discriminative enough to detect loop
                  closures without false positives (i.e., detecting
                  loop closure where there is none). A low
                  false-positive rate is very important because wrong
                  data association could have disastrous consequences
                  in a SLAM algorithm. Our approach uses only the
                  appearance of 3D point clouds to detect loops and
                  requires no pose information. We exploit the normal
                  distributions transform surface representation to
                  create feature histograms based on surface
                  orientation and smoothness. The surface shape
                  histograms compress the input data by two to three
                  orders of magnitude. Because of the high compression
                  rate, the histograms can be matched efficiently to
                  compare the appearance of two scans. Rotation
                  invariance is achieved by aligning scans with
                  respect to dominant surface orientations. We also
                  propose to use expectation maximization to fit a
                  gamma mixture model to the output similarity
                  measures in order to automatically determine the
                  threshold that separates scans at loop closures from
                  nonoverlapping ones. We discuss the problem of
                  determining ground truth in the context of loop
                  detection and the difficulties in comparing the
                  results of the few available methods based on range
                  information. Furthermore, we present quantitative
                  performance evaluations using three real-world data
                  sets, one of which is highly self-similar, showing
                  that the proposed method achieves high recall rates
                  (percentage of correctly identified loop closures)
                  at low false-positive rates in environments with
                  different characteristics.},
  doi          = {10.1002/rob.20314},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/jfr2009_2.pdf},  
}


@Article{JFR2009_1,
  author       = {S. May and D. Dr{\"o}schel and D. Holz and S. Fuchs
                  and E. Malis and A. N{\"u}chter and J. Hertzberg},
  title        = {{3D Mapping with Time-of-Flight Cameras}},
  journal      = {Journal of Field Robotics (JFR), Special Issue on
                  Three-Dimensional Mapping},
  year         = {2009},
  volume       = {26},
  number       = {11--12},
  pages        = {892--914},
  abstract     = {This article investigates the use of time-of-flight
                  (ToF) cameras in mapping tasks for autonomous mobile
                  robots, in particular in simultaneous localization
                  and mapping (SLAM) tasks. Although ToF cameras are
                  in principle an attractive type of sensor for
                  three-dimensional (3D) mapping owing to their high
                  rate of frames of 3D data, two features make them
                  difficult as mapping sensors, namely, their
                  restricted field of view and influences on the
                  quality of range measurements by high dynamics in
                  object reflectivity; in addition, currently
                  available models suffer from poor data quality in a
                  number of aspects. The paper first summarizes
                  calibration and filtering approaches for improving
                  the accuracy, precision, and robustness of ToF
                  cameras independent of their intended usage. Then,
                  several ego motion estimation approaches are applied
                  or adapted, respectively, in order to provide a
                  performance benchmark for registering ToF camera
                  data. As a part of this, an extension to the
                  iterative closest point algorithm has been developed
                  that increases the robustness under restricted field
                  of view and under larger displacements. Using an
                  indoor environment, the paper provides results from
                  SLAM experiments using these approaches in
                  comparison. It turns out that the application of ToF
                  cameras is feasible to SLAM tasks, although this
                  type of sensor has a complex error characteristic.},
  doi          = {10.1002/rob.20321},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/jfr2009_1.pdf},
}


@InProceedings{ICVS2009,
  author       = {D. Qiu and S. May and A. N{\"u}chter},
  title        = {{GPU-accelerated Nearest Neighbor Search for 3D
                  Registration}},
  booktitle    = {Proceedings of the 7th International Conference on
                  Computer Vision Systems (ICVS '09)},
  pages        = {194--203},
  year         = {2009},
  number       = {5815},
  series       = {LNCS},
  address      = {Li\`{e}ge, Belgium},
  month        = {October},
  abstract     = {Nearest Neighbor Search (NNS) is employed by many
                  computer vision algorithms. The computational
                  complexity is large and constitutes a challenge for
                  real-time capability. The basic problem is in
                  rapidly processing a huge amount of data, which is
                  often addressed by means of highly sophisticated
                  search methods and parallelism. We show that NNS
                  based vision algorithms like the Iterative Closest
                  Points algorithm (ICP) can achieve real-time
                  capability while preserving compact size and
                  moderate energy consumption as it is needed in
                  robotics and many other domains. The approach
                  exploits the concept of general purpose computation
                  on graphics processing units (GPGPU) and is compared
                  to parallel processing on CPU. We apply this
                  approach to the 3D scan registration problem, for
                  which a speed-up factor of 88 compared to a
                  sequential CPU implementation is reported.},
  doi          = {10.1007/978-3-642-04667-4_20},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icvs2009.pdf},
}


@InProceedings{TLS2009,
  author       = {A. N{\"u}chter},
  title        = {{6D SLAM mit Global Konsistentem Scanmatching}},
  booktitle    = {Terrestrisches Laserscanning (TLS 2009) Beitr{\"a}ge
                  zum DVW-Seminar am 18. und 19. November in Fulda},
  pages        = {69--92},
  year         = {2009},
  address      = {Fulda, Germany},
  month        = {November},
  abstract     = { Terrestrisches Laserscanning (TLS) hat die in den
                  letzten Jahren die Vermessungstechnik
                  revolutioniert. Durch die Entwicklung des
                  kinematischen terrestrischen Laserscannings (k-TLS)
                  oder Mobile Mapping, das die Aufnahme von
                  geometrische Umgebungsinformation von einer bewegten
                  Plattform aus erlaubt, wurde ein wesentlicher
                  Schritt zur weiteren Automatisierung in der
                  Vermessungstechnik getan. Leider ist k-TLS nicht
                  {\"u}berall einsetzbar, da neben den Daten des
                  Laserscanners hochgenaue Informationen {\"u}ber die Pose
                  (Position und Orientierung) der mobilen Plattform
                  vorliegen m{\"u}ssen.  Technischer Fortschritt erlaubt
                  den Bau von autonomen Robotersystemen, die mit
                  3D-Laserscannern ausgestattet sind und es besteht
                  Potential f{\"u}r weitere Automatisierung. Dazu muss das
                  Problem der gleichzeitigen Lokalisation und
                  Kartierung gel{\"o}st werden. Dieses klassische
                  Robotikproblem ist ein Henne-und-Ei-Problem: Mit
                  genauster Kenntnis der Position des mobilen Roboters
                  lassen sich korrekte Karten erzeugen. Mit Hilfe von
                  Karten k{\"o}nnen sich Roboter sehr genau
                  lokalisieren. Beides gleichzeitig durchzuf{\"u}hren
                  stellt neue hohe Anforderungen an die Algorithmen,
                  die Scannerdaten verarbeiten. },
}


@InProceedings{IROS2009,
  author       = {S. May and D. Dr{\"o}schel and D. Holz and S. Fuchs
                  and A. N{\"u}chter},
  title        = {{Robust 3D-Mapping with Time-of-Flight Cameras}},
  booktitle    = {Proceedings of the IEEE/RSJ International Conference
                  on Intelligent Robots and Systems (IROS '09)},
  pages        = {1673--1678},
  year         = {2009},
  address      = {St. Louis, MO, USA},
  month        = {October},
  abstract     = {Time-of-flight cameras constitute a smart and fast
                  technology for 3D perception but lack in measurement
                  precision and robustness. The authors present a
                  comprehensive approach for 3D environment mapping
                  based on this technology. Imprecision of depth
                  measurements are properly handled by calibration and
                  application of several filters. Robust registration
                  is performed by a novel extension to the Iterative
                  Closest Point algorithm. Remaining registration
                  errors are reduced by global relaxation after
                  loop-closure and surface smoothing. A laboratory
                  ground truth evaluation is provided as well as 3D
                  mapping experiments in a larger indoor environment.},
  doi          = {10.1109/IROS.2009.5354684},
}


@InProceedings{ECMR2009,
  author       = {J. Sprickerhof and A. N{\"u}chter and K. Lingemann
                  and J. Hertzberg},
  title        = {{An Explicit Loop Closing Technique for 6D SLAM}},
  booktitle    = {Proceedings of the 4th European Conference on Mobile
                  Robots (ECMR '09)},
  year         = {2009},
  address      = {Mlini/Dubrovnic, Croatia},
  month        = {September},
  abstract     = {Simultaneous Localization and Mapping (SLAM) is the
                  problem of building a map of an unknown environment
                  by a mobile robot while at the same time navigating
                  the environment, using the unfinished map. For SLAM,
                  two tasks have to be solved: First reliable feature
                  extraction and data association, second the optimal
                  estimation of poses and features. These two parts
                  are often referred to as SLAM frontend and
                  backend. Algorithms that solve SLAM by using laser
                  scans commonly rely on matching closest points in
                  the frontend part. Then the SLAM front- and backend
                  have to be iterated to ensure that the map
                  converges.  This paper presents a novel approach for
                  solving SLAM using 3D laser range scans. We aim at
                  avoiding the iteration between the SLAM front- and
                  backend and propose a novel explicit loop closing
                  heuristic (ELCH). It dissociates the last scan of a
                  sequence of acquired scans, reassociates it to the
                  map, built so far by scan registration, and
                  distributes the difference in the pose error over
                  the SLAM graph. We describe ELCH in the context of
                  SLAM with 3D scans considering 6 DoF. The
                  performance is evaluated using ground truth data of
                  an urban environment. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ecmr2009.pdf},
}


@Article{IJAAIES2009,
  author       = {S. Frintrop and A. N{\"u}chter and K. Perv{\"o}lz
                  and H. Surmann and S. Mitri and J. Hertzberg},
  title        = {Attentive Classification},
  journal      = {International Journal of Applied Artificial
                  Intelligence in Engineering Systems},
  year         = {2009},
  volume       = {1},
  number       = {1},
  abstract     = { In this paper, we present a two-step approach for
                  object recognition based on principles of human
                  perception: Attentive Classification. First, regions
                  of interest are detected by a biologically motivated
                  attention system. Second, these regions are analyzed
                  by a fast classifier based on the Adaboost learning
                  technique. Thus, the classification effort is
                  restricted to a small data subset. The approach has
                  two advantages over normal classification: First,
                  the system becomes considerably faster, which is an
                  important factor for real-time systems. Second,
                  since the attention system is able to make use of
                  top-down target-information, the combination of the
                  systems yields a significant reduction of false
                  detections for objects which are usually difficult
                  to discriminate from the surrounding. We show the
                  performance of the system in several experiments in
                  robotic scenarios. The presented attentive
                  classification system represents an important step
                  towards effective general object recognition which
                  is fast, robust and flexibly adaptable to a current
                  task.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ijaai2009.pdf},
}


@InProceedings{ICRA2009_2,
  author       = {M. Magnusson and A. N{\"u}chter, C. L{\"o}rken and
                  A. J. Lilienthal and J. Hertzberg},
  title        = {{Evaluation of 3D Registration Reliability and Speed
                  -- A Comparison of ICP and NDT}},
  booktitle    = {Proceedings of the IEEE International Conference
                  Robotics and Automation (ICRA '09)},
  address      = {Kobe, Japan},
  pages        = {3907--3912},
  month        = {May},
  year         = {2009},
  abstract     = {To advance robotic science it is important to
                  perform experiments that can be replicated by other
                  researchers to compare different methods. However,
                  these comparisons tend to be biased, since
                  re-implementations of reference methods often lack
                  thoroughness and do not include the hands-on
                  experience obtained during the original development
                  process. This paper presents a thorough comparison
                  of 3D scan registration algorithms based on a 3D
                  mapping field experiment, carried out by two
                  research groups that are leading in the field of 3D
                  robotic mapping. The iterative closest points
                  algorithm (ICP) is compared to the normal
                  distributions transform (NDT). We also present an
                  improved version of NDT with a substantially larger
                  valley of convergence than previously published
                  versions.},
  doi          = {10.1109/ROBOT.2009.5152538},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icra2009_1.pdf},
}

@InProceedings{ICRA2009_1,
  author       = {M. Magnusson and H. Andreasson and A. N{\"u}chter
                  and A. J. Lilienthal},
  title        = {{Appearance-Based Place Recognition from 3D Laser
                  Data Using the Normal Distributions Transform}},
  booktitle    = {Proceedings of the IEEE International Conference
                  Robotics and Automation (ICRA '09)},
  address      = {Kobe, Japan},
  pages        = {23--28},
  month        = {May},
  year         = {2009},
  abstract     = {To advance robotic science it is important to
                  perform experiments that can be replicated by other
                  researchers to compare different methods. However,
                  these comparisons tend to be biased, since
                  re-implementations of reference methods often lack
                  thoroughness and do not include the hands-on
                  experiences obtained during the original development
                  process. This paper presents the results of a field
                  experiment, carried out by two research groups that
                  are leading in the field of 3D robotic mapping. The
                  iterative closest points algorithm (ICP) is compared
                  to the normal distributions transform (NDT).  We
                  also present an improved version of NDT with a
                  substantially larger valley of convergence than
                  previously published versions.},
  doi          = {10.1109/ROBOT.2009.5152712},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icra2009_2.pdf},
}


@InProceedings{3DTage2009,
  author       = {A. N{\"u}chter and J. Elseberg},
  title        = {{Linearisierte L{\"o}sung der ICP-Fehlerfunktion
                  f{"u}r global konsistentes Scanmatching}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2009, Fachhochschule Oldenburg/Ostfr./Whv.},
  month        = {January},
  pages        = {74--81},
  year         = {2009},
  abstract     = {Dieser Artikel beschreibt eine Linearisierung in
                  geschlossener Form f{\"u}r die Minimierung der
                  Fehlerfunktion, die beim ICP-Algorithmus
                  auftaucht. Die Linearisierung approximiert die
                  tats{\"a}chliche L{\"o}sung und nutzt die Annahme aus, dass
                  die auftretenden Winkel klein sind. Weiterhin zeigt
                  der Artikel die M{\"o}glichkeit auf, die Linearisierung
                  f{\"u}r global konsistentes Scanmatching zu
                  verwenden. Global konsistentes Scanmatching
                  minimiert den Gesamtfehler, wenn mehr als zwei
                  3D-Punktwolken vorliegen. },
}


@Article{eCIT2009,
  author       = {A. N{\"u}chter},
  title        = {{Parallel and Cached Scan Matching for Robotic 3D Mapping}},
  journal      = {Journal of Computing and Information Technology (eCIT)},
  year         = {2009},
  volume       = {17},
  number       = {1},
  pages        = {51--65},
  month        = {March},
  abstract     = {Intelligent autonomous acting of mobile robots in
                  unstructured environments requires 3D maps. Since
                  manual mapping is a tedious job, automatization of
                  this job is necessary. Automatic, consistent
                  volumetric modeling of environments requires a
                  solution to the simultaneous localization and map
                  building problem (SLAM problem). In 3D this task is
                  computationally expensive, since the environments
                  are sampled with many data points with state of the
                  art sensing technology. In addition, the solution
                  space grows exponentially with the additional
                  degrees of freedom needed to represent the robot
                  pose. Mapping environments in 3D must regard six
                  degrees of freedom to characterize the robot
                  pose. This paper summarizes our 6D SLAM algorithm
                  and presents novel algorithmic and technical means
                  to reduce computation time, i.e., the data structure
                  cached k-d tree and parallelization. The
                  availability of multi-core processors as well as
                  efficient programming schemes as OpenMP permit the
                  parallel execution of robotics tasks. },
  doi          = {10.2498/cit.1001174},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ecit2009.pdf},
}

@Book{3DMAPPING,
  author       = {A. N{\"u}chter},
  title        = {3D Robotic Mapping: The Simultaneous Localization
                  and Mapping Problem with Six Degrees of Freedom},
  publisher    = {Springer},
  year         = {2009},
  number       = {52},
  series       = {Springer Tracts in Advanced Robotics},
  month        = {February},
  doi          = {10.1007/978-3-540-89884-9},
}


% --- 2008 ---


@InProceedings{WS3DMAP1_2008,
  author       = {M. Magnusson and A. N{\"u}chter and C. L{\"o}rken
                  and A. J. Lilienthal and J. Hertzberg},
  title        = {3D Mapping the Kvarntorp Mine: A Field Experiment
                  for Evaluation of 3D Scan Matching Algorithms},
  booktitle    = {Proceedings of the Workshop on 3D-Mapping at the
                  IEEE International Conference on Intelligent Robots
                  and Systems (IROS '08)},
  year         = {2008},
  address      = {Nice, France},
  month        = {September},
}


@InProceedings{WS3DMAP2_2008,
  author       = {T. Wiemann and A. N{\"u}chter and K. Lingemann and
                  S. Stiene and J. Hertzberg},
  title        = {Surface Reconstruction for 3D Robotic Mapping},
  booktitle    = {Proceedings of the Workshop on 3D-Mapping at the
                  IEEE International Conference on Intelligent Robots
                  and Systems (IROS '08)},
  year         = {2008},
  address      = {Nice, France},
  month        = {September},
}


@Article{RAS2008,
  author       = {A. N{\"u}chter and J. Hertzberg},
  title        = {{Towards Semantic 3D Maps}},
  journal      = {Journal Robotics and Autonomous Systems (JRAS),
                  Special Issue on Semantic Knowledge in Robotics},
  year         = {2008},
  volume       = {56},
  number       = {11},
  pages        = {915--926},
  month        = {November},
  abstract     = {Intelligent autonomous action in ordinary
                  environments calls for 3D maps. 3D geometry is
                  necessary for avoiding collision with complex
                  obstacles and to self localize in six degrees of
                  freedom (6 DoF) (x, y, z positions, roll, yaw, and
                  pitch angles). Meaning, in addition to geometry,
                  becomes inevitable if the robot is supposed to
                  interact with its environment in a goal-directed
                  way. A semantic stance enables the robot to reason
                  about objects; it helps disambiguate or round off
                  sensor data; and the robot knowledge becomes
                  reviewable and communicable.  The paper describes an
                  approach and a completed robot system for semantic
                  mapping. The prime sensor is a 3D laser
                  scanner. Individual scans are registered into a
                  coherent 3D geometry map by 6D SLAM. Coarse scene
                  features (e.g., walls, floors in a building) are
                  determined by semantic labeling. More delicate
                  objects are then detected by a trained classifier
                  and localized. In the end, the semantic maps can be
                  visualized for human inspection. We sketch the
                  overall architecture of the approach, explain the
                  respective steps and their underlying algorithms,
                  give examples based on a working robot
                  implementation, and discuss the findings. },
  doi          = {10.1016/j.robot.2008.08.001},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ras2008.pdf},
}


@InProceedings{3DPVT2008,
  author       = {D. Borrmann and J. Elseberg and K. Lingemann and
                  Andreas N{\"u}chter and J. Hertzberg},
  title        = {{The Efficient Extension of Globally Consistent Scan
                  Matching to 6 DoF}},
  booktitle    = {Proceedings of the 4th International Symposium on 3D
                  Data Processing, Visualization and Transmission
                  (3DPVT '08)},
  pages        = {29--36},
  year         = {2008},
  address      = {Atlanta, USA},
  month        = {June},
  abstract     = {Over ten years ago, Lu and Milios presented a
                  probabilistic scan matching algorithm for solving
                  the simultaneous localization and mapping (SLAM)
                  problem with 2D laser range scans, a standard in
                  robotics. This paper presents an extension to this
                  GraphSLAM method. Our iterative algorithm uses a
                  sparse network to represent the relations between
                  several overlapping 3D scans, computes in every step
                  the 6 degrees of freedom (DoF) transformation in
                  closed form and exploits efficient data association
                  with cached k-d trees. Our approach leads to
                  globally consistent 3D maps, precise 6D pose and
                  covariance estimates, as demonstrated by various
                  experimental results. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3dpvt2008.pdf},
}


@InProceedings{SICE2008,
  author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg},
  title        = {{Evaluating a 3D Camera for RoboCup Rescue}},
  booktitle    = {Proceedings of the SICE Annual Conference 2008:
                  International Conference on Instrumentation, Control
                  and Information Technology (SICE '08)},
  pages        = {2070--2075},
  year         = {2008},
  address      = {Tokyo, Japan},
  month        = {August},
  abstract     = {The following paper evaluates a time-of-flight 3D
                  camera with regards to its usability for RoboCup
                  rescue. This includes an evaluation of the influence
                  of outer conditions to the camera data, as well as
                  its usage for automatic 3D mapping by scan
                  registration. A color camera is calibrated with
                  respect to the 3D camera in order to gain colored
                  texture information for the acquired measurements.},
  doi          = {10.1109/SICE.2008.4655003},
}

@InProceedings{3DTage2008,
  author       = {A. N{\"u}chter and K. Lingemann and D. Bormann and
                  J. Elseberg and J. B{\"o}hm},
  title        = {{Global Konsistente 3D-Kartierung mit Scanmatching}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2008, Fachhochschule Oldenburg/Ostfr./Whv.},
  month        = {January},
  year         = {2008},
  abstract     = {Das Einpassen bzw. Registrieren von Punktmengen
                  unter starren Transformationen ist eines der
                  Grundprobleme in der Bildverarbeitung. Hierbei
                  k{\"o}nnen die 3D-Daten aus Laserscannern, Stereokameras
                  u.{\"a}. stammen. F{\"u}r zwei 3D-Punktmengen bildet der
                  ICP-Algorithmus (Iterative Closest Points) einen de
                  facto Standard f{\"u}r das Registrieren. Weitet man
                  diesen Algorithmus jedoch auf viele 3D-Scans aus,
                  akkumulieren sich Registrierungsfehler. Der
                  vorliegende Beitrag skizziert einen neuen
                  Algorithmus f{\"u}r das global konsistente
                  3D-Scanmatching (Borrmann, Elseberg, Lingemann,
                  N{\"u}chter und Hertzberg 2008) und zeigt eine Anwendung
                  f{\"u}r das Erfassen von Geb{\"a}uden. Die Genauigkeit des
                  Algorithmus wird bez{\"u}glich geod{\"a}tischer Methoden
                  evaluiert.},
}

@Article{JFR2007,
  author       = {O. Wulf and A. N{\"u}chter and J. Hertzberg and B. Wagner},
  journal      = {Journal of Field Robotics (JFR)},
  title        = {{Benchmarking Urban 6D SLAM}},
  volume       = {25},
  number       = {3},
  pages        = {148--163},
  month        = {March},
  year         = {2008},
  abstract     = {Quite a number of approaches for solving the
                  simultaneous localization and mapping (SLAM) problem
                  exist by now. Some of them have recently been
                  extended to mapping environments with six degrees of
                  freedom (DoF) poses, yielding 6D SLAM approaches. To
                  demonstrate the capabilities of the respective
                  algorithms, it is common practice to present
                  generated maps and successful loop closings in large
                  outdoor environments. Unfortunately, it is
                  non-trivial to compare different 6D SLAM approaches
                  objectively, because ground truth data about the
                  outdoor environments used for demonstration is
                  typically unavailable. We present a novel
                  benchmarking method for generating this ground truth
                  data based on reference maps. The method is then
                  demonstrated by comparing the absolute performance
                  of some previously existing 6D SLAM algorithms which
                  build a large urban outdoor map. },
  doi          = {10.1002/rob.20234},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/jfr2008.pdf},
}

@Article{RAS2007,
  author       = {D. Borrmann and J. Elseberg and K. Lingemann and
                  A. N{\"u}chter and J. Hertzberg},
  title        = {Globally consistent 3D mapping with scan matching},
  journal      = {Journal Robotics and Autonomous Systems (JRAS)},
  volume       = {56},
  number       = {2},
  pages        = {130--142},
  month        = {February},
  year         = {2008},
  abstract     = {A globally consistent solution to the simultaneous
                  localization and mapping (SLAM) problem in 2D with
                  three degrees of freedom (DoF) poses was presented
                  by Lu and Milios [F. Lu, E. Milios, Globally
                  consistent range scan alignment for environment
                  mapping, Autonomous Robots 4 (April) (1997)
                  333-349]. To create maps suitable for natural
                  environments it is however necessary to consider the
                  6DoF pose case, namely the three Cartesian
                  coordinates and the roll, pitch and yaw angles. This
                  article describes the extension of the proposed
                  algorithm to deal with these additional DoFs and the
                  resulting non-linearities. Simplifications using
                  Taylor expansion and Cholesky decomposition yield a
                  fast application that handles the massive amount of
                  3D data and the computational requirements due to
                  the 6DoF. Our experiments demonstrate the
                  functionality of estimating the exact poses and
                  their covariances in all 6DoF, leading to a globally
                  consistent map. The correspondences between scans
                  are found automatically by use of a simple distance
                  heuristic.},
  doi          = {10.1016/j.robot.2007.07.002},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ras2007.pdf},
}

@InCollection{Dagstuhl2008,
  author       = {J. Hertzberg and K. Lingemann and C. L{\"o}rken and
                  A. N{\"u}chter and S. Stiene},
  booktitle    = {Towards Affordance-Based Robot Control. Proceedings
                  of Dagstuhl Seminar 06231, Dagstuhl Castle},
  title        = {Does it help a robot navigate to call navigability
                  an affordance?},
  publisher    = {Springer LNAI},
  pages        = {16--26},
  year         = {2008},
  abstract     = {Gibson’s notion of affordance seems to attract
                  roboticists’ attention. On a phenomenological level,
                  it allows functions, which have “somehow” been
                  implemented, to be described using a new
                  terminology. However, that does not mean that the
                  affordance notion is of help for building robots and
                  their controllers. This paper explores viewing an
                  affordance as an abstraction from a
                  robot-environment relation that is of
                  inter-individual use, but requires an individual
                  implementation. Therefore, the notion of affordance
                  helps share environment representations and theories
                  among robots. Examples are given for navigability,
                  as afforded by environments of different types to
                  robots of different undercarriages and sensor
                  configurations.  Work in parts done in the projects
                  (1) LISA, which is funded by the German Federal
                  Ministry of Education and Research (BMBF) within the
                  Framework Concept ”Research for Tomorrow’s
                  Production” (fund number 02PB2170-02PB2177) and
                  managed by the Project Management Agency
                  Forschungszentrum Karlsruhe, Production and
                  Manufacturing Technologies Division (PTKA-PFT); and
                  (2) MACS, which is funded by the European
                  Commission’s 6th Framework Programme IST Project
                  MACS under contract/grant number FP6-004381. The
                  Commission’s support is gratefully acknowledged.},
  doi          = {10.1007/978-3-540-77915-5_2},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/Hertzberg_ea_Dagstuhl06231-2008.pdf},
}


% --- 2007 ---


@InProceedings{IROS2007,
  author       = {O. Wulf and A. N{\"u}chter and J. Hertzberg and B. Wagner},
  title        = {Ground Truth Evaluation of Large Urban 6D SLAM},
  booktitle    = {Proceedings of the IEEE/RSJ International Conference
                  on Intelligent Robots and Systems (IROS '07)},
  pages        = {650--657},
  year         = {2007},
  address      = {San Diego, CA, USA},
  month        = {October},
  abstract     = {In the past many solutions for simultaneous
                  localization and mapping (SLAM) have been
                  presented. Recently these solutions have been
                  extended to map large environments with six degrees
                  of freedom (DoF) poses. To demonstrate the
                  capabilities of these SLAM algorithms it is common
                  practice to present the generated maps and
                  successful loop closing. Unfortunately there is
                  often no objective performance metric that allows to
                  compare different approaches. This fact is
                  attributed to the lack of ground truth data. For
                  this reason we present a novel method that is able
                  to generate this ground truth data based on
                  reference maps. Further on, the resulting reference
                  path is used to measure the absolute performance of
                  different 6D SLAM algorithms building a large urban
                  outdoor map.},
  doi          = {10.1109/IROS.2007.4399026},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iros2007.pdf},
}

@Article{JFR2006,
  author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg and H. Surmann},
  title        = {{6D SLAM -- 3D Mapping Outdoor Environments}},
  journal      = {Journal of Field Robotics (JFR), Special Issue on
                  Quantitative Performance Evaluation of Robotic and
                  Intelligent Systems},
  volume       = {24},
  number       = {8--9},
  pages        = {699--722},
  month        = {August / September},
  year         = {2007},
  abstract     = {6D SLAM (Simultaneous Localization and Mapping) or
                  6D Concurrent Localization and Mapping of mobile
                  robots considers six dimensions for the robot pose,
                  namely, the x, y and z coordinates and the roll, yaw
                  and pitch angles. Robot motion and localization on
                  natural surfaces, e.g., driving outdoor with a
                  mobile robot, must regard these degrees of
                  freedom. This paper presents a robotic mapping
                  method based on locally consistent 3D laser range
                  scans. Iterative Closest Point (ICP) scan matching,
                  combined with a heuristic for closed loop detection
                  and a global relaxation method, results in a highly
                  precise mapping system. A new strategy for fast data
                  association, cached kd tree search, leads to
                  feasible computing times. With no ground-truth data
                  available for outdoor environments, point relations
                  in maps are compared to numerical relations in
                  uncalibrated aerial images in order to assess the
                  metric validity of the resulting 3D maps. },
  doi          = {10.1002/rob.20209},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/jfr2007.pdf},
}
<

@InProceedings{ECMR2007,
  author       = {A. N{\"u}chter},
  title        = {{Parallelization of Scan Matching for Robotic 3D
                  Mapping}},
  booktitle    = {Proceedings of the 3rd European Conference on Mobile
                  Robots (ECMR '07)},
  year         = {2007},
  address      = {Freiburg, Germany},
  month        = {September},
  abstract     = {Robotic 3D Mapping of environments is
                  computationally expensive, since 3D scanners sample
                  the environment with many data points. In addition,
                  the solution space grows exponentially with the
                  additional degrees of freedom needed to represent
                  the robot pose. Mapping environments in 3D must
                  regard six degrees of freedom to characterize the
                  robot pose. This paper extends our solution to the
                  3D mapping problem by parallelization. The
                  availability of multi-core processors as well as
                  efficient programming schemes as OpenMP permit the
                  parallel execution of robotics task with on-board
                  means. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ecmr2007.pdf},
}


@InProceedings{PERMIS2007,
  author       = {R. Lakaemper and A. N{\"u}chter and N. Adluru and
                  L. J. Latecki},
  title        = {Performance of 6D LuM and FFS SLAM -- An Example for
                  Comparison using Grid and Pose Based Evaluation
                  Methods},
  booktitle    = {Proceedings of seventh workshop on Performance
                  Metrics for Intelligent Systems (PerMIS '07)},
  year         = {2007},
  address      = {Washington D.C., USA,},
  month        = {August},
  abstract     = {The focus of this paper is on the performance
                  comparison of two simultaneous localization and
                  mapping (SLAM) algorithms namely 6D Lu/Milios SLAM
                  and Force Field Simulation (FFS). The two algorithms
                  are applied to a 2D data set. Although the
                  algorithms generate overall visually comparable
                  results, they show strengths and weaknesses in
                  different regions of the generated global maps. The
                  question we address in this paper is, if different
                  ways of evaluating the performance of SLAM
                  algorithms project different strengths and how can
                  the evaluations be useful in selecting an
                  algorithm. We will compare the performance of the
                  algorithms in different ways, using grid and pose
                  based quality measures. },
  doi          = {10.1145/1660877.1660913},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/permis2007.pdf},
}

@InProceedings{RA2007_1,
  author       = {A. Bartel and F. Meyer and C. Sinke and T. Wiemann
                  and A. N{\"u}chter and K. Lingemann and
                  J. Hertzberg},
  title        = {{Real-Time Outdoor Trail Detection on a Mobile Robot}},
  booktitle    = {Proceedings of the 13th IASTED International
                  Conference on Robotics and Applications (RA '07)},
  pages        = {477--482},
  year         = {2007},
  address      = {W{\"u}rzburg, Germany},
  month        = {August},
  abstract     = {In this paper we present a reliable approach for
                  real-time outdoor trail following and obstacle
                  avoidance. The trail classification is done using an
                  off-the-shelf webcam and a pitched 2D laser scanner
                  on a KURT2 robot equipped with an Intel Centrino
                  laptop. This simple setup enables us to follow given
                  pathways of different kinds using a GPS receiver for
                  rough orientation.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/kgc/},
}

@InProceedings{RA2007_2,
  author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg},
  title        = {{6D SLAM with Cached k-d tree Search}},
  booktitle    = {Proceedings of the 13th IASTED International
                  Conference on Robotics and Applications (RA '07)},
  pages        = {181--186},
  year         = {2007},
  address      = {W{\"u}rzburg, Germany},
  month        = {August},
  abstract     = {6D SLAM (Simultaneous Localization and Mapping) or
                  6D Concurrent Localization and Mapping of mobile
                  robots considers six degrees of freedom for the
                  robot pose, namely, the x, y and z coordinates and
                  the roll, yaw and pitch angles. In previous work we
                  presented our scan matching based 6D SLAM approach
                  [cite deleted], where scan matching is based on the
                  well known iter ative closest point (ICP) algorithm
                  [3]. Effcient implementations of this algorithm are
                  a result of a fast computation of closest
                  points. The usual approach, i.e., using k-d trees is
                  extended in this paper. We describe a novel search
                  strategy, that lead s to significant speed-ups. Our
                  mapping system is real-time capable, i.e., 3D maps
                  are computed using the resources of the used robotic
                  hardware. },
}


@InProceedings{3DIM2007,
  author       = "A. N{\"u}chter and K. Lingemann and J. Hertzberg",
  title        = "{C}ached $k$-d tree search for {ICP} {A}lgorithms",
  booktitle    = "Proceedings of the 6th IEEE International Conference
                  on Recent Advances in 3D Digital Imaging and
                  Modeling (3DIM '07)",
  pages        = {419--426},
  month        = {August},
  year         = {2007},
  address      = {Montreal, QC, Canada},
  abstract     = {The ICP (iterative closest point) algorithm is the
                  de facto standard for geometric alignment of
                  three-dimensional models when an initial relative
                  pose estimate is available. The basis of ICP is the
                  search for closest points. Since the development of
                  ICP, k-d trees have been used to accelerate the
                  search. This paper presents a novel search
                  procedure, namely cached k-d trees, exploiting
                  iterative behavior of the ICP algorithm. It results
                  in a significant speedup of about 50\% as we show in
                  an evaluation using different data sets.},
  doi          = {10.1109/3DIM.2007.15},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3dim2007.pdf},
}


@InProceedings{ICRA2007,
  author       = {G. Indiveri and A. N{\"u}chter and K. Lingemann},
  title        = {High Speed Differential Drive Mobile Robot Path
                  Following Control With Bounded Wheel Speed Commands},
  booktitle    = {Proceedings of the IEEE International Conference
                  Robotics and Automation (ICRA '07)},
  address      = {Rome, Italy},
  pages        = {2202--2207},
  month        = {April},
  year         = {2007},
  abstract     = {The great majority of path following control laws
                  for either kinematical or dynamical mobile robot
                  models are designed assuming ideal actuators,
                  i.e. assuming that any commanded velocity or torque
                  (in the kinematical and dynamical cases
                  respectively) will be instantly implemented
                  regardless of its value. Real actuators are far from
                  being ideal. In particular, only bounded velocities
                  and torques can be realized for any given
                  command. With reference to the kinematical model of
                  a differential drive mobile robot, a known path
                  following control law is modified to account for
                  actuator velocity saturation. The proposed solution
                  is experimentally shown to be particularly useful
                  for high speed applications where accounting for
                  actuator velocity saturation may have a large
                  influence on performance.},
  doi          = {10.1109/ROBOT.2007.363647},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icra2007.pdf},
}

@InProceedings{ICRA2007WS,
  author       = {S. Stiene and A. N{\"u}chter and K. Lingemann and J. Hertzberg},
  title        = {An Experiment in Semantic Correction of Sensor Data},
  booktitle    = {Proceedings Workshop on Semantic Information in
                  Robotics at the IEEE International Conference
                  Robotics and Automation (ICRA '07)},
  month        = {April},
  address      = {Rome, Italy},
  year         = {2007},
}

@Article{RT2007,
  author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg},
  title        = {{6D SLAM with Kurt3D}},
  journal      = {Robotics Today, Society of Manufacturing Engineers, First Quater},
  year         = {2007},
  volume       = {20},
  number       = {1},
  month        = {April},
}

@InProceedings{WCAA2007,
  author       = {L. Kunze and K. Lingemann and A. N{\"u}chter and
                  J. Hertzberg},
  title        = {{Salient Visual Features to Help Close the Loop in
                  6D SLAM}},
  booktitle    = {Proceedings of the ICVS Workshop on Computational
                  Attention \& Applications (WCAA '07)},
  month        = {March},
  address      = {Bielefeld, Germany},
  year         = {2007},
  abstract     = { One fundamental problem in mobile robotics research
                  is Simultaneous Localization and Mapping (SLAM): A
                  mobile robot has to localize itself in an unknown
                  environment, and at the same time generate a map of
                  the surrounding area. One fundamental part of SLAM
                  algorithms is loop closing: The robot detects
                  whether it has reached an area that has been visited
                  before, and uses this information to improve the
                  pose estimate in the next step. In this work, visual
                  camera features are used to assist closing the loop
                  in an existing 6 degree of freedom SLAM (6D SLAM)
                  architecture. For our robotics application we
                  propose and evaluate several detection methods,
                  including salient region detection and maximally
                  stable extremal region detection. The detected
                  regions are encoded using SIFT descriptors and
                  stored in a database. Loops are detected by matching
                  of the images' descriptors. A comparison of the
                  different feature detection methods shows that the
                  combination of salient and maximally stable extremal
                  regions suggested by performs moderately. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/wcaa2007.pdf},
}

@InProceedings{NF2007,
  author       = {J. Steger and R. M{\"a}rtin and K. Lingemann and
                  A. N{\"u}chter and J. Hertzberg and P. K{\"o}nig},
  title        = {{Assessing stereo matching algorithms using
                  ground-truth disparity maps of natural scenes}},
  booktitle    = {Proceedings of the 7th Meeting of the German
                  Neuroscience Society / 31th G{\"o}ttingen
                  Neurobiology Conference, Neuroforum 2007},
  year         = {2007},
  month        = {March},
  address      = {G{\"o}ttingen, Germany},
}


@InProceedings{CCNCV2007,
  author       = {J. Steger and R. M{\"a}rtin and K. Lingemann and
                  A. N{\"u}chter and J. Hertzberg and P. K{\"o}nig},
  title        = {{Laser range scans of natural scenes for the
                  evaluation of stereo-matching algorithms}},
  booktitle    = {Poster at ICVS Workshop From Computational Cognitive
                  Neuroscience to Computer Vision (CCNCV '07)},
  address      = {Bielefeld, Germany},
  month        = {March},
  year         = {2007},
}

@InProceedings{3DTage2007,
  author       = {A. N{\"u}chter},
  title        = {{Algorithmen zur Erstellung virtueller 3D-Welten mit mobilen Robotern}},
  booktitle    = {Photogrammetrie Laserscanning Optische
                  3D-Messtechnik, Beitr{\"a}ge der Oldenburger 3D-Tage
                  2007, Fachhochschule Oldenburg/Ostfr./Whv.},
  month        = {January},
  year         = {2007},
  abstract     = { 3D-Laserscanner sind eine junge Technologie, die
                  die Erfassung r{\"a}umlicher Daten revolutioniert und
                  Robotern das dreid imensionale Abtasten von Objekten
                  m{\"o}glich macht. Roboter, die ihre Umgebung
                  dreidimensional kartieren k{\"o}nnen, eignen sich zum
                  automatischen Erstellen virtuelle 3D-Welten. Eine
                  3D-Welt, oder 3D-Umgebungskarte muss mit der
                  wirklichen Umgebung {\"u}bereinstimmen, also korrekt und
                  konsistent sein. Ist die Position des Roboters genau
                  bekannt, k{\"o}nnen die loka len Karten auf der
                  Grundlage dieser Position zusammengef{\"u}gt
                  werden. Leider ist die Selbstlokalisation eines
                  Roboters stets fehlerbehaftet. Daher darf der
                  Kartenbau nicht nur auf der Roboterposition
                  basieren, sondern muss auch auf der Grundlage der
                  Sensorwerte geschehen. In diesem Zusammenhang
                  spricht man vom simultanen Lokalisations- und
                  Kartierungs problem (SLAM, simultaneous localization
                  and mapping problem). Korrekte, global konsistente
                  Modelle entstehen durch e inen 6D-SLAM
                  Algorithmus. Hierbei werden 6 Freiheitsgrade in der
                  Roboterpose ber{\"u}cksichtigt, geschlossene Kreise erka
                  nnt und der globale Fehler minimiert. Die Basis des
                  6D-SLAM ist ein sehr schneller ICP-Algorithmus.},
}


% --- 2006 ---


@Book{DISS2006,
  author       = {A. N{\"u}chter},
  title        = {Semantische dreidimensionale Karten f{\"u}r autonome
                  mobile Roboter},
  publisher    = {Infinix / Aka Verlag },
  year         = {2006},
  number       = {303},
  series       = {DISKI, Dissertationen zur k{\"u}nstlichen Intelligenz},
  address      = {Berlin, Germany},
  month        = {November},
}


@Proceedings{3DEnvCog2006,
  title        = {Robotic 3D Environment Cognition, Workshop at the
                  International Conference Spatial Cognition},
  year         = {2006},
  editor       = {A. N{\"u}chter and K. Lingemann and O. Wulf},
  address      = {Bremen, Germany},
  month        = {September},
  publisher    = {(Online Proceedings)},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/workshop_final.pdf},
}


@InProceedings{3DEnvCog2006_1,
  author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg},
  title        = {{6D SLAM with Kurt3D}},
  booktitle    = {{Robotic 3D Environment Cognition, Workshop at the
                  International Conference Spatial Cognition}},
  year         = {2006},
  address      = {Bremen, Germany},
  month        = {September},
  abstract     = { 6D SLAM (Simultaneous Localization and Mapping) of
                  mobile robots considers six dimensions for the robot
                  pose, namely, the x, y and z coordinates and the
                  roll, yaw and pitch angles. Robot motion and
                  localization on natural surfaces, e.g., when driving
                  with a mobile robot outdoor, must regard these
                  degrees of freedom. This paper presents a robotic
                  mapping method based on locally consistent 3D laser
                  range scans. Scan matching, combined with a
                  heuristic for closed loop detection and a global
                  relaxation method, results in a highly precise
                  mapping system for outdoor environments. The mobile
                  robot Kurt3D was used to acquire data of the Schloss
                  Birlinghoven campus. The resulting 3D map is
                  compared with ground truth, given by an aerial
                  photograph.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3DEnvCog.pdf},
}


@inproceedings{SSRR2006,
  author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg and
                  H. Surmann},
  Booktitle    = {Proceedings of the IEEE International Workshop on
                  Safety, Security and Rescue Robotics (SSRR '06)},
  Title        = {{Heuristic-Based Laser Scan Matching for Outdoor 6D SLAM}},
  Month        = {August},
  Address      = {Gaithersburg, Maryland},
  Year         = {2006},
  abstract     = {6D SLAM (Simultaneous Localization and Mapping) of
                  mobile robots considers six dimensions for the robot
                  pose, namely, the x, y and z coordinates and the
                  roll, yaw and pitch angles. Robot motion and
                  localization on natural surfaces, e.g., when driving
                  with a mobile robot outdoor, must regard these
                  degrees of freedom. This paper presents a robotic
                  mapping method based on locally consistent 3D laser
                  range scans. Scan matching, combined with a
                  heuristic for closed loop detection and a global
                  relaxation method, results in a highly precise
                  mapping system for outdoor environments. The mobile
                  robot Kurt3D was used to acquire data of the Schloss
                  Birlinghoven campus. The resulting 3D map is
                  compared with ground truth, given by an aerial
                  photograph. },
}


@inproceedings{3DPVT2006,
  author       = {S. Stiene and K. Lingemann and A. N{\"u}chter and
                  J. Hertzberg},
  title        = {{Contour-based Object Detection in Range Images}},
  booktitle    = {Proceedings of the 3rd IEEE International Symposium
                  on 3D Data Processing, Visualization and
                  Transmission (3DPVT '06)},
  month        = {June},
  year         = {2006},
  abstract     = {This paper presents a novel object recognition
                  approach based on range images. Due to its
                  insensitivity to illumination, range data is well
                  suited for reliable silhouette
                  extraction. Silhouette or contour descriptions are
                  good sources of information for object
                  recognition. We propose a complete object
                  recognition system, based on a 3D laser scanner,
                  reliable contour extraction with floor
                  interpretation, feature extraction using a new, fast
                  eigen-CSS method, and a supervised learning
                  algorithm. The recognition system was successfully
                  tested on range images acquired with a mobile robot,
                  and the results are compared to standard techniques,
                  i.e., geometric features, Hu and Zernike moments,
                  the border signature method and the angular radial
                  transformation. An evaluation using the receiver
                  operating characteristic analysis completes this
                  paper. The eigen-CSS method has proved to be
                  comparable in detection performance to the top
                  competitors, yet faster than the best one by an
                  order of magnitude in feature extraction time.},
  doi          = {10.1109/3DPVT.2006.46},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3dptv2006.pdf},
}


@inproceedings{SRMED2006,
  author       = {S. Albrecht and J. Hertzberg and K. Lingemann and
                  A. N{\"u}chter and J. Sprickerhof and S. Stiene},
  title        = {{Device Level Simulation of Kurt3D Rescue Robots}},
  booktitle    = {Proceedings of the 3rd International Workshop on
                  Synthetic Simulation and Robotics to Mitigate
                  Earthquake Disaster (SRMED 2006)},
  month        = {June},
  year         = {2006},
  abstract     = {USARSIM is a worldwide used robot simulator deployed
                  in Urban Search and Rescue (USAR) and in the context
                  of the RoboCup Rescue Real Robot contest. This paper
                  describes the USARSIM simulator for KURT2 and Kurt3D
                  robot platforms, which we are using in both
                  education and research. As it simulates on the
                  device level, a seamless integration of real robot
                  control software with the simulations becomes
                  possible. We evaluate the performance for simulating
                  laser range scans and the camera system. In
                  addition, we show a simulation of the rescue
                  robots. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/UOSSim/srmed2006.pdf},
}


@techreport{TDP2006,
  Address      = {Bremen, Germany},
  Author       = {K. Lingemann and A. N{\"u}chter and O. Wulf and
                  H. Surmann and K. Perv{\"o}lz and J. Hertzberg and
                  B. Wagner and T. Christaller},
  Institution  = {{Team Description Paper, Rescue Robot League
                  Competition}},
  Month        = {June},
  Title        = {{RoboCupRescue - Robot League Team, Team Deutschland1}},
  Year         = {2006},
  abstract     = { After scoring second in RoboCup Rescue 2004 with
                  Kurt3D and participating in 2005 with two robots,
                  namely Kurt3D and RTS Crawler, we concentrated on
                  the development of interaction between both
                  vehicles. Kurt3D is able to autonomously explore and
                  map the environment in 3D and search for
                  victims. The RTS Crawler is designed to access more
                  demanding territory (i.e., red arena), working
                  either remote controlled or semi-autonomous. The key
                  innovation of this system lies in the capability for
                  autonomous 6D SLAM (simultaneous localization and
                  mapping) and 3D map generation of natural scenes,
                  combined with the intelligent cooperation between
                  robots that enables one operator to efficiently map
                  and explore the whole arena.  The robots are
                  equipped with dedicated state of the art equipment,
                  e.g., 3D laser range finders, infrared camera and
                  CO2-sensor. Robots as well as operator station are
                  rather compact and easy to set up. The challenge of
                  controlling two rescue robots with only one operator
                  is managed with a redesigned user interface and a
                  number of autonomous and semi-autonomous features. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/robocup2006_TDP.pdf},
}


@InProceedings{ISR2006,
  author       = "A. N{\"u}chter and K. Lingemann and J. Hertzberg",
  title        = {{Extracting Drivable Surfaces in Outdoor 6D SLAM}},
  booktitle    = "Proceedings of the 37rd International Symposium on
                  Robotics (ISR '06) and Robotik 2006",
  month        = {May},
  year         = {2006},
  address      = {Munich, Germany},
  abstract     = {A basic issue of mobile robotics is generating
                  environment maps automatically. Outdoor terrain is
                  challenging since the ground is uneven and the
                  surrounding is structured irregularly. In earlier
                  work, we have introduced 6D SLAM (Simultaneous
                  Localization and Mapping) as a method to taking all
                  six DOF of robot poses (x, y, z translation; roll,
                  pitch, yaw angles) into account. This paper adds to
                  6D SLAM a method for extracting drivable surfaces in
                  the 3D maps while they are being
                  generated. Experiments have been made in a Botanical
                  Garden, with drivable surfaces consisting of gravel
                  paths or lawn, both involving significant slope.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/robotik2006.pdf},
}


@article{KI2006,
  Author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg and
                  O. Wulf and B. Wagner and K. Perv{\"o}lz and
                  H. Surmann and T. Christaller},
  Journal      = {KI -- K{\"u}nstliche Intelligenz},
  Title        = {{The RoboCup Rescue Team Deutschland1}},
  Number       = {2},
  Pages        = {24--29},
  Year         = {2006},
  abstract     = {The RoboCup Rescue competition aims at boosting
                  research in robots and infrastructure able to help
                  in real rescue missions. The task is to find and
                  report victims in areas of different grades of
                  roughness, which are currently indoor. It challenges
                  to some extreme the mobility of robot platforms as
                  well as the autonomy of their control and sensor
                  interpretation software. In the 2004 competition,
                  the Kurt3D robot was introduced, the first
                  participant capable of mapping its environment in 3D
                  and self-localizing in all six degrees of freedom,
                  i.e., x, y, z positions and roll, yaw and pitch
                  angles. In 2005, we have upgraded the system with
                  more sensors, with a focus on speeding up the
                  algorithms, and we have started to develop a tracked
                  robot platform to cooperate with Kurt3D. This paper
                  gives an introduction to the competition in general
                  and presents main contributions of our Deutschland1
                  RoboCup Rescue team. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/kiart2006.pdf},
}

@TechReport{ELROB2006,
  author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg},
  title        = {{Kurt3D -- A Mobile Robot for 3D Mapping of Environments}},
  institution  = {ELROB},
  year         = {2006},
  address      = {Hammelburg, Germany},
  month        = {May},
  abstract     = {The mobile robot Kurt3D is the first robot that is
                  capable of mapping its environment in 3D and self
                  localize in all six degrees of freedom, i.e.,
                  considering its x, y and z positions and the roll,
                  yaw and pitch angles. Robot motion on natural
                  surfaces has to cope with yaw, pitch and roll
                  angles, turning pose estimation into a problem in
                  six mathematical dimensions. Kurt3D creates a
                  consistent volumetric scene in a common coordinate
                  frame from multiple 3D laser scans. To create 3D
                  volumetric maps it is necessary to gage several 3D
                  scans and register them into one consistent 3D
                  model. A fast variant of the Iterative Closest
                  Points (ICP) algorithm is used for registration and
                  relocalization.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/elrob2006.pdf},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/TeamInformation.pdf},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/VehicleSpecificationSheet.pdf},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/TeamRoster.pdf},
}


@Article{CGTA_2006,
  author       = {S. P. Fekete and R. Klein and A. N{\"u}chter},
  title        = {Online searching with an autonomous robot},
  journal      = {Computational Geometry: Theory and Applications (CGTA)},
  year         = {2006},
  volume       = {34},
  number       = {2},
  pages        = {102--115},
  month        = {May},
  abstract     = {We discuss online strategies for visibility-based
                  searching for an ob ject hidden behind a corner,
                  using Kurt3D, a real autonomous mobile robot. This
                  task is closely related to a number of well-studied
                  problems. Our robot uses a threedimensional laser
                  scanner in a stop, scan, plan, go fashion for
                  building a virtual three-dimensional
                  environment. Besides planning trajectories and
                  avoiding obstacles, Kurt3D is capable of identifying
                  objects like a chair. We derive a practically useful
                  and asymptotically optimal strategy that guarantees
                  a competitive ratio of 2, which differs remarkably
                  from the well-studied scenario without the need of
                  stopping for surveying the environment. Our strategy
                  is used by Kurt3D, documented in a separate video. },
  doi          = {10.1016/j.comgeo.2005.08.005},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/cg2006.pdf},
}

% --- 2005 ---


@Article{PATENT2005,
  author       = {K. Lingemann and H. Surmann and A. N{\"u}chter and
                  J. Hertzberg},
  title        = {Verfahren zur Ermittlung der Position und
                  Orientierung eines navigierenden Systems},
  journal      = {Patentblatt, Offenlegungsschrift DE 10 2004 015 111 A1 2005.10.20},
  year         = {2005},
  volume       = {125},
  number       = {42},
  publisher    = {Deutsches Patentamt},
  month        = {October},  
  abstract     = {Bei dem Verfahren zur Ermittlung der Position und
                  Orientierung eines autonom navigierenden Systems,
                  beispielsweise eines Roboters, in einer Umgebung
                  werden die Entfernung des in Fahrtrichtung vor den
                  navigierenden System liegenden Bereichs der Umgebung
                  bei Bewegung des navigierenden Systems abgetastet
                  und die abgetasteten Entfernungspunkte mindestens
                  zweier aufeinanderfolgender Abtastvorg{\"a}nge als
                  Entfernungsmesskurven in der Polardarstellung
                  gespeichert. Anschliessend werden die
                  Entfernungsmesskurven der beiden aufeinander
                  folgenden Abtastvorg{\"a}nge auf charakteristische
                  merkmale wie z.B. Extremwerte untersucht. Danach
                  werden die parameter von einender getrennt
                  durchf{\"u}hrbaren Translations- und
                  Rotationstransformationen der einen
                  Entfernungsmesskurve zur Ermittlungder zuordnung der
                  charakteristischen Merkmale der trnasformierten
                  Entfernungsmesskurve zu solchen der anderen
                  Entfernungsmesskurve und die Position und
                  Orientierung des navigierenden Systems anhand von
                  dessen Position und dessen Orientierung zum
                  Zeitpunkt des zeitlich ersten von zwei
                  aufeinanderfolgenden Abtastungen sowie der
                  ermittelten Parameter der Translation- und
                  Rotationstransformation bestimmt.  },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/patent2005.pdf},
}


@Article{CVIU_2005,
  author       = {S. Frintrop and E. Rome and A. N{\"u}chter and H. Surmann},
  title        = {A Bimodal Laser-Based Attention System},
  journal      = {Journal Computer Vision and Image Understanding
                  (CVIU), Special Issue on Attention and Performance
                  in Computer Vision},
  year         = {2005},
  volume       = {100},
  number       = {1-2},
  pages        = {124--151},
  month        = {October / November},
  abstract     = {In this paper, we present a new bimodal attention
                  system for robotic applications capable of
                  processing data from different sensor modes
                  simultaneously. Considering several sensor
                  modalities is an obvious approach to regard a
                  variety of ob ject properties. Nevertheless,
                  conventional att ention systems only regard the
                  processing of camera images. In contrast to these
                  systems, the input data to our system is provided by
                  a bimodal 3D laser scanner, mounted on top of an
                  autonomous mobile robot. In a single 3D scan pass,
                  the scanner yields range as well as reflectance
                  data. Both dat a modes are illumination independent,
                  yielding a robust approach that enables all day
                  operation. Data from both laser modes are fed into
                  our attention system built on principles of one of
                  the standard models of visual attention by Koch &
                  Ullman. The system computes conspicuities of both
                  modes in parallel and fuses them into one saliency
                  map. The focus of attention is directed to the most
                  salient points in this map sequentially. We present
                  results on recorded scans of indoor and outdoor
                  scenes showing the respective advantages of the
                  sensor modalities enabling the mode-specific
                  detectio n of different ob ject
                  properties. Furthermore, we show as an application
                  of the attention system the recognition of ob jects
                  for building semantic 3D maps of the robot's
                  environment. Key words: visual attention, saliency
                  detection, bimodal sensor fusion, 3D laser scanner },
  doi          = {10.1016/j.cviu.2004.08.005},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/cviu2005.pdf},
}


@Article{it2005,
   author      = {H. Surmann and K. Perv{\"o}lz and A. N{\"u}chter and
                  K. Lingemann and J. Hertzberg and M. Hennig},
   title       = {{Simultaneous Mapping and Localization of Rescue
                  Environments}},
   Journal     = {it- Information Technology},
   volume      = {47},
   year        = {2005},
   pages       = {282--291},
   publisher   = {Oldenbourg press},
}


@inproceedings{KI2005,
  Address      = {Koblenz, Germany},
  Author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg and
                  H. Surmann},
  Booktitle    = {KI 2005: Advances in Artificial Intelligence. 28th
                  Annual German Conference on AI, Proceedings Springer
                  LNAI vol. 3698},
  Month        = {September},
  Pages        = {304--319},
  Title        = {{H}euristic-{B}ased {L}aser {S}can {M}atching for
                  {O}utdoor {6D} {SLAM}},
  Year         = {2005},
  abstract     = {6D SLAM (Simultaneous Localization and Mapping) or
                  6D Concurrent Localization and Mapping of mobile
                  robots considers six dimensions for the robot pose,
                  namely, the x, y and z coordinates and the roll, yaw
                  and pitch angles. Robot motion and localization on
                  natural surfaces, e.g., driving with a mobile robot
                  outdoor, must regard these degrees of freedom. This
                  paper presents a robotic mapping method based on
                  locally consistent 3D laser range scans. Scan
                  matching, combined with a heuristic for closed loop
                  detection and a global relaxation method, results in
                  a highly precise mapping system for outdoor
                  environments. The mobile robot Kurt3D was used to
                  acquire data of the Schloss Birlinghoven campus. The
                  resulting 3D map is compared with ground truth,
                  given by an aerial photograph. },
  doi          = {10.1007/11551263},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/6Doutdoor/},

}


@inproceedings{RIIA2005,
  Address      = {Bonn, Germany},
  Author       = {J. Hertzberg and K. Lingemann and A. N{\"u}chter},
  Booktitle    = {Informatik 2005 -- Informatik LIVE, vol.1
                  (Beitr{\"a}ge der 35. Jahrestagung der Gesellschaft
                  f{\"u}r Informatik, Bonn)},
  Month        = {September},
  Pages        = {158--162},
  Title        = {{USARSIM -- Game-Engines in der Robotik-Lehre}},
  Year         = {2005},
  abstract     = {In der Lehre zum Thema Wissensbasierte Robotik
                  verwenden wir seit Kurzem den Robotersimulator
                  USARSIM, der weltweit im Kontext der RoboCup Rescue
                  Real Robot Liga eingesetzt wird. Wir stellen den
                  Lehr-Kontext vor, in dem wir arbeiten, skizzieren
                  den Simulator und beschreiben seine Einbindung in
                  unsere Lehre. Unsere Erfahrungen bezuglich der
                  Motivation der Studierenden und ihrer Leistungen der
                  Verwendung des Simulators sind sehr positiv. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/riia2005.pdf},
}


@inproceedings{ECMR2005,
  Address      = {Ancona, Italy},
  Author       = {K. Lingemann and A. N{\"u}chter and J. Hertzberg and
                  H. Surmann},
  Booktitle    = {Proceedings of the Second European Conference on
                  Mobile Robotics (ECMR '05)},
  Month        = {September},
  Pages        = {218--223},
  Title        = {{A}bout the {C}ontrol of {H}igh {S}peed {M}obile
                  {I}ndoor {R}obots},
  Year         = {2005},
  abstract     = {This paper describes the control algorithms of the
                  high speed mobile robot Kurt3D. Kurt3D drives up to
                  4 m/s autonomously and reliably in an unknown office
                  environment. We present the reliable hardware, fast
                  control cycle algorithms and a novel set value
                  computation scheme for achieving these
                  velocities. In addition we sketch a real-time
                  capable laser based position tracking method that is
                  well suited for driving with these velocities. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/highspeed/},
}

@inproceedings{ICAR2005_2,
  Author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg and
                  H. Surmann},
  Booktitle    = {Proceedings of the 12th IEEE International
                  Conference on Advanced Robotics (ICAR '05)},
  Month        = {July},
  Pages        = {242--249},
  Title        = {{6D SLAM} with {A}pproximate {D}ata {A}ssociation},
  Year         = {2005},
  abstract     = {This paper provides a new solution to the
                  simultaneous localization and mapping (SLAM) problem
                  with six degrees of freedom. A fast variant of the
                  iterative closest points (ICP) algorithm registers
                  3D scans taken by a mobile robot into a common
                  coordinate system and thus provides
                  relocalization. Hereby, data association is reduced
                  to the problem of searching for closest
                  points. Approximation algorithms for this searching,
                  namely, approximate kd-trees and box decomposition
                  trees, are presented and evaluated in this paper. A
                  solution to 6D SLAM that considers all free
                  parameters in the robot pose is built based on 3D
                  scan matching.},
  doi          = {10.1109/ICAR.2005.1507419},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icar2005_2.pdf},
}

@inproceedings{ICAR2005_1,
  Author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg and
                  H. Surmann},
  Booktitle    = {Proceedings of the 12th IEEE International
                  Conference on Advanced Robotics (ICAR '05)},
  Month        = {July},
  Pages        = {665--672},
  Title        = {{A}ccurate {O}bject {L}ocalization in {3D} {L}aser
                  {R}ange {S}cans},
  Year         = {2005},
  abstract     = {This paper presents a novel method for object
                  detection and classification in 3D laser range data
                  that is acquired by an autonomous mobile
                  robot. Unrestricted objects are learned using
                  classification and regression trees (CARTs) and
                  using an Ada Boost learning procedure. Off-screen
                  rendered depth and reflectance images serve as an
                  input for learning. The performance of the
                  classification is improved by combining both sensor
                  modalities, which are independent from external
                  light. This enables highly accurate, fast and
                  reliable 3D object localization with point
                  matching. Competitive learning is used for
                  evaluating the accuracy of the object localization.},
  doi          = {10.1109/ICAR.2005.1507480},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icar2005_1.pdf},
}


@techreport{TDP2005,
  Address      = {Osaka, Japan},
  Author       = {H. Surmann and K. Lingemann and A. N{\"u}chter and
                  M. Hennig and K. Perv{\"o}lz and O. Wulf and
                  J. Hertzberg and B. Wagner and T. Christaller},
  Institution  = {Team Description Paper, Rescue Robot League
                  Competition},
  Month        = {July},
  Title        = {{RoboCupRescue - Robot League Team, Team Deutschland1}},
  Year         = {2005},
  abstract     = {After the second place in RoboCup Rescue 2004, a new
                  version of the mobile robot Kurt3D was developed in
                  our groups during the last year [1]. The key
                  innovation of this system lies in the capability for
                  autonomous or operator-assisted 6D SLAM
                  (simultaneous localization and mapping) and 3D map
                  generation of natural scenes. Hence, Kurt3D already
                  meets the basic requirement regarding urban search
                  and rescue. For the rescue robot league competition,
                  it is additionally configured with dedicated
                  state-of-the-art equipment e.g. infrared camera and
                  CO2sensor. The robot and the operator station are
                  rather compact and easy to set up. The operator uses
                  a joystick as a remote control for the robot and can
                  watch a live video of the scene where the robot
                  drives. Data are transmitted via wireless LAN. A 3D
                  laser scanner, which is mounted on an outdoor
                  variant of Kurt3D, is used as the main sensor for
                  map generation as well as for navigation and
                  localization. The whole system has been used with a
                  proven record of success for different tasks of map
                  building, so that we are confident of managing the
                  rescue robot league competition, too. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/rr2005-team-deutschland1.pdf},
}


@inproceedings{ROBOCUP2005,
  address      = {Osaka, Japan},
  Author       = {A. N{\"u}chter and O. Wulf and K. Lingemann and
                  J. Hertzberg and B. Wagner and H. Surmann},
  Booktitle    = {Proceedings of the RoboCup International Symposium},
  Month        = {June},
  Title        = {{3D} {M}apping with {S}emantic {K}nowledge},
  Year         = {2005},
  abstract     = {A basic task of rescue robot systems is mapping of
                  the environment. Localizing injured persons, guiding
                  rescue workers and excavation equipment requires a
                  precise 3D map of the environment. This paper
                  presents a new 3D laser range finder and novel scan
                  matching method for the robot Kurt3D [9]. Compared
                  to previous machinery [12], the apex angle is
                  enlarged to 360 . The matching is based on semantic
                  information. Surface attributes are extracted and
                  incorporated in a forest of search trees in order to
                  associate the data, i.e., to establish
                  correspondences. The new approach results in
                  advances in speed and reliability. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/robocup2005.pdf},
}


@inproceedings{SSRR2005,
  Address      = {Kobe, Japan},
  Author       = {A. N{\"u}chter and K. Lingemann and J. Hertzberg and
                  H. Surmann and K. Perv{\"o}lz and M. Hennig and
                  K. R. Tiruchinapalli and R. Worst and
                  T. Christaller},
  Booktitle    = {Proceedings of the IEEE International Workshop on
                  Safety, Security and Rescue Robotics (SSRR '05)},
  Month        = {June},
  Pages        = {158--163},
  Title        = {{M}apping of {R}escue {E}nvironments with {Kurt3D}},
  Year         = {2005},
  abstract     = {Deploying rescue workers in an urban setting is
                  often a perilous, time-, power-, and force-consuming
                  job, and systems to assist in this effort are
                  needed. A fundamental task for rescue is to localize
                  injured persons. To this end, robotic systems are
                  used for mapping a site and for remote inspection of
                  suspicious objects. The mobile robot Kurt3D is the
                  first rescue robot that is capable of mapping its
                  environment in 3D and self localize in all six
                  degrees of freedom, i.e., considering its x, y and z
                  positions and the roll, yaw and pitch angles. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ssrr2005.pdf},
}


@article{RAS2005,
  Author       = {K. Lingemann and A. N{\"u}chter and J. Hertzberg and
                  H. Surmann},
  Journal      = {Journal Robotics and Autonomous Systems (JRAS)},
  Title        = {High-{S}peed {L}aser {L}ocalization for {M}obile
                  {R}obots},
  Volume       = {51},
  Number       = {4},
  Year         = {2005},
  Pages        = {275--296},
  abstract     = {This paper describes a novel, laser-based approach
                  for tracking the pose of a high-speed mobile
                  robot. The algorithm is outstanding in terms of
                  accuracy and computation time. The efficiency is
                  achieved by a closed-form solution for the matching
                  of two laser scans, the use of natural scan features
                  and fast linear filters. The implemented algorithm
                  is evaluated with the high-speed robot Kurt3D
                  (4 m/s), and compared to standard scan matching
                  methods in indoor and outdoor environments.},
  doi          = {10.1016/j.robot.2005.02.004},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/raas2005-highspeed-laser-localization.pdf},
}


@InProceedings{ICRA2005,
  author        = {S. Mitri and S. Frintrop and K. Perv{\"o}lz and
                  H. Surmann and A. N{\"u}chter},
  title         = {{Robust Object Detection at Regions of Interest
                  with an Application in Ball Recognition}},
  booktitle     = {Proceedings of the IEEE International Conference
                  Robotics and Automation (ICRA '05)},
  pages         = {126--131},
  year          = {2005},
  address       = {Barcelona, Spain},
  month         = {April},
  abstract     = {In this paper, we present a new combination of a
                  biologically inspired attention system (VOCUS –
                  Visual Object detection with a CompUtational
                  attention System) with a robust object detection
                  method. As an application, we built a reliable
                  system for ball recognition in the RoboCup
                  context. Firstly, VOCUS finds regions of interest
                  generating a hypothesis for possible locations of
                  the ball. Secondly, a fast classifier verifies the
                  hypothesis by detecting balls at regions of
                  interest. The combination of both approaches makes
                  the system highly robust and eliminates false
                  detections. Furthermore, the system is quickly
                  adaptable to balls in different scenarios: The
                  complex classifier is universally applicable to
                  balls in every context and the attention system
                  improves the performance by learning
                  scenario-specific features quickly from only a few
                  training examples.},
  doi          = {10.1109/ROBOT.2005.1570107},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icra2005.pdf},
}


% --- 2004 ---


@inproceedings{IROS2004_1,
  Address      = {Sendai, Japan},
  Author       = {S. Frintrop and A. N{\"u}chter and H. Surmann and
                  J. Hertzberg},
  Booktitle    = {Proceedings of the IEEE/RSJ International Conference
                  on Intelligent Robots and Systems (IROS '04)},
  Month        = {September},
  Pages        = {2167--2172},
  Title        = {{S}aliency-based {O}bject {R}ecognition in {3D}
                  {D}ata},
  Year         = {2004},
  abstract     = {This paper presents a robust and real-time capable
                  recognition system for the fast detection and
                  classification of objects in spatial 3D data. Depth
                  and reflection data from a 3D laser scanner are
                  rendered into images and fed into a saliency-based
                  visual attention system that detects regions of
                  potential interest. Only these regions are examined
                  by a fast classifier. The time saving of classifying
                  objects in salient regions rather than in complete
                  images is linear with the number of trained object
                  classes. Robustness is achieved by the fusion of the
                  bi-modal scanner data; in contrast to camera images,
                  this data is completely illumination
                  independent. The recognition system is trained for
                  two different object classes and evaluated on real
                  indoor data.},
  doi          = {10.1109/IROS.2004.1389730},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iros2004_1.pdf},
}


@inproceedings{IROS2004,
  Address      = {Sendai, Japan},
  Author       = {K. Lingemann and H. Surmann and A. N{\"u}chter and
                  J. Hertzberg},
  Booktitle    = {Proceedings of the IEEE/RSJ International Conference
                  on Intelligent Robots and Systems (IROS '04)},
  Month        = {September},
  Pages        = {2185--2190},
  Title        = {{I}ndoor and {O}utdoor {L}ocalization for {F}ast
                  {M}obile {R}obots},
  Year         = {2004},
  abstract     = {This paper describes a novel, laser-based approach
                  for tracking the pose of a high-speed mobile
                  robot. The algorithm is outstanding in terms of
                  accuracy and computational time, being 33 times
                  faster than real time. The efficiency is achieved by
                  a closed form solution for the matching of two
                  lasers scans, the use of natural landmarks and fast
                  linear filters. The implemented algorithm is
                  evaluated with the high-speed robot Kurt3D (4 m/s),
                  and compared to standard scan matching methods in
                  indoor and outdoor environments.},
  doi          = {10.1109/IROS.2004.1389733},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/iros2004.pdf},
}


@InProceedings{MECHROB2004,
  author       = {S. Mitri and K. Perv{\"o}lz and H. Surmann and
                  A. N{\"u}chter},
  title        = {{Fast Color-Independent Ball Detection for Mobile
                  Robots}},
  booktitle    = {Proceedings of the IEEE International Conference
                  Mechatronics and Robotics 2004 (MechRob '04)},
  pages        = {900--905},
  year         = {2004},
  address      = {Aachen, Germany},
  month        = {September},
  abstract     = {This paper presents a novel scheme for fast color
                  invariant ball detection in the RoboCup
                  context. Edge filtered camera images serve as an
                  input for an Ada Boost learning procedure that
                  constructs a cascade of classification and
                  regression trees (CARTs). Our system is capable to
                  detect different soccer balls in the RoboCup and
                  other environments. The resulting approach for
                  object classification is real-time capable and
                  reliable. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/mechrob2004.pdf},
}


@InProceedings{WAFR2004,
  author       = {S. Fekete and R. Klein and A. N{\"u}chter},
  title        = {{Online Searching with an Autononmous Robot}},
  booktitle    = {Algorithmic Foundations of Robotics VI, STAR 17
                  (Proceedings of the 6th International Workshop on
                  the Algorithmic Foundations of Robotics (WAFR '04))},
  pages        = {139--154},
  year         = {2004},
  volume       = {17},
  series       = {Springer Tracts in Advanced Robotics},
  address      = {Zeist/Utrecht, The Netherlands},
  month        = {July},
  abstract     = {We discuss online strategies for visibility-based
                  searching for an ob ject hidden behind a corner,
                  using Kurt3D, a real autonomous mobile robot. This
                  task is closely related to a number of well-studied
                  problems. Our robot uses a threedimensional laser
                  scanner in a stop, scan, plan, go fashion for
                  building a virtual three-dimensional
                  environment. Besides planning tra jectories and
                  avoiding obstacles, Kurt3D is capable of identifying
                  objects like a chair. We derive a practically useful
                  and asymptotically optimal strategy that guarantees
                  a competitive ratio of 2, which differs remarkably
                  from the well-studied scenario without the need of
                  stopping for surveying the environment. Our strategy
                  is used by Kurt3D, documented in a separate video. },
  doi          = {10.1007/10991541_11},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/scg2004/},
}


@techreport{TDP2004,
  Address      = {Portugal},
  Author       = {H. Surmann and R. Worst and M. Hennig and
                  K. Lingemann and A. N{\"u}chter and K. Perv{\"o}lz
                  and K. Raj Tiruchinapalli and T. Christaller and
                  J. Hertzberg},
  Institution  = {Team Description Paper, Rescue Robot League Competition},
  Month        = {July},
  Title        = {{RoboCupRescue - Robot League Team, Team Kurt3D}},
  Year         = {2004},
  abstract     = {A mobile robot named KURT3D was developed at the
                  Fraunhofer Institute for Autonomous Intelligent
                  Systems during the last three years. The key
                  innovation of this system lies in the capability for
                  autonomous or operatorassisted 6D SLAM (simultaneous
                  localization and mapping) and 3D map generation of
                  natural scenes. Hence, KURT3D already meets the
                  basic requirement regarding urban search and
                  rescue. For the rescue robot league competition, it
                  is additionally configured with dedicated
                  state-of-the-art equipment. The robot and the
                  operator station are rather compact and easy to set
                  up. The operator uses a joystick as a remote control
                  for the robot and can watch a live video of the
                  scene where the robot drives. Data are transmitted
                  via wireless LAN. A 3D laser scanner, which is
                  mounted on an outdoor variant of KURT3D, is used as
                  the main sensor for map generation as well as for
                  navigation and localization. The whole system has
                  been used with a proven record of success for
                  different tasks of map building, so that we a
                  reconfident of managing the rescue robot league
                  competition, too. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/Lisbon_Kurt3D/rr2004-team-kurt3D.pdf},
}


@inproceedings{IAV2004,
  Address      = {Lisbon, Portugal},
  Author       = {H. Surmann and A. N{\"u}chter and K. Lingemann and
                  J. Hertzberg},
  Booktitle    = {Proceedings of the 5th IFAC Symposium on Intelligent
                  Autonomous Vehicles (IAV '04)},
  Month        = {July},
  Title        = {{6D SLAM} {A} {P}reliminary {R}eport on {C}losing
                  the {L}oop in {S}ix {D}imensions},
  Year         = {2004},
  abstract     = {To create 3D volumetric maps of scenes with
                  autonomous mobile robots it is necessary to gage
                  several 3D scans and to merge them into one
                  consistent 3D model. This paper provides a new
                  solution to the simultaneous localization and
                  mapping (SLAM) problem with six degrees of
                  freedom. Robot motion on natural surfaces has to
                  cope with yaw, pitch and roll angles, turning pose
                  estimation into a problem in six mathematical
                  dimensions. A fast variant of the Iterative Closest
                  Points (ICP) algorithm registers the 3D scans in a
                  common coordinate system and relocalizes the
                  robot. Finally, consistent 3D maps are generated
                  using closing loop detection and a global
                  relaxation. Keywords: autonomous mobile robots, 3D
                  laser scanner, 3D scan matching, simultaneous
                  localization and mapping (SLAM), closing loop. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/6Dpre/},
}


@InProceedings{SOCG2004,
  author       = {S. Fekete and R. Klein and A. N{\"u}chter},
  title        = {{Searching with an Autonomous Robot}},
  booktitle    = {Proccedings of the 20th ACM Annual Symposium on
                  Computational Geometry (SoCG '04)},
  pages        = {449--450},
  year         = {2004},
  address      = {New York, USA},
  month        = {June},
  abstract     = {We demonstrate how one of the classical areas of
                  computational geometry has reached practical
                  application, which in turn gives rise to new,
                  fascinating geometric problems. In particular, we
                  discuss the problem of developing a good online
                  strategy for an autonomous mobile robot to locate an
                  object that is hidden behind a corner or door.},
  doi          = {10.1145/997817.997885},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/scg2004/},
}


@InProceedings{ROBOTIK2004,
  author       = {K. Perv{\"o}lz and A. N{\"u}chter and H. Surmann and
                  J. Hertzberg},
  title        = {{Automatic Reconstruction of Colored 3D Models}},
  booktitle    = {Proceedings of Robotik 2004, VDI-Berichte 1841},
  pages        = {215--222},
  year         = {2004},
  series       = {VDI-Berichte 1841},
  address      = {Munich, Germany},
  month        = {June},
  abstract     = {A basic issue of mobile robotics is the automatic
                  generation of environment maps. This paper presents
                  novel results for the reconstruction of textured 3D
                  maps with an autonomous mobile robot, a 3D laser
                  range finder and two pan-tilt color
                  cameras. Building 3D maps involves a number of
                  fundamental scientific issues. This paper adresses
                  the issue of how to fuse the geometry data of the 3D
                  laser range finder with camera images. The proposed
                  algorithm allows to texturize geometrical 3D
                  scenes-models.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/robotik2004.pdf},
}


@InProceedings{WAPCV2004,
  author       = {S. Frintrop and A. N{\"u}chter and H. Surmann},
  title        = {{Visual Attention for Object Recognition in Spatial
                  3D Data}},
  booktitle    = {Proceedings of 2nd International Workshop on
                  Attention and Performance in Computational Vision
                  (WAPCV '04)},
  series       = {Revised Selected Papers Series: Lecture Notes in
                  Computer Science, Vol. 3368},
  year         = {2004},
  editor       = {L. Paletta and J. K. Tsotsos and E. Rome and
                  G. Humphreys},
  address      = {Prague, Czech Republic},
  month        = {May},
  abstract     = {In this paper, we present a new recognition system
                  for the fast detection and classification of objects
                  in spatial 3D data. The system consists of two main
                  components: A biologically motivated attention
                  system and a fast classifier. Input is provided by a
                  3D laser scanner, mounted on an autonomous mobile
                  robot, that acquires illumination independent range
                  and reflectance data. These are rendered into images
                  and fed into the attention system that detects
                  regions of potential interest. The classifier is
                  applied only to a region of interest, yielding a
                  significantly faster classification that requires
                  only 30\% of the time of an exhaustive
                  search. Furthermore, both the attention and the
                  classification system benefit from the fusion of the
                  bi-modal data, considering more object properties
                  for the detection of regions of interest and a lower
                  false detection rate in classification. },
  doi          = {10.1007/978-3-540-30572-9_13},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/wapcv2004.pdf},
}


@inproceedings{ICRA2004,
  Address      = {New Orleans, USA},
  Author       = {A. N{\"u}chter and H. Surmann and K. Lingemann and
                  J. Hertzberg and S. Thrun},
  Booktitle    = {Proceedings of the IEEE International Conference on
                  Robotics and Automation (ICRA '04)},
  Month        = {April},
  Pages        = {1998--2003},
  Title        = {{6D SLAM} with an {A}pplication in {A}utonomous
                  {M}ine {M}apping},
  Year         = {2004},
  abstract     = {To create with an autonomous mobile robot a 3D
                  volumetric map of a scene it is necessary to gage
                  several 3D scans and to merge them into one
                  consistent 3D model. This paper provides a new
                  solution to the simultaneous localization and
                  mapping (SLAM) problem with six degrees of
                  freedom. Robot motion on natural surfaces has to
                  cope with yaw, pitch and roll angles, turning pose
                  estimation into a problem in six mathematical
                  dimensions. A fast variant of the Iterative Closest
                  Points algorithm registers the 3D scans in a common
                  coordinate system and relocalizes the
                  robot. Finally, consistent 3D maps are generated
                  using a global relaxation. The algorithms have been
                  tested with 3D scans taken in the Mathies mine,
                  Pittsburgh, PA. Abandoned mines pose significant
                  problems to society, yet a large fraction of them
                  lack accurate 3D maps.},
  doi          = {10.1109/ROBOT.2004.1308117},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icra2004.pdf},
}


@InProceedings{MRNV2004,
  author       = {D. Giel and S. Frey and A. Thelen and J. Bongartz
                  and P. Hering and A. N\"{u}chter and H. Surmann and
                  K. Lingemann and J. Hertzberg},
  title        = {{Ultra-fast Holographic Recording and Automatic 3D
                  Scan Matching of Living Human Faces}},
  booktitle    = {Proceedings of the Scientific Workshop Medical
                  Robotics, Navigation and Visualization (MRNV '04)},
  month        = {March},
  year         = {2004},
  address      = {Remagen, Germany},
  abstract     = {},
  doi          = {},
  url          = {},
}

@InProceedings{IAS2004,
  author       = {A. N{\"u}chter and H. Surmann and J. Hertzberg},
  title        = {{A}utomatic {C}lassification of {O}bjects in {3D}
                  {L}aser {R}ange {S}cans},
  booktitle    = {Proceedings of the 8th Conference on Intelligent
                  Autonomous Systems (IAS '04)},
  month        = {March},
  year         = {2004},
  pages        = {963--970},
  address      = {Amsterdam, The Netherlands},
  abstract     = {3D models of the skin surface of patients are
                  created by ultra-fast holography and automatic scan
                  matching of synchronously recorded holograms. By
                  recording with a pulsed laser and continuous-wave
                  optical reconstruction of the holographic real
                  image, motion artifacts are eliminated. Focal analys
                  is of the real image yields a surface relief of the
                  patient. To generate a complete 360 patient model,
                  several synchronously recorded reliefs are
                  registered by automatic scan matching. We find the
                  transformation consisting of a rotation and a
                  translation that minimizes a cost function
                  containing the Euclidian distances between points
                  pairs from two surface relief maps. A variant of the
                  ICP (Iterative Closest Points) algorithm2 is used to
                  compute such a minimum. We propose a new fast
                  approximation based on kDtrees for the problem of
                  creating the closest point pairs on which the ICP
                  algorithm spends most of its time. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/mrnv2004.pdf},
}


@InProceedings{TWK2004,
  author       = {S. Frintrop and E. Rome and A. N{\"u}chter and H. Surmann},
  title        = {{Focussing Object Recognition on Regions of
                  Interest}},
  booktitle    = {Proceedings of the 7. T{\"u}bingen Perception
                  Conference (TWK '04)},
  pages        = {67},
  year         = {2004},
  editor       = {H. B{\"u}lthoff and H. A. Mallot and R. Ulrich and
                  F. A. Wichmann},
  address      = {T{\"u}bingen, Germany},
  month        = {February},
}


% --- 2003 ---


@InProceedings{IT2003,
  author       = {A. N{\"u}chter},
  title        = {{Schnelle Visualisierung von Radialen 3D-Laserscans}},
  booktitle    = {Proceedings of the 5. Fachwissenschaftlicher
                  Informatikkongress - Informatiktage 2003},
  pages        = {243--246},
  year         = {2003},
  address      = {Bad Schussenried, Germany},
  month        = {November},
}


@article{RAAS2003,
  author       = "H. Surmann and A. N{\"u}chter and J. Hertzberg",
  title        = "{A}n autonomous mobile robot with a {3D} laser range
                  finder for {3D} exploration and digitalization of
                  indoor environments",
  journal      = "Journal Robotics and Autonomous Systems (JRAS)",
  volume       = "45",
  number       = "3--4",
  month        = "December",
  year         = "2003",
  pages        = "181--198",
  abstract     = { Digital 3D models of the environment are needed in
                  rescue and inspection robotics, facility managements
                  and architecture. This paper presen ts an automatic
                  system for gaging and digitalization of 3D indoor
                  environments. It consists of an autonomous mobile
                  robot, a reliable 3D laser range finder and three
                  elaborated software modules. The first module, a
                  fast variant of the Iterative Closest Points
                  algorithm, registers the 3D scans in a common
                  coordinate system and relocalizes the robot. The
                  second module, a next best view planner, computes
                  the next nominal pose based on the acquired 3D data
                  while avoiding complicated obstacles. The third
                  module, a closed-loop and globally stable motor
                  controller, navigates the mobile robot to a nominal
                  pose on the base of odometry and avoids collisions
                  with dynamical obstacles. The 3D laser range finder
                  acquires a 3D scan at this pose. The proposed method
                  allows one to digitalize large indoor environments
                  fast and reliably without any intervention and
                  solves the SLAM problem. The results of two 3D
                  digitalization experiments are presented using a
                  fast octree-based visualization method.},
  doi          = {10.1016/j.robot.2003.09.004},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/raas2003.pdf},
}


@inproceedings{VMV2003,
  Address      = {Munich, Germany},
  Author       = {A. N{\"u}chter and H. Surmann and K. Lingemann and
                  J. Hertzberg},
  Booktitle    = {Proceedings of the of the 8th International Fall
                  Workshop Vision, Modeling, and Visualization (VMV
                  '03)},
  Month        = {November},
  Pages        = {215--222},
  Title        = {{S}emantic {S}cene {A}nalysis of {S}canned {3D}
                  {I}ndoor {E}nvironments},
  Year         = {2003},
  abstract     = {Precise digital 3D models of indoor environments are
                  needed in several applications, e.g., facility
                  management, architecture, rescue and inspection
                  robotics. This paper presents a new method that
                  transforms a 3D volumetric model, acquired by a
                  mobile robot equipped with a 3D laser scanner, into
                  a very precise compact 3D map and generates semantic
                  descriptions. The scanned 3D scene is matched
                  against a coarse semantic description of general
                  indoor environments. The matching is done by a
                  Prolog program compiled from the scanned 3D scene
                  and combined with clauses from the coarse semantic
                  description. The generated scene specific knowledge
                  produced by the unification in the Prolog program is
                  used to refine the 3D model. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/vmv2003.pdf},
}


@article{ERCIM,
  author       = {H. Surmann and A. N{\"u}chter and K. Lingemann and
                  J. Hertzberg},
  title        = {{Kurt3D - An Autonomous Mobile Robot for Modeling
                  the World in 3D}},
  Journal      = {ERCIM NEWS},
  volume       = {55},
  pages        = {24--25},
  month        = {October},
  year         = {2003},
}

@InProceedings{3DIM2003,
  author       = "A. N{\"u}chter and H. Surmann and J. Hertzberg",
  title        = "{A}utomatic {M}odel {R}efinement for {3D}
                  {R}econstruction with {M}obile {R}obots",
  booktitle    = "Proceedings of the 4th IEEE International Conference
                  on Recent Advances in 3D Digital Imaging and
                  Modeling (3DIM '03)",
  month        = "October",
  year         = "2003",
  address      = "Banff, Canada",
  pages        = "394--401",
  abstract     = {Precise digital 3D models of indoor environments
                  are needed in several applications, e.g., facility
                  management, architecture, rescue and inspection
                  robotics. This paper presents a new algorithm that
                  transforms a 3D volumetric model into a very precise
                  compact 3D map and generates semantic descri
                  ptions. Our system is composed of a robust,
                  autonomous mobile robot for the automatic data
                  acquisition and a precise, cost effective, high
                  quality 3 D laser scanner to gage indoor
                  environments. The reconstruction method consists of
                  reliable scan matching and feature detection
                  algorithms. The 3D scene is matched against a coarse
                  semantic description of general indoor environments
                  and the generated knowledge is used to refine the 3D
                  model. },
  doi          = {10.1109/IM.2003.1240274},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/3dim2003.pdf},
}


@inproceedings{KI2003,
  Address      = {Hamburg, Germany},
  Author       = {A. N{\"u}chter and H. Surmann and K. Lingemann and
                  J. Hertzberg},
  Booktitle    = {KI 2003: Advances in Artificial Intelligence. 26th
                  Annual German Conference on AI, Proceedings Springer
                  LNAI vol. 2821},
  Month        = {September},
  Pages        = {550--564},
  Title        = {{C}onsistent {3D} {M}odel {C}onstruction with
                  {A}utonomous {M}obile {R}obots},
  Year         = {2003},
  abstract     = {Digital 3D models of the environment are needed in
                  facility management, architecture, rescue and
                  inspection robotics. To create 3D volumet ric models
                  of scenes, rooms or buildings, it is necessary to
                  gage several 3D scans and to merge them into one
                  consistent 3D model. This paper presen ts a system,
                  composed of a fast and robust, autonomous mobile
                  robot, a precise, cost effective, high quality 3D
                  laser scanner, and reliable scan mat ching
                  algorithms for measuring and reconstructing
                  environments, capable of matching two 3D scans
                  within a fraction of a second. The proposed new sof
                  tware modules for scan matching are fast variants of
                  the iterative closest point algorithm (ICP) for
                  consistent alignment. Two applications are
                  presented: First, the reconstruction of an office
                  environment, second, the fitting of sewer pipes into
                  3D data to detect deviations from the spatial
                  geometry. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/ki2003.pdf},
}

@InProceedings{ICAR2003,
  author       = "A. N{\"u}chter and H. Surmann and J. Hertzberg",
  title        = "{P}lanning {R}obot {M}otion for {3D}
                  {D}igitalization of {I}ndoor {E}nvironments",
  booktitle    = "Proceedings of the 11th IEEE International
                  Conference on Advanced Robotics (ICAR '03)",
  month        = "June",
  year         = "2003",
  address      = "Coimbra, Portugal",
  pages        = "222--227",
  abstract     = {3D digitalization of environments without occlusions
                  requires multiple 3D scans. Autonomous mobile robots
                  equipped with a 3D laser scanner are wel l suited
                  for the gaging task. They need an efficient
                  exploration scheme for the digitalization. We
                  present a new approach for planning the next scan
                  pose as well as the robot motion. Our approach
                  calculates a collision free trajectory regarding
                  complicated objects, e.g., with jutting out edges. A
                  closed loop and global ly stable motor control ler
                  navigates the mobile robot. The results of a 3D
                  digitalization experiment in the main hall of castle
                  Birlinghoven is presented. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icar2003.pdf},
}


@InProceedings{ICVS2003,
  author       = {S. Frintrop and E. Rome and A. N{\"u}chter and H. Surmann},
  title        = {{An Attentive, Multi-modal Laser Eye}},
  booktitle    = {Proceedings of the third International Conference on
                  Computer Vision Systems (ICVS '03)},
  pages        = {202--211},
  year         = {2003},
  address      = {Graz, Austria},
  month        = {April},
  abstract     = {In this paper we present experimental results on a
                  novel application of visual attention mechanisms for
                  the selection of points of interes t in an arbitrary
                  scene. The imaging sensor used is a multi-modal 3D
                  laser scanner. In a single 3D scan pass, it is
                  capable of providing range data as well as a
                  gray-scale intensity image. The scanner is mounted
                  on top of an autonomous mobile robot and serves
                  control purposes. We present results achieved by
                  applying the visual attention system of Itti et
                  al. [8] to recorded scans of indoor and outdoor
                  scenes. The vast ma jority of the prima ry attended
                  locations pointed to scene ob jects of potential
                  interest for navigation and ob ject detection
                  tasks. Moreover, both sensor modalities c omplement
                  each other, resulting in a greater variety of points
                  of interest than one modality alone can provide. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/icvs03-laser-eye-color.pdf},
}

@InProceedings{WAPCV2003,
  author       = {S. Frintrop and E. Rome and A. N{\"u}chter and H. Surmann},
  title        = {{Applying Attentional Mechanisms to Bi-modal 3D
                  Laser Data}},
  booktitle    = {Proecceings of the International Workshop on
                  Attention and Performance in Computer Vision (WAPCV
                  '03)},
  pages        = {25--30},
  year         = {2003},
  address      = {Graz, Austria},
  month        = {April},
  abstract     = {In this paper we present experimental results on a
                  novel application of visual attention mechanisms for
                  the selection of points of interest in an ar bitrary
                  scene. The imaging sensor used is a multi-modal 3D
                  laser scanner. In a single 3D scan pass, it is
                  capable of providing range data as well as a
                  gray-scale intensity image. The scanner is mounted
                  on top of an autonomous mobile robot and serves
                  control purposes. We present results achieved by
                  applying the visual attention system of Itti et
                  al. [8] to recorded scans of indoor and outdoor
                  scenes. The vast majority of the primary attended l
                  ocations pointed to scene objects of potential i
                  nterest for navigation and object detection
                  tasks. Moreover, both sensor modalities complement
                  each other, resulting in a greater variety of points
                  of interest than one modality alone can provide.},
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/wapcv2003.pdf},
}


@InProceedings{TWK2003,
  author       = {S. Frintrop and E. Rome and A. N{\"u}chter and H. Surmann},
  title        = {{Visuelle Aufmerksamkeitsmechanismen auf bimodalen
                  Laserdaten}},
  booktitle    = {Beitr{\"a}ge zur 6. T{\"u}binger
                  Wahrnehmungskonferenz (TWK '03)},
  pages        = {100},
  year         = {2003},
  address      = {T{\"u}bingen, Germnay},
  month        = {Februrary},
}

@Book{REPORT2003,
  author       = {H. Surmann and A. N{\"u}chter and J. Hertzberg},
  title        = {{Autonomous Mobile Robots for 3D Digitalization of
                  Indoor Environments}},
  publisher    = {GMD - Forschungszentrum Informationstechnik GmbH},
  year         = {2003},
  series       = {GMD Report 147},
  address      = {Sankt Augustin, Germany},
}


% --- 2002 ---


@InProceedings{IT2002,
  author       = "A. N{\"u}chter",
  title        = "{Autonome Exploration und 3D-Modellierung der
                  Umgebung eines Roboters}", 
  booktitle    = "Tagungsband zum 4. Fachwissenschaftlichen
                  Informatikkongress - Informatiktage 2001",
  month        = "November",
  year         = "2003",
  pages        = "64--68",
  address      = "Bad Schussenried, Germany",
  abstract     = {Autonome mobile Roboter m{\"u}ssen in der Lage sein,
                  sicher durch ihre Umgebung zu navigieren, um
                  anwendungsspezifische Aufgaben ausf{\"u}hren zu
                  k{\"o}nnen. Gelingen kann dies nur durch den Einsatz von
                  3D-Sensoren und 3D-Karten. Daher ist die
                  automatische und schnelle 3D-Modellierung der
                  Umgebung eine wichtige Fragestellung in der
                  Robotik. 3D-Laserscanner sind eine junge
                  Technologie, die die Erfassung r{\"a}umlicher Daten
                  revolutioniert und Robotern das dreidimensionale
                  Abtasten von Objekten m{\"o}lich macht. Die vorliegende
                  Arbeit untersucht und evaluiert die zur autonome n
                  3D-Kartenerstellung notwendigen Algorithmen mit
                  Hilfe des AIS 3D-Laserscanners, der sich auf einer
                  geeigneten Roboterplattform befindet. Das
                  entwickelte System erm{\"o}glicht das berhrungslose
                  Abtasten der gesamten Umgebung. Daf{\"u}r werden mehrere
                  3D-Scans zu einer konsistenten Szene zusammengef{\"u}gt
                  sowie Scanpositionen generiert. },
}


@Book{REPORT2002,
  author    = "A. N{\"u}chter",
  title     = {{Autonome Exploration und Modellierung von 3D-Umgebungen}},
  publisher = "GMD - Forschungszentrum Informationstechnik GmbH",
  address   = "Sankt Augustin, Germany",
  series = 	  {GMD Report 157},
  month     = "July",
  year      = "2002",
}


@MastersThesis{DIPLOM2002,
  author       = {A. N{\"u}chter},
  title        = {{Autonome Exploration und Modellierung von 3D-Umgebungen}},
  school       = {Universit{\"a}t Bonn},
  year         = {2002},
  month        = {July},
}


% --- 2001 ---


@InProceedings{IT2001,
  author       = "A. N{\"u}chter and K. Lingemann",
  title        = "Ein 3{D}-{L}aserscanner f{\"u}r autonome mobile {R}oboter",
  booktitle    = "Tagungsband zum 3. Fachwissenschaftlichen
                  Informatikkongress - Informatiktage 2001",
  month        = "November",
  year         = "2001",
  pages        = "89--92",
  address      = "Bad Schussenried, Germany"
}


@InProceedings{VMV2001,
  author       = "H. Surmann and K. Lingemann and A. N{\"u}chter and
                  J. Hertzberg",
  title        = "{F}ast acquiring and analysis of three dimensional
                  laser range data",
  booktitle    = "Proceedings of the 6th International Fall Workshop
                  Vision, Modeling, and Visualization (VMV '01)",
  month        = "November",
  year         = "2001",
  pages        = "59--66",
  address      = "Stuttgart, Germany",
}


@InProceedings{ISR2001,
  author       = "H. Surmann and K. Lingemann and A. N{\"u}chter and
                  J. Hertzberg",
  title        = "A 3{D} laser range finder for autonomous mobile
                  robots",
  booktitle    = "Proceedings of the 32nd International Symposium on
                  Robotics (ISR '01)",
  month        = "April",
  year         = "2001",
  pages        = "153--158",
  address      = "Seoul, Korea",
  abstract     = { This paper presents a high quality, low cost 3D
                  laser range finder designed for autonomous mobile
                  systems. The 3D laser is built on the bas e of a 2D
                  range finder by the extension with a standard
                  servo. The servo is controlled by a computer running
                  RT-Linux. The scan resolution (5 cm) f or a complete
                  3D scan of an area of 150 (h) 90 (v) degree is up to
                  115000 points and can be grabbed in 12
                  seconds. Standard resolutions e.g. 150 (h) 90 (v)
                  degree with 22500 points are grabbed in 4
                  seconds. While scanning, different online algorithms
                  for line and surface detection are applied to the
                  data. Object segmentation and detection are done
                  offline after the scan. The implemented software
                  modules detect overhanging objects blocking t he
                  path of the robot. With the proposed approach a
                  cheap, precise, reliable and real-time capable 3D
                  sensor for autonomous mobile robots is availabl e
                  and the robot navigation and recognition in
                  real-time is improved. 1. Introduction Prognoses at
                  the beginning of the nineties claimed for the new
                  millennium a number of about 50.000 independently
                  operating autonomous service robots in different
                  areas of production and service sectors [1]. The
                  reality is different. In industrial environments
                  guided vehicles, i.e. vehicles guided by a magnetic
                  or optical track are standard [2]. Autonomous mobile
                  service systems, i.e. systems not restricted by a
                  track, are used extremely rarely although many
                  research groups are working on this since sev eral
                  years particularly with mobile systems for
                  transportation tasks, e.g. [3, 4, 5, 6]. One of
                  several reasons for the gap between prognoses and r
                  eality is the lack of good, cheap and fast sensors
                  that allow the robots to sense the environment in
                  real-time and to act on the basis of the acquir ed
                  data. This paper presents a 3D laser range finder
                  designed for autonomous mobile systems (fig. 1). A
                  large number of today's autonomous robots us e 2D
                  laser range finders as a proximity sensor. They are
                  very fast (processing time 30 ms), precise ( 1 cm, )
                  and becoming cheaper (\$3000) since th ere are at
                  least two competing products [7, 8]. },
  url          = {https://robotik.informatik.uni-wuerzburg.de/telematics/download/isr2001.pdf},
}


@Book{REPORT2001,
  author       = "H. Surmann and K. Lingemann and A. N{\"u}chter and
                  J. Hertzberg",
  title        = "Aufbau eines 3D--Laserscanners f{\"u}r autonome
                  mobile Roboter, GMD Report 126",
  publisher    = "GMD - Forschungszentrum Informationstechnik GmbH",
  address      = "Sankt Augustin",
  month        = "March",
  year         = "2001",
  series       = "GMD-Report 126",
}

% ------ other sources

@article{3D_per_2D_based,
author = {Fang, Zheng and Zhao, Shibo and Wen, Shiguang and Zhang, Yu},
year = {2018},
month = {05},
pages = {1-14},
title = {A Real-Time 3D Perception and Reconstruction System Based on a 2D Laser Scanner},
volume = {2018},
journal = {Journal of Sensors},
doi = {10.1155/2018/2937694}
}


@misc{allen, title={Unearthing the Subterranean Environment}, howpublished={\url{https://www.subtchallenge.com}}, journal={DARPA Subterranean Challenge}, author={Allen, Booz}, note={Accessed: 2020-04-06}}

@article{classical_mechanics_scanner,
author = {Lehtola, Ville and Virtanen, Juho-Pekka and Kukko, Antero and Kaartinen, Harri and Hyyppä, Hannu},
year = {2015},
month = {01},
pages = {25 - 29},
title = {Localization of mobile laser scanner using classical mechanics},
volume = {99},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
doi = {10.1016/j.isprsjprs.2014.10.008}
}

@misc{imuphidgets, key={Phidgets}, title={{Phidgets Imu Website}}, howpublished={\url{https://www.phidgets.com}}, note={Accessed: 2020-04-15}}

@misc{turnigymotor, key={Turnigy}, title={{Turnigy Park480 Brushless Outrunner}}, howpublished={\url{https://hobbyking.com/en_us/turnigy-park480-brushless-outrunner-1320kv.html}}, note={Accessed: 2020-04-17}}

@misc{tate1893sphere,
  title={Method and system for measurement of road profile},
  author={J.L. Tate},
  url={http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&d=PALL&p=1&u=%2Fnetahtml%2FPTO%2Fsrchnum.htm&r=1&f=G&l=50&s1=0508558.PN.&OS=PN/0508558&RS=PN/0508558},
  year={1893},
  month={November 14,},
  note={US Patent 508,558}
}

@inproceedings{cubliIROS12,
author={M. Gajamohan and M. Merz and I. Thommen and R. D'Andrea},
title={The Cubli: A Cube that can Jump Up and Balance},
booktitle={International Conference on Intelligent Robots and Systems},
year={2012},
pages={3722-3727}
}



















